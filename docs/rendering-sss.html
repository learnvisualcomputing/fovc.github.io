<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Subsurface and Volume Scattering – Foundations of Visual Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./imaging.html" rel="next">
<link href="./rendering-surface.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./rendering.html">Rendering</a></li><li class="breadcrumb-item"><a href="./rendering-sss.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Subsurface and Volume Scattering</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Foundations of Visual Computing</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">An Invitation to Visual Computing</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./hvs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Human Visual System</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">From Light to Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-receptor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Photoreceptors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-color.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-colorimetry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Colorimetry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-retcomp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Models for Retinal Computation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Visual Adaptations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./rendering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rendering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The Basics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-surface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Surface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-sss.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Subsurface and Volume Scattering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./imaging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Imaging</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Imaging Optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-sensor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Image Sensor Architecture</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-noises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Noises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-isp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Image Signal Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./display.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Display</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Basic Principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-impl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Implementation Technologies</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-chpt-mat-vs-ov" id="toc-sec-chpt-mat-vs-ov" class="nav-link active" data-scroll-target="#sec-chpt-mat-vs-ov"><span class="header-section-number">10.1</span> An Informal Discussion to Build Intuition</a>
  <ul class="collapse">
  <li><a href="#general-intuitions" id="toc-general-intuitions" class="nav-link" data-scroll-target="#general-intuitions"><span class="header-section-number">10.1.1</span> General Intuitions</a></li>
  <li><a href="#transparent-vs.-opaque-vs.-translucent-materials" id="toc-transparent-vs.-opaque-vs.-translucent-materials" class="nav-link" data-scroll-target="#transparent-vs.-opaque-vs.-translucent-materials"><span class="header-section-number">10.1.2</span> Transparent vs.&nbsp;Opaque vs.&nbsp;Translucent Materials</a></li>
  <li><a href="#equilibrium" id="toc-equilibrium" class="nav-link" data-scroll-target="#equilibrium"><span class="header-section-number">10.1.3</span> Equilibrium</a></li>
  </ul></li>
  <li><a href="#sec-chpt-mat-vs-abs" id="toc-sec-chpt-mat-vs-abs" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-abs"><span class="header-section-number">10.2</span> Absorption</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-mat-vs-abs-simple" id="toc-sec-chpt-mat-vs-abs-simple" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-abs-simple"><span class="header-section-number">10.2.1</span> A Simple Case: Collimated Illumination on Uniform Medium</a></li>
  <li><a href="#absorption-coefficient" id="toc-absorption-coefficient" class="nav-link" data-scroll-target="#absorption-coefficient"><span class="header-section-number">10.2.2</span> Absorption Coefficient</a></li>
  <li><a href="#sec-chpt-mat-vs-abs-quan" id="toc-sec-chpt-mat-vs-abs-quan" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-abs-quan"><span class="header-section-number">10.2.3</span> A Few Important Quantities</a></li>
  <li><a href="#general-case" id="toc-general-case" class="nav-link" data-scroll-target="#general-case"><span class="header-section-number">10.2.4</span> General Case</a></li>
  <li><a href="#nature-and-applicability-of-the-model" id="toc-nature-and-applicability-of-the-model" class="nav-link" data-scroll-target="#nature-and-applicability-of-the-model"><span class="header-section-number">10.2.5</span> Nature and Applicability of the Model</a></li>
  </ul></li>
  <li><a href="#sec-chpt-mat-vs-sca" id="toc-sec-chpt-mat-vs-sca" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-sca"><span class="header-section-number">10.3</span> Scattering</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-mat-vs-sca-intuition" id="toc-sec-chpt-mat-vs-sca-intuition" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-sca-intuition"><span class="header-section-number">10.3.1</span> Scattering by a Particle vs.&nbsp;a Collection of Particles</a></li>
  <li><a href="#sec-chpt-mat-vs-sca-single" id="toc-sec-chpt-mat-vs-sca-single" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-sca-single"><span class="header-section-number">10.3.2</span> A Single Scattering Event</a></li>
  <li><a href="#sec-chpt-mat-vs-sca-single-pf" id="toc-sec-chpt-mat-vs-sca-single-pf" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-sca-single-pf"><span class="header-section-number">10.3.3</span> Scattering Direction Distribution: Phase Function</a></li>
  <li><a href="#sec-chpt-mat-vs-sca-models" id="toc-sec-chpt-mat-vs-sca-models" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-sca-models"><span class="header-section-number">10.3.4</span> Common Models and General “Rules”</a></li>
  </ul></li>
  <li><a href="#sec-chpt-mat-vs-rte" id="toc-sec-chpt-mat-vs-rte" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte"><span class="header-section-number">10.4</span> Radiative Transfer Equation and Volume Rendering</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-mat-vs-rte-rte" id="toc-sec-chpt-mat-vs-rte-rte" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-rte"><span class="header-section-number">10.4.1</span> Radiative Transfer Equation</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-vre" id="toc-sec-chpt-mat-vs-rte-vre" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-vre"><span class="header-section-number">10.4.2</span> Volume Rendering Equation</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-vis" id="toc-sec-chpt-mat-vs-rte-vis" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-vis"><span class="header-section-number">10.4.3</span> Discrete VRE and Scientific Volume Visualization</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-nr" id="toc-sec-chpt-mat-vs-rte-nr" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-nr"><span class="header-section-number">10.4.4</span> Discrete VRE in (Neural) Radiance-Field Rendering</a></li>
  <li><a href="#sec-chpt-mat-vs-sca-bssrdf" id="toc-sec-chpt-mat-vs-sca-bssrdf" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-sca-bssrdf"><span class="header-section-number">10.4.5</span> Integrating Surface Scattering with Volume Scattering</a></li>
  </ul></li>
  <li><a href="#sec-chpt-mat-vs-km" id="toc-sec-chpt-mat-vs-km" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-km"><span class="header-section-number">10.5</span> The Kubelka–Munk Model</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-mat-vs-km-derivation" id="toc-sec-chpt-mat-vs-km-derivation" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-km-derivation"><span class="header-section-number">10.5.1</span> Deriving the Model</a></li>
  <li><a href="#sec-chpt-mat-vs-km-model" id="toc-sec-chpt-mat-vs-km-model" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-km-model"><span class="header-section-number">10.5.2</span> The Model and Its Interpretation</a></li>
  <li><a href="#sec-chpt-mat-vs-km-mix" id="toc-sec-chpt-mat-vs-km-mix" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-km-mix"><span class="header-section-number">10.5.3</span> K-M Model for Mixture of Materials</a></li>
  <li><a href="#sec-chpt-mat-vs-km-nflux" id="toc-sec-chpt-mat-vs-km-nflux" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-km-nflux"><span class="header-section-number">10.5.4</span> N-Stream Model</a></li>
  <li><a href="#sec-chpt-mat-vs-km-cor" id="toc-sec-chpt-mat-vs-km-cor" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-km-cor"><span class="header-section-number">10.5.5</span> Correction for Surface Reflection</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./rendering.html">Rendering</a></li><li class="breadcrumb-item"><a href="./rendering-sss.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Subsurface and Volume Scattering</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-chpt-mat-vs" class="quarto-section-identifier"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Subsurface and Volume Scattering</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This chapter studies subsurface scattering and volume scattering. While superficially different, they involve the same forms of light-matter interaction and are modeled in the same way. We start with an example to build some useful intuitions, and then we will get into the weeds of modeling. In our modeling, we start from modeling local events (absorbing and scattering photons by particles), from which we will build a general framework, called the Radiative Transfer Equation and its variant Volume Rendering Equation (VRE), to reason about subsurface and volume scattering globally. Finally, we will connect VRE to (neural) radiance-field rendering, a modern iteration of image-based rendering (<a href="rendering-basics.html#sec-chpt-mat-basics-radiometry-lf" class="quarto-xref"><span>Section 8.6</span></a>) that uses VRE to parameterize the image formation process.</p>
<div class="hidden">
<p><span class="math display">\[
\def\oi{{\omega_i}}
\def\os{{\omega_s}}
\def\Oi{{\Omega_i}}
\def\Os{{\Omega_s}}
\def\d{{\text{d}}}
\def\D{{\Delta}}
\def\do{{\d\omega}}
\def\Do{{\Delta\omega}}
\def\doi{{\d\omega_i}}
\def\dos{{\d\omega_s}}
\def\Doi{{\D\omega_i}}
\def\Dos{{\D\omega_s}}
\def\H{{\mathbf{H}}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cL}{\mathcal{L}}
\]</span></p>
</div>
<section id="sec-chpt-mat-vs-ov" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="sec-chpt-mat-vs-ov"><span class="header-section-number">10.1</span> An Informal Discussion to Build Intuition</h2>
<p>Once inside the material (through surface refraction), a photon roams about until it meets a particle. The interactions between photons and particles are governed by the subsurface scattering (SSS) or volume scattering processes. As noted before, photon emission, absorption, and scattering all take place during the SSS/volume scattering processes, not just scattering, even though the names suggest otherwise. We will generally ignore emission in our discussion unless otherwise noted, but just note that emission does happen and is correlated with absorption, since emission is the result of absorbed photons having (e.g., chemical) reactions with the particles.</p>
<p>Also a reminder that SSS and volume scattering are governed by exactly the same principles, because they are exactly the same thing. In computer vision and graphics literature they might be used to refer to superficially different phenomena. Volume scattering is concerned with materials that can be modeled as a volume of particles, like fog, clouds, and smoke; they are given the name <strong>participating media</strong> in computer graphics. SSS is, instead, more commonly used to refer to solids where subsurface-scattered photons contribute to their observed colors.</p>
<p>Subsurface scattering is so termed to distinguish itself from surface scattering, but what is beneath the surface is nothing more than a volume of particles. In fact, what is above the surface is also a volume of particles. Looking at <a href="#fig-photon_particle_interactions" class="quarto-xref">Figure&nbsp;<span>10.1</span></a>, the air, Material<sub>1</sub>, and Material<sub>2</sub> can all be thought of as participating media. We usually model the air as a vacuum so photons traverse in straight lines undisturbedly, but if we were to be exact, we would want to model the particles in the air, which becomes a participating medium. So “above-surface scattering” is as different from as surface scattering as is subsurface scattering.</p>
<div id="fig-photon_particle_interactions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-photon_particle_interactions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/photon_particle_interactions.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-photon_particle_interactions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.1: At the Air-Material<sub>1</sub> interface, photons are either reflected directly back or penetrate into the material through refraction. The refracted photons interact with the material particles through the volume scattering processes, where some photons are absorbed and others penetrate into Material<sub>2</sub>. For someone observing from the outside, a portion of the photons would eventually leave the material composite altogether and re-enter the air. Some of these leaving photons are called the back-scattered photons that contribute to the apparent surface reflectance; others transmit through the materials and contribute to the apparent transmittance of the material composite.
</figcaption>
</figure>
</div>
<section id="general-intuitions" class="level3" data-number="10.1.1">
<h3 data-number="10.1.1" class="anchored" data-anchor-id="general-intuitions"><span class="header-section-number">10.1.1</span> General Intuitions</h3>
<p>We will use <a href="#fig-photon_particle_interactions" class="quarto-xref">Figure&nbsp;<span>10.1</span></a> as a running example to discuss the life of photons inside the material. At the Air-Material 1 interface, photons are either reflected directly back or penetrate into the material through refraction. When a refracted photon meets a particle, the particle might absorb the photon or scatter it away. If absorbed, the photon is “dead” and can be removed from the discussion. If scattered, the photon might appear to change its direction and continue to travel on a straight line until it meets another particle, so in principle a photon can be scattered multiple times.</p>
<p>There are three fates a photon eventually has to accept: 1) it might be absorbed along the way, 2) it might re-emerge from Material 1 back to the air, or 3) it might emerge to the air from the bottom of Material 2. Absorption is easy to understand: a photon has a certain probability of being absorbed when it meets a particle, so the longer it travels, the more likely it will be absorbed. Let’s examine the other two cases where a photon escapes the media.</p>
<ul>
<li><p>After multiple scattering, some of the initial photons that enter Material 1 from the air will reach the Material 1-air boundary again, but this time from the material side. At that point, the photons necessarily go through another round of reflection-refraction governed by the surface scattering processes. The refracted photons will re-emerge from Material 1.</p>
<p>This is called <strong>back-scattering</strong>, because these photons are scattered back to where they come. As a consequence, when we observe the material from the same side of the illumination, the lights that enter our eye come from two sources: the initial surface scattering and the back-scattering.</p></li>
<li><p>Some photons might leave Material 1 from the other side and enter Material 2, in which photons go through the same volume scattering processes, where some are absorbed, some can be turned back to Material 1, and some, critically, can hit the Air-Material 2 interface. Just like what happens at the Air-Material 1 interface, some of the photons will eventually emerge from Material 2. These photons essentially survive the absorption of all the particles in the media. When you observe the material from the opposite side of the illumination, it is these transmitted photons that dictate the color of the material.</p></li>
</ul>
<p>Sometimes people will also say, “sub-surface scattering is caused by photons exiting at a point different from the incident point”. It points to the fact that a photon can re-emerge anywhere from the material after SSS, whereas surface scattering is <em>modeled</em> to be taking place only at the incident point (although we will see later that this is just a useful macroscopic abstraction or, rather, modeling strategy).</p>
</section>
<section id="transparent-vs.-opaque-vs.-translucent-materials" class="level3" data-number="10.1.2">
<h3 data-number="10.1.2" class="anchored" data-anchor-id="transparent-vs.-opaque-vs.-translucent-materials"><span class="header-section-number">10.1.2</span> Transparent vs.&nbsp;Opaque vs.&nbsp;Translucent Materials</h3>
<p>We often hear materials being described as opaque, translucent, and transparent. We can now more scientifically approach these terms given the intuitions we have built so far.</p>
<section id="transparent-materials" class="level4">
<h4 class="anchored" data-anchor-id="transparent-materials">Transparent Materials</h4>
<p>Transparent materials either scatter light predominantly in forward directions or they scatter very little light (other than surface scattering). As a result, most photons traveling through the material are either absorbed or go through without changing much of their the directions. So if you hold a transparent material against a light source, you can clearly see through the material and see the light on the other side. This does not mean transparent materials always have the same color as the light source — absorption could be wavelength-selective. An example is aqueous/dye solutions where dye molecules are very small (<span class="math inline">\(\sim nm\)</span> range) and, thus, scatter little light so they look transparent, but depending on the absorption spectrum (which depends on how the dye molecules interact with molecules in the solvent), most dye solutions are not colorless.</p>
</section>
<section id="opaque-materials" class="level4">
<h4 class="anchored" data-anchor-id="opaque-materials">Opaque Materials</h4>
<p>In many materials, photons arriving at the material surface are either reflected right away at the surface or, for those that do penetrate into the materials, are all absorbed by the subsurface particles. Examples include conductors like metals, whose subsurface absorption is very strong, or sufficiently thick dielectrics. These materials are <strong>opaque</strong> in two senses. First, their transmittance is practically 0. Because of strong absorption, no photon re-emerges at the other side of the material. If you hold, say, a brick (dielectric) against a light bulb, the brick would completely block the light. Second, their reflectance is independent of the substrate or the material beneath them, so they completely hide the color of the substrate. Painters know that if they want to cover a layer in their painting, they will need to apply a very thick layer of paint on top.</p>
</section>
<section id="translucent-materials" class="level4">
<h4 class="anchored" data-anchor-id="translucent-materials">Translucent Materials</h4>
<p><strong>Translucent</strong> materials such as jade, wax, and human skin are neither opaque nor transparent. If you hold wax against a light bulb, the wax will not completely block the light, so you will see some light, but you will not be able to see clearly the other side through the wax, since photons from the light bulb are very much volume-scattered after passing through the wax. Clearly modeling SSS is critical for accurately estimating the color of translucent materials. In fact, in graphics literature we sometimes see things like “modeling translucent material must consider sub-surface scattering”. In this sense, we might be tempted to classify participating media as translucent materials, because their colors certainly very much depend on volume scattering. While it is technically correct, people rarely do that, perhaps just because of the weirdness of calling, say, smokes, a material rather than a medium?</p>
<p>It is <em>not</em> true that SSS is important only in modeling translucency. Modeling SSS can be important for opaque materials. Consider the wax case: what if we make the wax very thick? The thick wax will eventually become opaque in that it will completely hide the material behind it. But that does not mean volume scattering does not matter here; the back-scattered photons do contribute to the apparent color of a thick wax.</p>
</section>
<section id="oil-painting-example" class="level4">
<h4 class="anchored" data-anchor-id="oil-painting-example">Oil Painting Example</h4>
<p>To put things together, consider a painting. One way paintings are characterized is by how they were painted, and we might see things like ``oil on canvas’’. Oil means the paint is oil paint, where paint pigments are dispersed into (usually linseed) oil, which is usually called the binder or the vehicle. Canvas is the substrate, which is nothing more than another material that is right beneath the painting.</p>
<p>The oil itself is somewhat transparent, especially when you just apply a thin layer on the canvas. But with the paint pigments, the entire oil paint becomes a translucent material. When photons leave the oil paints, they immediately interact with the canvas. If the paint layer is thick enough, virtually no photon can ever reach the canvas. But if the paint is relatively thin, the property of the substrate will contribute to the overall color of the paint. For instance, if the canvas is white-ish, a good percentage of the photons will be reflected back. The same paint would look much darker if the canvas is black, which absorbs a lot of photons.</p>
</section>
</section>
<section id="equilibrium" class="level3" data-number="10.1.3">
<h3 data-number="10.1.3" class="anchored" data-anchor-id="equilibrium"><span class="header-section-number">10.1.3</span> Equilibrium</h3>
<p>We can view the light-material interaction as a dynamical system under an equilibrium. To appreciate this, consider again <a href="#fig-photon_particle_interactions" class="quarto-xref">Figure&nbsp;<span>10.1</span></a>. Some photons entering Material 1 are back-scattered and hit the Air-Material 1 interface and some of those photons will re-enter Material 1 through internal reflection. Those photons will then go through multiple scattering, and as a result some will be back-scattered again and hit the Air-Material 1 interface. The cycle goes on. The secondary back-scattering is weaker in power than the first back-scattering, and the third-order back-scattering is even weaker, and so on. So eventually you can imagine that the total number of photons back-scattered at the surface will reach a constant.</p>
<p>In fact, this sort of dynamics takes place everywhere inside the material along every direction. If you pick a point <span class="math inline">\(p\)</span> in the material (or at the surface) and a direction <span class="math inline">\(\omega\)</span> starting at the point, the radiance at (<span class="math inline">\(p, \omega\)</span>) is a constant under equilibrium. In other words, the spatial radiance distribution (a.k.a., the light field) is not changing over time.</p>
<p>The equilibrium is reached almost instantaneously, since light propagates incredibly fast. So the equilibrium discussion is probably of no practical impact in modeling or actual measurement, but it is still important to keep this in mind. The (spectral) reflectance/BRDF modeling/measurement is done assuming equilibrium, and later when we model volume scattering, we will set up the differential equations under the equilibrium assumption, too.</p>
</section>
</section>
<section id="sec-chpt-mat-vs-abs" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="sec-chpt-mat-vs-abs"><span class="header-section-number">10.2</span> Absorption</h2>
<p>We will focus on modeling absorption in this chapter, and the way we build the models is fundamental to how scattering will be dealt with later.</p>
<section id="sec-chpt-mat-vs-abs-simple" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="sec-chpt-mat-vs-abs-simple"><span class="header-section-number">10.2.1</span> A Simple Case: Collimated Illumination on Uniform Medium</h3>
<p>Imagine that a beam of light hits a volume of particles. The light is <strong>collimated</strong> in that all photons travel along the same direction. We take a slice of the material perpendicular to the incident direction. The slice is so thin that no particles in that material cover each other from the direction of the incident light. This is shown in <a href="#fig-absorption_model" class="quarto-xref">Figure&nbsp;<span>10.2</span></a> (a). We also, for now, assume that the medium is <em>uniform</em> in that the <strong>number concentration</strong> <span class="math inline">\(c\)</span> (i.e., the number of particles per unit volume) of each slice is exactly the same.</p>
<div id="fig-absorption_model" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-absorption_model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/absorption_model.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-absorption_model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.2: Conceptual model to help reason about photon absorption. (a): the setting for calculating the radiance reduction over a very thin slice. (b): the radiance reduction over a finite length is calculated by accumulating the radiance reduction over infinitely many thin slices.
</figcaption>
</figure>
</div>
<p>Say the slice has a depth of <span class="math inline">\(\D s\)</span> and a geometrical cross-sectional area of <span class="math inline">\(E\)</span>. All the particles have the same geometrical cross-sectional area of <span class="math inline">\(\epsilon_g\)</span>. In the simplest model, a photon is absorbed whenever it hits a particle. In reality, the chance of absorption can be higher or lower. The <em>effective</em> area available for absorption is:</p>
<p><span class="math display">\[
\begin{align}
    \epsilon = \epsilon_g Q_a,
\end{align}
\]</span></p>
<p>where <span class="math inline">\(Q_a\)</span> is called the <strong>absorption efficiency</strong> and is usually smaller than 1 for molecules (which have small <span class="math inline">\(\epsilon_g\)</span>) and greater than 1 for large particles (whose <span class="math inline">\(\epsilon_g\)</span> can be large). <span class="math inline">\(Q_a\)</span> is wavelength dependent, so we should have written it as <span class="math inline">\(Q_a(\lambda)\)</span>, but we will omit the wavelength in our notations for simplicity’s sake. In physics, <span class="math inline">\(\epsilon\)</span> is called the <strong>absorption cross section</strong> of the particle; it characterizes the intrinsic capability of a particle to absorb photons. Mind the subtle but important difference between the geometrical cross-sectional area and the cross section of a particle.</p>
<p>The question we are interested in is, if the incident radiance is <span class="math inline">\(L\)</span>, what is the radiance leaving the slice <span class="math inline">\(L+\D L\)</span>? By convention, <span class="math inline">\(\D L\)</span> is defined as the exitant radiance minus the incident radiance and, in this case, has to be negative. The percentage of photons that are absorbed by this slice of particles (<span class="math inline">\(-\frac{\D L}{L}\)</span>) is equivalent to the cross-sectional area of the slice that is covered by the total cross sections of the particles:</p>
<p><span id="eq-abs_1"><span class="math display">\[
\begin{align}
    -\frac{\D L}{L} &amp;= \frac{cE\D s\epsilon}{E},
\end{align}
\tag{10.1}\]</span></span></p>
<p>where <span class="math inline">\(c\)</span> is the particle concentration of the slice, and <span class="math inline">\(E\D s\)</span> is the total volume of the slice. So <span class="math inline">\(cE\D s\)</span> is the number of particles in this thin slice, and <span class="math inline">\(cE\D s\epsilon\)</span> is the total cross section of all the particles. Given the assumption that no particles are covering each other, <span class="math inline">\(\frac{cE\D l\epsilon}{E}\)</span> is then the percentage of the thin slice’s cross-sectional area that is available for photon absorption and, thus, the percentage of the incident photons that are absorbed. The negative sign on the left-hand side of <a href="#eq-abs_1" class="quarto-xref">Equation&nbsp;<span>10.1</span></a> signals the fact that <span class="math inline">\(\D L\)</span> is negative.</p>
<p>We rewrite <a href="#eq-abs_1" class="quarto-xref">Equation&nbsp;<span>10.1</span></a> as <a href="#eq-abs_2" class="quarto-xref">Equation&nbsp;<span>10.2</span></a>: <span id="eq-abs_2"><span class="math display">\[
\begin{align}
    \frac{\D L}{\D s} &amp;= -c\epsilon L = -\sigma_a L,
\end{align}
\tag{10.2}\]</span></span></p>
<p>which shows that the amount of photon absorption per unit length (<span class="math inline">\(\frac{\D L}{\D s}\)</span>) is proportional to the current amount of photons up to a scaling factor <span class="math inline">\(c\epsilon\)</span>. In the computer graphics literature, <span class="math inline">\(c\epsilon\)</span> is called the <strong>absorption coefficient</strong>, denoted <span class="math inline">\(\sigma_a\)</span>.</p>
<section id="bouguer-beer-lamberts-law" class="level4">
<h4 class="anchored" data-anchor-id="bouguer-beer-lamberts-law">Bouguer-Beer-Lambert’s Law</h4>
<p>When <span class="math inline">\(\D s\)</span> approaches infinity, we can rewrite <a href="#eq-abs_2" class="quarto-xref">Equation&nbsp;<span>10.2</span></a> as a differential equation:</p>
<p><span id="eq-abs_3"><span class="math display">\[
\begin{align}
    \frac{\d L}{\d s} = \lim_{\D s \rightarrow 0}\frac{\D L}{\D s} = -\sigma_a L
\end{align}
\tag{10.3}\]</span></span></p>
<p>This equation is a classic case of exponential decay, and its solution is given by:</p>
<p><span id="eq-abs_4"><span class="math display">\[
\begin{align}
    L(s) = L_0 e^{-\sigma_a s}.
\end{align}
\tag{10.4}\]</span></span></p>
<p>where <span class="math inline">\(L_0 = L(0)\)</span> is the initial radiance of the light before interacting with the particles, as visualized in <a href="#fig-absorption_model" class="quarto-xref">Figure&nbsp;<span>10.2</span></a> (b), <span class="math inline">\(L(s)\)</span> denotes the radiance at a particular length <span class="math inline">\(s\)</span>.</p>
<p><a href="#eq-abs_4" class="quarto-xref">Equation&nbsp;<span>10.4</span></a> allows us to calculate the remaining radiance after the light travels a length <span class="math inline">\(s\)</span>. <a href="#eq-abs_4" class="quarto-xref">Equation&nbsp;<span>10.4</span></a> is called the <strong>Bouguer-Beer-Lambert’s law</strong> (BBL), which is a geometrical optics’ simplification of the electromagnetic theory of light-matter interaction where the matter is purely absorptive <span class="citation" data-cites="mayerhofer2020bouguer">(<a href="references.html#ref-mayerhofer2020bouguer" role="doc-biblioref">Mayerhöfer, Pahlow, and Popp 2020</a>)</span>.</p>
</section>
<section id="an-alternative-derivation" class="level4">
<h4 class="anchored" data-anchor-id="an-alternative-derivation">An Alternative Derivation</h4>
<p>An equivalent way of deriving the BBL law is the following. We divide the entire volume (with a total length of <span class="math inline">\(s\)</span>) into <span class="math inline">\(N\)</span> thin slices, each with a length of <span class="math inline">\(\D s\)</span>. After the first slice, the surviving portion of the initial radiance is <span class="math inline">\(L = L_0(1-\sigma_a \D s)\)</span>, so after going through all the <span class="math inline">\(N\)</span> slices, the remaining radiance is given by:</p>
<p><span id="eq-alt_abs_1"><span class="math display">\[
\begin{align}
    L_N = L_0(1-\sigma_a \D s)^N = L_0(1-\sigma_a \frac{s}{N})^N.
\end{align}
\tag{10.5}\]</span></span></p>
<p>Now when <span class="math inline">\(\D s\)</span> becomes infinitesimally small, <span class="math inline">\(N\)</span> approaches infinity, so the limit of the remaining radiance as a function of the total length <span class="math inline">\(s\)</span> is given in <a href="#eq-alt_abs_2" class="quarto-xref">Equation&nbsp;<span>10.6</span></a>, which is the same as <a href="#eq-abs_4" class="quarto-xref">Equation&nbsp;<span>10.4</span></a>.</p>
<p><span id="eq-alt_abs_2"><span class="math display">\[
\begin{align}
    L(s) = \lim_{N \rightarrow \infty}L_0(1-\sigma_a \frac{s}{N})^N = L_0 e^{-\sigma_a s}.
\end{align}
\tag{10.6}\]</span></span></p>
</section>
</section>
<section id="absorption-coefficient" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="absorption-coefficient"><span class="header-section-number">10.2.2</span> Absorption Coefficient</h3>
<p>The absorption coefficient is an important measure of the medium’s ability to absorb photons. It has a unit of <span class="math inline">\(\text{m}^\text{-1}\)</span>, which means it is not bound by 0 and 1. One way to interpret the absorption coefficient is to observe that <span class="math inline">\(\sigma_a \d s = \d L/L\)</span>, which is the fraction of the radiance absorbed or the probability of light absorption by an infinitesimal slice. So <span class="math inline">\(\sigma_a = (\d L/L)/\d s\)</span> can be interpreted as the probability <em>density</em> of photon absorption, i.e., the probability of absorption per unit length traveled:</p>
<p><span class="math display">\[
\begin{align}
    \sigma_a = \lim_{\D s \rightarrow 0} \frac{\D L}{L}/\D s = \frac{\d L}{L \d s}.
\end{align}
\]</span></p>
<p>Like any density measure, absorption coefficient is most useful when it is integrated: when we integrate <span class="math inline">\(\sigma_a\)</span> over the length that light travels, we get the fraction/percentage of the light absorbed. One can also show that <span class="math inline">\(1/\sigma_a\)</span> is the expected value of the distance a photon can travel before being absorbed <span class="citation" data-cites="bohren2006fundamentals">(<a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">Bohren and Clothiaux 2006</a>, Chpt. 5.1.3)</span>; this quantity is given the name <strong>mean free path</strong> (l). To derive <span class="math inline">\(l\)</span>, observe that the probability that a photon is absorbed after traveling a distance <span class="math inline">\(s\)</span> is <span class="math inline">\(1-e^{-\sigma_as}\)</span>. So the probability <em>density</em> of absorption as a function of the distance <span class="math inline">\(s\)</span> is:</p>
<p><span class="math display">\[
\begin{align}
    f(s) = \frac{\text{d}(1-e^{-\sigma_a s})}{\text{d}s} = \sigma_ae^{-\sigma_a s}.
\end{align}
\]</span></p>
<p>So the expected value of <span class="math inline">\(s\)</span>, which we can interpret as the distance a photon can travel on average before being absorbed, is:</p>
<p><span id="eq-mfp"><span class="math display">\[
\begin{align}
    l = \int_0^\infty sf(s)\text{d}s = 1/\sigma_a.
\end{align}
\tag{10.7}\]</span></span></p>
</section>
<section id="sec-chpt-mat-vs-abs-quan" class="level3" data-number="10.2.3">
<h3 data-number="10.2.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-abs-quan"><span class="header-section-number">10.2.3</span> A Few Important Quantities</h3>
<p>We can now define a few other commonly used quantities (omitting the wavelength dependence for simplicity). The <strong>transmittance</strong> <span class="math inline">\(T\)</span> of a volume with a total thickness of <span class="math inline">\(s\)</span> is defined as the percentage of the transmitted/unabsorbed photons after traveling the length of <span class="math inline">\(s\)</span> (<a href="#eq-trans" class="quarto-xref">Equation&nbsp;<span>10.8</span></a>): <span id="eq-trans"><span class="math display">\[
\begin{align}
    T = \frac{L(s)}{L_0} = e^{-\sigma_a s}.
\end{align}
\tag{10.8}\]</span></span></p>
<p>The <strong>absorbance</strong> <span class="math inline">\(A\)</span> is the product of <span class="math inline">\(\sigma_a s\)</span>: <span id="eq-absorbance"><span class="math display">\[
\begin{align}
    A = -\ln T = \ln\frac{L(s)}{L_0} = \sigma_a s.
\end{align}
\tag{10.9}\]</span></span></p>
<p>The <strong>absorptance</strong> <span class="math inline">\(a\)</span> of a volume is defined as the percentage of the absorbed photons by the volume, which relates to <span class="math inline">\(T\)</span> and <span class="math inline">\(A\)</span> by <a href="#eq-absorbance" class="quarto-xref">Equation&nbsp;<span>10.9</span></a>: <span id="eq-absorptance"><span class="math display">\[
\begin{align}
    a = 1 - T = 1 - e^{-A}.
\end{align}
\tag{10.10}\]</span></span></p>
<p>We have seen these definitions in <a href="hvs-receptor.html#sec-chpt-hvs-receptor-absorb-msp" class="quarto-xref"><span>Section 3.2.1</span></a>. One very nice thing about the absorbance <span class="math inline">\(A\)</span> is that it is approximately equivalent to absorptance <span class="math inline">\(a\)</span> when <span class="math inline">\(A\)</span> is small (which would be true when, e.g., the length <span class="math inline">\(s\)</span> is very small, as is the case when discussing how a photoreceptor absorbs photons when illuminated transversely).</p>
<p>Another nice thing about absorbance is that absorbances add, because <em>absorption coefficients add</em>. Imagine you have <span class="math inline">\(n\)</span> kinds of particles mixed up in a medium, each with a different absorption coefficient <span class="math inline">\(\sigma_a^i\)</span>. The overall absorbance of the medium is the sum of the individual absorbance <span class="math inline">\(A^i\)</span> derived as if the medium is made up of only one kind of particles. That is: <span id="eq-absorbances_add"><span class="math display">\[
\begin{align}
    A = \sum_i^n A^i = s\sum_i^n\sigma_a^i = s\sum_i^n c^i\epsilon^i,
\end{align}
\tag{10.11}\]</span></span></p>
<p>where <span class="math inline">\(c^i\)</span> and <span class="math inline">\(\epsilon^i\)</span> are the concentration and absorption cross section of the <span class="math inline">\(i^{th}\)</span> particles. Specifically, <span class="math inline">\(c^i\)</span> is defined as: <span class="math display">\[
\begin{align}
    c^i = \frac{n_i}{V},
\end{align}
\]</span></p>
<p>where <span class="math inline">\(n_i\)</span> is the number of the <span class="math inline">\(i^{th}\)</span> kind of particles in the material, and <span class="math inline">\(V\)</span> is the material volume.</p>
<p>This is not a surprising result. As long as particles in a thin slice of this new heterogeneous medium do not cover each other, we can easily extend <a href="#eq-abs_1" class="quarto-xref">Equation&nbsp;<span>10.1</span></a> and the rest of the derivation to consider multiple kinds of particles; eventually <a href="#eq-absorbances_add" class="quarto-xref">Equation&nbsp;<span>10.11</span></a> would be a natural conclusion. We will omit the derivation here for simplicity sake.</p>
<p><a href="#eq-absorbances_add" class="quarto-xref">Equation&nbsp;<span>10.11</span></a> is a nice conclusion to have, because usually we <em>are</em> dealing with hybrid media. For instance, paint is a mixture of binder particles and pigment particles, and a mist is a mixture of water droplets and air particles. <!-- %\fixme{true to model this way? how to model a suspension of particles?} --> If we do not want to model individual matters, we can use a single absorption coefficient to describe the aggregate behavior of the mixture. That absorption coefficient does have a physical meaning: it is the concentration-weighted sum of the individual absorption coefficients.</p>
<p>There are a bunch of other quantities defined in the literature. The state of the definitions is a bit of a mess, largely because different communities use different definitions.</p>
<ul>
<li><p>In visual neuroscience people sometimes use a quantity called <strong>specific absorbance</strong> (see, e.g., <span class="citation" data-cites="bowmaker1980visual">Bowmaker and Dartnall (<a href="references.html#ref-bowmaker1980visual" role="doc-biblioref">1980</a>)</span>), which is the absorbance per unit length <span class="math inline">\(\frac{A}{s}\)</span>. Whenever you see a quantity that starts with the word “specific”, chances are that the quantity is defined per unit length. You can see that specific absorbance is actually just our absorption coefficient.</p></li>
<li><p>In scientific communities, especially chemistry and spectroscopy, people define <span class="math inline">\(\epsilon\)</span>, rather than <span class="math inline">\(c\epsilon\)</span>, to be the absorption coefficient. You can see the appeal of doing that — <span class="math inline">\(\epsilon\)</span> is a more fundamental measure of a medium’s ability to absorb photons, independent of the particle concentration <span class="math inline">\(c\)</span> (and certainly independent of the traversal length <span class="math inline">\(s\)</span>).</p></li>
<li><p>The absorbance defined in <a href="#eq-absorbance" class="quarto-xref">Equation&nbsp;<span>10.9</span></a> is technically called the <strong>Naperian absorbance</strong>, because we take the natural logarithm of <span class="math inline">\(T\)</span>. Sometimes people also use the <strong>decadic absorbance</strong>, which is defined as <span class="math inline">\(-\log T\)</span>. This quantity is also called the <strong>optical density</strong>.</p></li>
<li><p>Finally, the number concentration <span class="math inline">\(c\)</span> here is defined in terms of the absolute quantity per unit volume, but sometimes people want to define <span class="math inline">\(c\)</span> as the <strong>molar concentration</strong>, which is the number of moles per unit volume. If so, all other derived quantities are then prefixed with “molar”. Next time when you see something like the <strong>molar decadic absorption coefficient</strong>, you know what it is!</p></li>
</ul>
<p>The annoying thing is that people do not always tell you which definition they use. The plea I have to you is to be specific about which definition <em>you</em> use in your writing and tell me when I am being vague!</p>
</section>
<section id="general-case" class="level3" data-number="10.2.4">
<h3 data-number="10.2.4" class="anchored" data-anchor-id="general-case"><span class="header-section-number">10.2.4</span> General Case</h3>
<p>So far we have assumed that the absorption coefficient <span class="math inline">\(\sigma_a = c\epsilon\)</span> is a constant regardless of the position <span class="math inline">\(p\)</span> in the medium and along any direction <span class="math inline">\(\omega\)</span>. The former property assumes that the medium is uniform, and the latter property is called <strong>isotropic</strong><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> in that the medium’s ability to absorb photons is independent of the light direction.</p>
<p>Both assumptions are problematic in practice. The concentration can change spatially and should be denoted <span class="math inline">\(c(p)\)</span>, where <span class="math inline">\(p\)</span> is an arbitrary position in space. <span class="math inline">\(\epsilon\)</span> can also change with <span class="math inline">\(p\)</span> and, more importantly, change with the direction of light incidence <span class="math inline">\(\omega\)</span>. For instance, the particles might not be spherical, so their geometrical cross-sectional area and, thus, the cross section <span class="math inline">\(\epsilon\)</span> available for absorbing photons can depend on <span class="math inline">\(\omega\)</span>. As a result, the absorption coefficient should generally be denoted <span class="math inline">\(\sigma_a(p, \omega)\)</span>.</p>
<div id="fig-absorption_model_general" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-absorption_model_general-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/absorption_model_general.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-absorption_model_general-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.3: A conceptual model to help reason about photon absorption in the general case, where the absorption coefficient can vary spatially and directionally. The medium is divided into many tiny elemental volumes, each of which is so small that particles do not cover each from any direction.
</figcaption>
</figure>
</div>
<p>Effectively, our conceptual model, shown in <a href="#fig-absorption_model_general" class="quarto-xref">Figure&nbsp;<span>10.3</span></a>, has to be changed to one where the entire body of particles is divided into many equally-sized volumes (with a length <span class="math inline">\(\D s\)</span> and an area <span class="math inline">\(\D A\)</span>), each of which is so small that particles do not cover each other from any direction. The radiance reduction per unit length in a small volume is then expressed as:</p>
<p><span id="eq-abs_dif_cont"><span class="math display">\[
\begin{align}
    \frac{\D L(p, \omega)}{\D s} = -\sigma_a(p, \omega)L.
\end{align}
\tag{10.12}\]</span></span></p>
<p>Given this model, we can calculate the exitant radiance after light travels a length <span class="math inline">\(s\)</span> through the medium:</p>
<p><span id="eq-abs_cont"><span class="math display">\[
\begin{align}
    L(p+s\omega, \omega) = L(p, \omega) e^{-\int_0^s \sigma_a(p+t\omega, \omega) \d t},
\end{align}
\tag{10.13}\]</span></span></p>
<p>where <span class="math inline">\(\omega\)</span> is the (unit) direction of the incident radiance, <span class="math inline">\(L(p, \omega)\)</span> is the incident radiance, and <span class="math inline">\(L(p+s\omega, \omega)\)</span> is the exitance radiance (radiance toward <span class="math inline">\(\omega\)</span> leaving the entire medium after traveling <span class="math inline">\(s\)</span>).</p>
<p>You would notice that for a beam with an oblique incident direction, the distance traveled, say <span class="math inline">\(\D s'\)</span>, can be different (longer or shorter than) from <span class="math inline">\(\D s\)</span>. Our model can account for this by folding the factor <span class="math inline">\(\D s'/\D s\)</span> specific to a particular direction <span class="math inline">\(\omega'\)</span> into the absorption coefficient <span class="math inline">\(\sigma_a(p, \omega')\)</span>. Note that the <span class="math inline">\(\D s'/\D s\)</span> factor should be the average for all the incident photons with the same direction <span class="math inline">\(\omega'\)</span> across the entire <span class="math inline">\(\D A\)</span>.</p>
</section>
<section id="nature-and-applicability-of-the-model" class="level3" data-number="10.2.5">
<h3 data-number="10.2.5" class="anchored" data-anchor-id="nature-and-applicability-of-the-model"><span class="header-section-number">10.2.5</span> Nature and Applicability of the Model</h3>
<p>The absorption model (the BBL law) derived before (<a href="#eq-abs_4" class="quarto-xref">Equation&nbsp;<span>10.4</span></a> and <a href="#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>10.13</span></a>) is a continuous one, but it is derived based on modeling discrete particles and events. It is another example of the modeling methodology discussed on <a href="rendering-surface.html#sec-chpt-mat-ss-para-model" class="quarto-xref"><span>Section 9.5.1</span></a>.</p>
<p><a href="#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>10.13</span></a> seems to suggest that absorption coefficient <span class="math inline">\(\sigma_a(p, \omega)\)</span> is continuously defined at any position <span class="math inline">\(p\)</span> in the medium along any direction <span class="math inline">\(\omega\)</span>. It is not true. For starters, concentration <span class="math inline">\(c\)</span> is not continuous. Rather, it exhibits the triphasic profile shown in <a href="rendering-surface.html#fig-model_scale" class="quarto-xref">Figure&nbsp;<span>9.2</span></a>. As we keep shrinking the size of the volume to the molecular scale, eventually the concentration depends on whether the tiny volume contains any molecules or not, so it becomes wildly discontinuous, not to mention the headache of dealing with a partial molecule in a volume — should it be counted or not? In general, the absorption coefficient can be an arbitrary discontinuous function that is not integrable.</p>
<p>What about <a href="#eq-abs_4" class="quarto-xref">Equation&nbsp;<span>10.4</span></a> where the absorption coefficient is uniform so we do not have to take the integral? Well, that is a lie too: concentration is not continuous, so it cannot be uniform everywhere, and, by extension, the absorption coefficient cannot be a constant everywhere either. So <a href="#eq-abs_3" class="quarto-xref">Equation&nbsp;<span>10.3</span></a> is technically wrong when we let <span class="math inline">\(\D s \rightarrow 0\)</span> (i.e., <span class="math inline">\(N \rightarrow \infty\)</span>), which is necessary for us to construct the differential equation (or take the limit in <a href="#eq-alt_abs_2" class="quarto-xref">Equation&nbsp;<span>10.6</span></a>). For <a href="#eq-abs_3" class="quarto-xref">Equation&nbsp;<span>10.3</span></a> to be true, the concentration/absorption coefficient must be a constant everywhere, which can be true only if the volume is continuous.</p>
<p>What has to happen is that the limit of <span class="math inline">\(\D s\)</span> cannot be literally 0 and the limit of <span class="math inline">\(N\)</span> cannot be infinity. What we do is to keep reducing <span class="math inline">\(\D s\)</span> to the point where the concentration (and thus absorption coefficient) is insensitive to slight perturbation of <span class="math inline">\(\D s\)</span> (i.e., operating in the stable range in <a href="rendering-surface.html#fig-model_scale" class="quarto-xref">Figure&nbsp;<span>9.2</span></a>), and call it the concentration/absorption coefficient of that specific <span class="math inline">\(\D s\)</span>. And we repeat this for all the <span class="math inline">\(\D s\)</span>. This certainly applies to the general-case models in <a href="#eq-abs_dif_cont" class="quarto-xref">Equation&nbsp;<span>10.12</span></a> and <a href="#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>10.13</span></a>, where we iterate over not the thin slices <span class="math inline">\(\D s\)</span> but all the tiny volumes (<span class="math inline">\(\D A \times \D s\)</span>). So all the integral symbols are secretly summing over an extremely fine-grained grid.</p>
<p>How big of an error are we introducing here? Technically, we should sum all <span class="math inline">\(N\)</span> slices across the total traversal length <span class="math inline">\(s\)</span> in <a href="#eq-alt_abs_1" class="quarto-xref">Equation&nbsp;<span>10.5</span></a>. If we assume <span class="math inline">\(\D s\)</span> to be very small (even though not infinitesimal) compared to <span class="math inline">\(s\)</span>, <span class="math inline">\(N\)</span> would be large, so taking the integration (equivalent to letting <span class="math inline">\(N \rightarrow \infty\)</span>) would be very close to summing over <span class="math inline">\(N\)</span>. Similarly, the integral in should have been a summation of the concentration in each of the <span class="math inline">\(N\)</span> slices. If you want to be pedantic, however, the integration there is exact: we can model <span class="math inline">\(c\)</span> as a piece-wise function, where the value at each piece is the concentration of the corresponding volume. Integrating over a piece-wise function is the same as summing all the pieces. Only the exponential expression in <a href="#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>10.13</span></a> is inexact.</p>
<p>The discontinuity of the medium is, of course, orthogonal to the discontinuity and non-uniformity in the light field itself. For instance, the fact that we use <span class="math inline">\(\frac{cE\D l\epsilon}{E}\)</span> as the percentage of photon absorption in <a href="#eq-abs_1" class="quarto-xref">Equation&nbsp;<span>10.1</span></a> (and implicitly in <a href="#eq-abs_4" class="quarto-xref">Equation&nbsp;<span>10.4</span></a>) assumes that the irradiance of the incident illumination is continuous and uniform in the small volume. This is technically not true because photons are discrete packets of energy. But in practice this is not a concern because we can assume that there is an enormous amount of photons incident on the small volume, and these photons are randomly distributed. <!-- %on the same point, Bohren p. 110 ``Implicit in the definition of cross sections is that the irradiance of the incident illumination be constant over lateral dimensions large compared with the size of the particle.'' --></p>
<p>In essence, we are using the aggregated behavior of many photons to model the behavior of a small volume. This is similar to the microfacet models, where we use the aggregated behavior of many microfacets to statistically model the behavior of a small macro-surface.</p>
<p>This sort of modeling strategy is a weird case where the discrete model provides the “ground truth”, which is approximated by a continuous model. I say ground truth — to the extent that the geometrical optics can approximate the electromagnetic theory of light-matter interaction. The BBL law fails when the wave nature of photons has to be considered <span class="citation" data-cites="mayerhofer2020bouguer">(<a href="references.html#ref-mayerhofer2020bouguer" role="doc-biblioref">Mayerhöfer, Pahlow, and Popp 2020</a>)</span>.</p>
<!-- \fixme{talk about distribution of the particles. they can't be non-random: two extreme cases.} -->
</section>
</section>
<section id="sec-chpt-mat-vs-sca" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-sca"><span class="header-section-number">10.3</span> Scattering</h2>
<p>Scattering is much more difficult to reason about than absorption, primarily because a scattered photon is not “dead” and continues to participate in light-matter interaction. The way to study scattering is to first understand the behavior of a single scattering event and then consider the overall behavior of a large of collection of particles.</p>
<p>This section focuses a single scattering event (<a href="#sec-chpt-mat-vs-sca-single" class="quarto-xref"><span>Section 10.3.2</span></a>), and the next section discusses the general case where a large collection of particles interacts with photons. Before all these, though, it is useful to first build some intuitions as to why there is a distinction between a single scattering event and scattering by a particle collection and explicitly lay out the assumptions made for the rest of our discussions (<a href="#sec-chpt-mat-vs-sca-intuition" class="quarto-xref"><span>Section 10.3.1</span></a>).</p>
<section id="sec-chpt-mat-vs-sca-intuition" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-intuition"><span class="header-section-number">10.3.1</span> Scattering by a Particle vs.&nbsp;a Collection of Particles</h3>
<p>In geometric optics terms, scattering can be thought of as an event that takes place between a photon and a particle. In the real world, however, objects and media are usually made of a large collection of particles, which introduces two complications: multiple scattering and interference.</p>
<section id="multiple-scattering" class="level4">
<h4 class="anchored" data-anchor-id="multiple-scattering">Multiple Scattering</h4>
<p>First, it is possible that a scattered photon, after traveling a certain distance, meets another particle and gets scattered again. This makes it considerably more difficult to analyze the effect of scattering by a medium than does the scattering of a single particle.</p>
<div id="fig-haze_scattering" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-haze_scattering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/haze_scattering.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-haze_scattering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.4: Left: The atmospheric scattering of the sand coming from the Sahara during Harmattan glows in the sun and gives a hazy view of the remote mountains. Nigeria’s National Mosque is in the foreground; from . Right: illustrations of the glow of the sun and the haze. Both are due to scattering, and the difference is purely visual but not fundamental.
</figcaption>
</figure>
</div>
<p>Look at <a href="#fig-haze_scattering" class="quarto-xref">Figure&nbsp;<span>10.4</span></a> (left) taken during Harmattan, where the atmosphere is full of sand and dust blown from the Sahara. The large collection of particles in the atmosphere scatters light, glowing the sun and giving the remote mountains a hazy view. The right panel illustrates the scattering events that give rise to the glow and the haze.</p>
<p>Without scattering, sunlight enters the eye directly. With scattering, some photons from the sun are first knocked out of the view and could potentially be then scattered again back to the eye. Some photons that enter the eye might even come from nearby objects other than the sun. The scattering creates a glow around the sun, and, for the observer, the sun appears larger than it actually is. The hazy view of the mountains is created by exactly the same scattering processes. The photons that enter the eyes are mixed up from different parts of the mountains and from other objects. The mountains appear hazy rather than glowing as the sun does simply because the sun has a higher brightness contrast against the background than does a region on the mountain. So the distinction between “glow” and “haze” is nothing more than a visual difference at a superficial level rather than anything deeper in physics.</p>
<p>You can see why multiple scattering by large collections of particles poses challenges to our analysis. If a photon is scattered once in the medium, the only effect of scattering would be to knock photons out of our line of sight, and thus, remote objects would only look dimmer rather than hazy. In this case, scattering would function exactly like absorption, for modeling purposes at least. With multiple scattering, we have to track not only photons that are scattered out but also photons that are scattered into the rays that enter our eyes<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. This is a daunting task considering that we are usually dealing with millions of particles and billions of photons, if not more.</p>
<p>If you want to be absolutely pedantic, we can distinguish the following cases:</p>
<ul>
<li>a single scattering event, where a photon meets a particle and is scattered away;</li>
<li>single scattering, where a photon is scattered <em>once</em> by a medium (a large collection of photons), which is under
<ul>
<li>a collimated illumination, so the radiance of a ray can only be weakened because photons are scattered to other directions,</li>
<li>an arbitrary illumination, so the radiance of a ray can be both weakened and augmented (by photons scattered from other directions);</li>
</ul></li>
<li>multiple scattering, where a photon is scattered <em>multiple times</em> by a medium, so the radiance of a ray can both be weakened and augmented.</li>
</ul>
<p><a href="#sec-chpt-mat-vs-sca-single" class="quarto-xref"><span>Section 10.3.2</span></a> studies Case 1 and Case 2(a) together, because the latter is the statistical consequence of the former. <a href="#sec-chpt-mat-vs-rte" class="quarto-xref"><span>Section 10.4</span></a> studies Case 2(b) and Case 3 together because they have the same observable effects and, thus, are modeled in the same way.</p>
</section>
<section id="interference-and-coherence" class="level4">
<h4 class="anchored" data-anchor-id="interference-and-coherence">Interference and Coherence</h4>
<p>Second, when there is a large collection of particles, the scattered radiation fields of individual particles can interfere with each other. The exact impact of interference can only be calculated by considering the wave nature of the light. But to the first order, the inference depends on how densely packed the particles are.</p>
<p>In fact, the specular surface scattering we discussed in <a href="rendering-surface.html#sec-chpt-mat-ss-mat" class="quarto-xref"><span>Section 9.4</span></a> is just a macroscopic approximation of the microscopic volume scattering where particles interfere non-randomly. In a mirror or a glass of water, the particles/molecules are very densely packed to the point that the distance between two particles is smaller than the wavelength of the light. As a result, the scattering is <em>coherent</em>, which gives rise to the <em>illusion</em> of a specular surface. One can show that the Fresnel equations are the solution to the Maxwell’s equations when surface particles are densely packed.</p>
<p>Why would the particle density matter? If particles are very close to each other, their radiation fields are close too, so the interference is stronger and cannot be ignored. More importantly, when particles are close to each other, their spatial positions can no longer be treated as random, so the interference can become coherent. Imagine you drop particles into a vast empty space; the particle sizes are much smaller relative to the space, so their spatial distribution can be roughly described as random. But if the particles are very densely packed, where the next particle can be is very much restrained, so their positions are highly correlated, leading to coherent scattering.</p>
<p>We will generally assume <strong>incoherent scattering</strong> unless otherwise noted, where individual scattering events interfere each other in random ways, so we are spared of the complication of thinking of the wave nature of the photons. Under this assumption, the total power scattered by a collection of particles is the same as the sum of the power scattered by the individual particles. This happens when the particles are sufficient sufficiently distant (separated by more than multiple wavelengths) and their spatial arrangements are uncorrelated.</p>
<!-- %according to bohren and huffman p. 9, it's possible that particles are sufficiently apart but they are still not randomly positioned so their scattered fields can still interfere in a coherent way.
%when they say single scattering, they just mean particles are very apart, and their multiple scattering means particles are close.
%this definition is technically precise but can be weird since if particles are apart even if they interfere the effect is weak.
%so in our definition (and many others) here we assume that incoherent scattering means particles are both sufficiently apart and sufficiently randomly positioned so that individual scatterings are independent of each other. -->
</section>
</section>
<section id="sec-chpt-mat-vs-sca-single" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-single"><span class="header-section-number">10.3.2</span> A Single Scattering Event</h3>
<section id="sec-chpt-mat-vs-sca-single-coeff" class="level4">
<h4 class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-single-coeff">Scattering Efficiency and Coefficient</h4>
<p>Intuitively, scattering has a similar effect as absorption: it weakens the radiance by taking photons away from a beam of light. The difference is that scattered photons are not dead; they are re-directed to other directions. We can define two important quantities, one to characterize a <em>particle</em>’s ability to scatter photons and the other to characterize a <em>medium</em>’s ability to scatter photons.</p>
<p>Similar to the situation in absorption, the intrinsic capability of a particle to scatter photons is defined by the particle’s <strong>scattering cross section</strong> <span class="math inline">\(\epsilon_s\)</span>, which itself is the product of the geometrical cross-sectional area of the particle <span class="math inline">\(\epsilon_g\)</span> and the <strong>scattering efficiency</strong> <span class="math inline">\(Q_s\)</span>. We can then define the <strong>scattering coefficient</strong> <span class="math inline">\(\sigma_s\)</span> of a medium (a large collection of particles), which characterizes the ability of the medium to scatter photons away from its incident radiance. <span class="math inline">\(\sigma_s\)</span> is the product of the particle concentration of the medium <span class="math inline">\(c\)</span> and the particle’s scattering cross section <span class="math inline">\(\epsilon_s\)</span>. Again, <span class="math inline">\(\sigma_s\)</span> has a unit <span class="math inline">\(\text{m}^\text{-1}\)</span> and is not bound by 0 and 1; it is best interpreted as the probability density (i.e., probability per unit length) of light being scattered away. Of course, both the scattering efficiency and scattering coefficient can vary spatially, angularly, and spectrally.</p>
<p>The effects of scattering and absorption add up, because they both weaken a radiance. We can extend <a href="#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>10.13</span></a> to consider scattering (again omitting the wavelength from the equations):</p>
<p><span id="eq-scat_cont"><span class="math display">\[
\begin{align}
    L(p+s\omega, \omega) = L(p, \omega) e^{-\int_0^s (\sigma_a(p+t\omega, \omega) + \sigma_s(p+t\omega, \omega)) \d t},
\end{align}
\tag{10.14}\]</span></span></p>
<p>where <span class="math inline">\(\sigma_s(p, \omega)\)</span> is the scattering coefficient at <span class="math inline">\(p\)</span> toward the direction <span class="math inline">\(\omega\)</span>.</p>
<p>Rearranging the terms, we can express the <strong>transmittance</strong> between <span class="math inline">\(p\)</span> and <span class="math inline">\(p+s\omega\)</span> along the direction <span class="math inline">\(\omega\)</span>, denoted <span class="math inline">\(T(p \rightarrow p+s\omega)\)</span>: <span id="eq-transmittance"><span class="math display">\[
\begin{align}
    T(p \rightarrow p+s\omega) = \frac{L(p+s\omega, \omega)}{L(p, \omega)} = e^{-\int_0^s (\sigma_a(p+t\omega, \omega) + \sigma_s(p+t\omega, \omega)) \d t}.
\end{align}
\tag{10.15}\]</span></span></p>
<p><a href="#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>10.14</span></a> can be derived using the same idea as that used for deriving the absorption equation in <a href="#sec-chpt-mat-vs-abs-simple" class="quarto-xref"><span>Section 10.2.1</span></a> by modeling a thin layer <span class="math inline">\(\D x\)</span> — with an additional assumption that <span class="math inline">\(\D x\)</span> is so thin that a photon is scattered at most once before leaving <span class="math inline">\(\D x\)</span>. Therefore, scattering by a single particle has the same effect as absorption: they both take the photon out of the radiance, and that is why the absorption equation (<a href="#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>10.13</span></a>) can be directly extended here.</p>
<p>Think of the applicability of <a href="#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>10.14</span></a>: it says that the radiance of a ray can only be weakened. If the incident light has only one direction (e.g., a collimated beam), <a href="#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>10.14</span></a> is true when a photon is scattered at most once in the medium. This is because a scattered photon will not have a chance to get back to the ray. If the incident light is not mono-directional, e.g., diffuse illumination, <a href="#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>10.14</span></a> in general does not apply — even if we consider only single scattering. This is because photons originally not along the direction <span class="math inline">\(\omega\)</span> can be scattered toward it through just one single scattering event. We can see how limited <a href="#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>10.14</span></a> is: it applies only when the illumination is collimated and we assume only single scattering. We will relax this constraint later. <!-- %same as the text above Equ 3.108 in Bohren. --></p>
<p>Just like the absorption case (<a href="#eq-absorbances_add" class="quarto-xref">Equation&nbsp;<span>10.11</span></a>), if a medium is mixed with different particles, each with a different scattering coefficient, the overall scattering coefficient is the sum of the individual scattering coefficients as if the medium is made up of a particular kind of particles.</p>
<p>The sum of the scattering coefficient and absorption coefficient is called the <strong>extinction coefficient</strong> or <strong>attenuation coefficient</strong>, denoted <span class="math inline">\(\sigma_t(p, \omega)\)</span>:</p>
<p><span class="math display">\[
\begin{align}
    \sigma_t(p, \omega) = \sigma_a(p, \omega) + \sigma_s(p, \omega).
\end{align}
\]</span></p>
<p>The ratio between the scattering coefficient and the attenuation coefficient is called the <strong>single-scattering albedo</strong> of the medium:</p>
<p><span class="math display">\[
\begin{align}
    \rho = \frac{\sigma_s(p, \omega)}{\sigma_t(p, \omega)}.
\end{align}
\]</span></p>
<p>This albedo can be seen as the volumetric counterpart of the surface albedo discussed in <a href="rendering-surface.html#eq-albedo_1" class="quarto-xref">Equation&nbsp;<span>9.11</span></a>. The two forms of albedo have the same physical meaning: the fraction of the incident energy that is scattered away (i.e., not absorbed). A dark medium (e.g., smoke) has a lower albedo, and a bright medium (e.g., mist) has a higher albedo.</p>
<p>The sum of the scattering and absorption cross sections is called the <strong>extinction cross section</strong> or <strong>attenuation cross section</strong>, denoted <span class="math inline">\(\epsilon_t = \epsilon_a + \epsilon_s\)</span>. And of course <span class="math inline">\(1/\sigma_t\)</span> is the mean free path in a medium where both absorption and scattering take place, i.e., the mean distance a photon can travel without being absorbed or scattered away.</p>
</section>
</section>
<section id="sec-chpt-mat-vs-sca-single-pf" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-single-pf"><span class="header-section-number">10.3.3</span> Scattering Direction Distribution: Phase Function</h3>
<p>While the scattering efficiency (coefficient) characterizes how well a particle (medium) is able to scatter photons, it tells us nothing about the <em>direction</em> of scattering. The direction of a single scattering event is characterized by the <strong>phase function</strong> <span class="math inline">\(f_p(p, \os, \oi)\)</span>, which can be interpreted as the probability <em>density</em> function that a photon incident from a direction <span class="math inline">\(\oi\)</span> is scattered toward a direction <span class="math inline">\(\os\)</span>. We will omit <span class="math inline">\(p\)</span> and write the phase function as <span class="math inline">\(f_p(\os, \oi)\)</span> when the discussion is unconcerned of <span class="math inline">\(p\)</span>.</p>
<p><span class="math inline">\(f_p(\os, \oi)\)</span> is defined as the fraction of the irradiance incident from an infinitesimal solid angle <span class="math inline">\(\doi\)</span> that is scattered toward an infinitesimal solid angle <span class="math inline">\(\dos\)</span> per unit solid angle:</p>
<p><span id="eq-phase_func_def"><span class="math display">\[
\begin{align}
    f_p(\os, \oi) = \lim_{\Dos \rightarrow 0} \lim_{\Doi \rightarrow 0} \frac{\D E_o(\os)}{\D E_i(\oi)} / \Dos = \frac{\d^2 E_o(\os)}{\d E_i(\oi)\dos} = \frac{\d^2 E_o(\os)}{L(\oi) \doi \dos}.
\end{align}
\tag{10.16}\]</span></span></p>
<p><span class="math inline">\(\D E_i(\oi)\)</span> is the incident irradiance over a small solid angle <span class="math inline">\(\Doi\)</span> and scatters in all directions. <span class="math inline">\(\D E_o(\oi)\)</span> is the outgoing irradiance over a small solid angle <span class="math inline">\(\Dos\)</span>, so <span class="math inline">\(\frac{\D E_o(\os)}{\D E_i(\oi)}\)</span> is the fraction of the photons incident from <span class="math inline">\(\Doi\)</span> that are scattered over <span class="math inline">\(\Dos\)</span> or, alternatively, the probability that a photon incident from <span class="math inline">\(\Doi\)</span> is scattered toward <span class="math inline">\(\Dos\)</span>; this ratio/fraction is clearly a value between 0 and 1. Dividing that fraction by <span class="math inline">\(\Dos\)</span> gets us the probability per unit solid angle. When both the incident solid angle <span class="math inline">\(\Doi\)</span> and the outgoing solid angle <span class="math inline">\(\Dos\)</span> approach 0, the fraction can be interpreted as the directional-directional reflectance (<a href="rendering-surface.html#sec-chpt-mat-ss-reflectance" class="quarto-xref"><span>Section 9.2</span></a>), and the probability per solid angle within <span class="math inline">\(\Dos\)</span> becomes the probability <em>density</em> toward <span class="math inline">\(\os\)</span>.</p>
<p>Like all density functions, the meaning of a phase function is most clear when it is integrated to compute some other quantity. Integrating <a href="#eq-phase_func_def" class="quarto-xref">Equation&nbsp;<span>10.16</span></a> over all the outgoing directions <span class="math inline">\(\os\)</span>:</p>
<p><span id="eq-energy_con_phase_func_1"><span class="math display">\[
\begin{align}
    \d E_o &amp;= \int^{\Omega = 4\pi} f_p(\os, \oi)L(\oi)\doi\dos \label{eq:energy_con_phase_func_1a} \\
    &amp;= L(\oi)\doi\int^{\Omega = 4\pi} f_p(\os, \oi)\dos \label{eq:energy_con_phase_func_1b} \\
    &amp;= \d E_i\int^{\Omega = 4\pi} f_p(\os, \oi)\dos \label{eq:energy_con_phase_func_1c}.
\end{align}
\tag{10.17}\]</span></span></p>
<p>To interpret this integration, consider a point that receives an incident radiance of <span class="math inline">\(L(\oi)\)</span> over an infinitesimal solid angle <span class="math inline">\(\doi\)</span>. The point receives a total irradiance of <span class="math inline">\(\d E_i = L(\oi)\doi\)</span>, which is scattered in all directions. The density of the irradiance scattered toward a particular direction <span class="math inline">\(\os\)</span> is <span class="math inline">\(f_p(\os, \oi)L(\oi)\doi\)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, which when multiplied by <span class="math inline">\(\dos\)</span> gives us the actual irradiance scattered over a small solid angle <span class="math inline">\(\dos\)</span> around <span class="math inline">\(\os\)</span>. Integrating all outgoing directions over the entire sphere (<span class="math inline">\(4\pi\)</span>) we have <a href="#eq-energy_con_phase_func_1" class="quarto-xref">Equation&nbsp;<span>10.17</span></a>.</p>
<p>Now, of course, some of the photons in <span class="math inline">\(\d E_i\)</span> might not be scattered; they could be absorbed, or they could simply not hit the cross section of any particle. So technically <span class="math inline">\(\d E_o \leq \d E_i\)</span> in <a href="#eq-energy_con_phase_func_1" class="quarto-xref">Equation&nbsp;<span>10.17</span></a>, just like how energy conservation is expressed in surface scattering in <a href="rendering-surface.html#eq-energy_con_1" class="quarto-xref">Equation&nbsp;<span>9.8</span></a>. By the convention in the volume scattering literature, however, the phase function is defined such that <span class="math inline">\(\d E_i\)</span> refers to only the portion of the incident irradiance that does get scattered. Therefore, <span class="math inline">\(\d E_o = \d E_i\)</span>, so we have:</p>
<p><span id="eq-energy_con_phase_func_2"><span class="math display">\[
\begin{align}
    \int^{\Omega = 4\pi} f_p(\os, \oi) \dos = \int^{\Omega = 4\pi} f_p(\os, \oi) \doi = 1.
\end{align}
\tag{10.18}\]</span></span></p>
<p>That is, the phase function integrates to 1; the second integral can be derived using the Helmholtz reciprocity (since we are still dealing with geometrical optics):</p>
<p><span class="math display">\[
\begin{align}
    f_p(\oi, \os) = f_p(\os, \oi).
\end{align}
\]</span></p>
<p>One way to interpret the fact that the phase function integrates to 1 is that the phase function is the <em>conditional</em> probability density function of scattering: given that a photon is scattered, what is the probability (density) of scattering to a particular direction?</p>
<section id="phase-function-vs.-brdf" class="level4">
<h4 class="anchored" data-anchor-id="phase-function-vs.-brdf">Phase Function vs.&nbsp;BRDF</h4>
<p>The phase function can be seen as the volumetric counterpart (in the sense that we are talking about volume scattering) of BRDF (<a href="rendering-surface.html#sec-chpt-mat-ss-brdf" class="quarto-xref"><span>Section 9.1</span></a>) — with two differences. First, the definition of the BRDF accounts for absorption, so the BRDF integrates to <em>at most</em> 1, whereas the integral of the phase function is normalized to 1. This difference in definition is born purely of convention.</p>
<p>The second difference is more fundamental. There is no <span class="math inline">\(\cos\theta\)</span> term when using the phase function; see, e.g., <a href="#eq-energy_con_phase_func_1" class="quarto-xref">Equation&nbsp;<span>10.17</span></a>, unlike how the BRDF is used to turn irradiance into radiance (e.g., <a href="rendering-surface.html#eq-energy_con_1" class="quarto-xref">Equation&nbsp;<span>9.8</span></a>). In fact, from <a href="#eq-energy_con_phase_func_1" class="quarto-xref">Equation&nbsp;<span>10.17</span></a> we can see that given a radiance <span class="math inline">\(L(\oi)\)</span> and a solid angle <span class="math inline">\(\doi\)</span>, the irradiance is simply <span class="math inline">\(L(\oi)\doi\)</span> rather than <span class="math inline">\(L(\oi)\cos\theta_i\doi\)</span>. Didn’t we say that there is a cosine fall-off between radiance and irradiance (<a href="rendering-basics.html#sec-chpt-mat-basics-radiometry-radiance" class="quarto-xref"><span>Section 8.3.4</span></a>)?</p>
<p>One intuition that might help is that in volume scattering we are dealing with points, which can receive flux from the entire sphere and have no definition of a normal (because points are dimensionless and shapeless) or, perhaps more conveniently, have a “flexible” normal that changes with the illumination direction and is always facing directly at the illumination. Entertain this thought experiment. We set up a small surface detector at a point and measure the power of the detector; if the incident light is parallel to the surface, the detector would receive no power, but would you say that the <em>point</em> does not receive any light and that the radiation field has no power? Of course not.</p>
<p>The fact that a parallel surface would receive no photons absolutely does not mean the illumination has no power; the radiation field is the same whether it is illuminating a surface or illuminating a point. But if we are modeling a surface, we <em>want</em> our model to say that the power received by the surface is 0, because it matches our phenomenological observation (that a detector arranged that way would receive no recording); when we are modeling a point in volume scattering, we <em>want</em> the point to receive a power as if the point has a “normal” that is directly facing the illumination because, again, this matches our phenomenological observation.</p>
<p>Ultimately, the difference is a conscious choice of modeling strategy even though the underlying physics is exactly the same. That is why models based on BRDF and phase function are phenomenological models. If you deal with electromagnetic theories and QED, you would not have to have this distinction between modeling surface and volume scattering.</p>
<p>With the understanding that there is no cosine fall-off in volume scattering, <a href="#eq-phase_func_def" class="quarto-xref">Equation&nbsp;<span>10.16</span></a> can be re-written as:</p>
<p><span id="eq-phase_func_def2"><span class="math display">\[
\begin{align}
    f_p(\os, \oi) = \frac{\d^2 E_o(\os)}{\d E_i(\oi)\dos} = \frac{\d}{\d E_i(\oi)}\frac{\d E_o(\os)}{\dos} = \frac{\d L_o(\os)}{\d E_i(\oi)} = \frac{\d L_o(\os)}{L_i(\oi)\doi},
\end{align}
\tag{10.19}\]</span></span></p>
<p>where <span class="math inline">\(\d L_o(\os)\)</span> is the infinitesimal outgoing radiance toward <span class="math inline">\(\os\)</span>. In this sense, the phase function operates in exactly the same way as the BRDF (<a href="rendering-surface.html#eq-brdf" class="quarto-xref">Equation&nbsp;<span>9.33</span></a>): they both operate on irradiance and turn infinitesimal irradiance into infinitesimal radiance.</p>
</section>
<section id="sec-chpt-mat-vs-sca-single-pf-iso" class="level4">
<h4 class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-single-pf-iso">Isotropic Medium and Isotropic Scatters</h4>
<p>Given the normalization in the phase function, the scattering efficiency should actually be parameterized as <span class="math inline">\(\bar{Q_s}(p, \os, \oi)\)</span>:</p>
<p><span id="eq-sca_eff_phase"><span class="math display">\[
\begin{align}
    \bar{Q_s}(p, \os, \oi) = Q_s(p, \oi) f_p(p, \os, \oi),
\end{align}
\tag{10.20}\]</span></span></p>
<p>where <span class="math inline">\(Q_s(p, \oi)\)</span> should be be interpreted as the <em>total</em> scattering efficiency at <span class="math inline">\(p\)</span> over all outgoing directions for a given incident direction <span class="math inline">\(\oi\)</span>. Similarly, the scattering coefficient would be expressed as:</p>
<p><span id="eq-sca_coeff_phase"><span class="math display">\[
\begin{align}
    \bar{\sigma_s}(p, \os, \oi) = \sigma_s(p, \oi) f_p(p, \os, \oi),
\end{align}
\tag{10.21}\]</span></span></p>
<p>where <span class="math inline">\(\sigma_s(p, \oi)\)</span> is interpreted as the <em>total</em> scattering coefficient at <span class="math inline">\(p\)</span> over all outgoing directions for a given incident direction <span class="math inline">\(\oi\)</span>.</p>
<div id="fig-phase_function" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-phase_function-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/phase_function.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-phase_function-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.5: Visualizations of common phase functions; adapted from <span class="citation" data-cites="novak2018monte">Novák et al. (<a href="references.html#ref-novak2018monte" role="doc-biblioref">2018</a>)</span>, where <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\bar\omega\)</span> are the incident direction <span class="math inline">\(\oi\)</span> and the outgoing direction <span class="math inline">\(\os\)</span> in our notation, respectively. For an isotropic medium, the phase function depends on only the angle <span class="math inline">\(\theta\)</span> subtended by <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega'\)</span> and is axially symmetric about <span class="math inline">\(\omega\)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-phase_function" class="quarto-xref">Figure&nbsp;<span>10.5</span></a> visualizes a few common phase functions. While <span class="math inline">\(f_p(\cdot)\)</span> is technically a 4D function parameterized by <span class="math inline">\(\os\)</span> and <span class="math inline">\(\oi\)</span>, the phase function of many natural media is 1D and depends only on the angle <span class="math inline">\(\theta\)</span> subtended by <span class="math inline">\(\os\)</span> and <span class="math inline">\(\oi\)</span>. In <a href="#fig-phase_function" class="quarto-xref">Figure&nbsp;<span>10.5</span></a>, the distance of a point on the contour to the center represents the magnitude of the phase function at that particular <span class="math inline">\(\theta\)</span> Consider under what conditions this simplification can be true:</p>
<ul>
<li>First, it says that the phase function does not depend on the absolute incident direction <span class="math inline">\(\oi\)</span> but the relative angle between <span class="math inline">\(\oi\)</span> and <span class="math inline">\(\os\)</span>. To get a visual intuition, see <a href="#fig-phase_function_isotropic" class="quarto-xref">Figure&nbsp;<span>10.6</span></a>; if the phase function is invariant to the photon incident direction <span class="math inline">\(\oi\)</span>, we can, without losing any generality, assign <span class="math inline">\(\oi\)</span> to the <span class="math inline">\(z\)</span>-axis; the scattered direction <span class="math inline">\(\os\)</span> is parameterized by <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>.</li>
<li>Second, it also says the phase function depends on only <span class="math inline">\(\theta\)</span> but not <span class="math inline">\(\phi\)</span>. That is, the phase function is rotationally symmetric about the incident direction <span class="math inline">\(\oi\)</span>. So <span class="math inline">\(f_p(\os, \oi) = f_p(\os', \oi) \neq f_p(\os'', \oi)\)</span>.</li>
</ul>
<div id="fig-phase_function_isotropic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-phase_function_isotropic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/phase_function_isotropic.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-phase_function_isotropic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.6: The phase function of a spherical particle is 1) invariant to the incident direction <span class="math inline">\(\oi\)</span>, which, without losing generality, is taken to be the <span class="math inline">\(z\)</span>-axis here, and 2) also invariant to the azimuthal angle <span class="math inline">\(\phi\)</span> of the outgoing direction <span class="math inline">\(\os\)</span> but depends on the polar angle <span class="math inline">\(\theta\)</span>. So <span class="math inline">\(f_p(\os, \oi) = f_p(\os', \oi) \neq f_p(\os'', \oi)\)</span>. Media consisting of such particles are called isotropic media, but it does not mean the particle itself is an isotropic scatterer, which does not exist, but if it did, its phase function would be a constant (invariant to both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>).
</figcaption>
</figure>
</div>
<p>Intuitively, the phase function has the following two properties:</p>
<ul>
<li>If you fix the incident direction, no matter how you rotate the particle, the phase function distribution is the same. Alternatively, if you change the incident direction, the phase function distribution moves along with the incident direction.</li>
<li>Given an incident direction, the phase function distribution is axially symmetric about the incident direction.</li>
</ul>
<p>The two conditions above are met only when the medium consists of randomly distributed spherically symmetric particles<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, in which case 1) there is no reason to think that any incident direction is special, so the phase function certainly is invariant to <span class="math inline">\(\oi\)</span>, and 2) there is no reason to think <span class="math inline">\(\os\)</span> and <span class="math inline">\(\os'\)</span> are any different since one should not expect the scattering behavior to change if we rotate the sphere about the incident direction (<span class="math inline">\(z\)</span>-axis).</p>
<p>A medium consisting of spherically symmetric particles is called a <em>symmetric</em> or an <strong>isotropic medium</strong>. Usually when we refer to an isotropic medium, not only is the phase function but also the total scattering coefficient <span class="math inline">\(\sigma_s(p, \oi)\)</span> (<a href="#eq-sca_coeff_phase" class="quarto-xref">Equation&nbsp;<span>10.21</span></a>) rotationally invariant to the incident direction<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p>As we said earlier, “isotropic” is an unbelievably overloaded term. People also call a particle an <strong>isotropic scatterer</strong> if its phase function is a constant, i.e., invariant to <span class="math inline">\(\os\)</span>; such a phase function is sometimes called an <em>isotropic phase function</em>. An isotropic scatterer does not exist; it is a purely theoretical construction, but if it existed, its phase function would take the value of <span class="math inline">\(\frac{1}{4\pi}\)</span> given <a href="#eq-energy_con_phase_func_2" class="quarto-xref">Equation&nbsp;<span>10.18</span></a>, as shown in the first graph in <a href="#fig-phase_function" class="quarto-xref">Figure&nbsp;<span>10.5</span></a>.</p>
</section>
</section>
<section id="sec-chpt-mat-vs-sca-models" class="level3" data-number="10.3.4">
<h3 data-number="10.3.4" class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-models"><span class="header-section-number">10.3.4</span> Common Models and General “Rules”</h3>
<p>There are many factors that determine the exact scattering efficiency and scattering direction, which can be calculated by solving the Maxwell’s equations. We will talk about a few common models here; we focus on the intuitions while omitting the exact mathematical expressions, which can be found in standard texts. From the models, we can identify a few general “rules” or, rather, approximations under certain assumptions.</p>
<p>The main theory or model for a single scattering event is called the <strong>Mie scattering</strong> theory, which, strictly speaking, applies only when the particle is spherical <span class="citation" data-cites="sharma2003color bohren2006fundamentals melbourne2004radio">(<a href="references.html#ref-sharma2003color" role="doc-biblioref">Sharma 2003</a>, Chpt. 3.5.2; <a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">Bohren and Clothiaux 2006</a>, Chpt 3.5; <a href="references.html#ref-melbourne2004radio" role="doc-biblioref">Melbourne 2004</a>, Chpt. 3)</span>. Mie scattering is <em>not</em> somehow a different scattering process from any other scattering, and the Mie theory is nothing more than the solution to the Maxwell’s equations under certain conditions<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<p>The Mie theory predicts that the overall scattering efficiency <span class="math inline">\(Q_s\)</span> is:</p>
<p><span id="eq-mie_1"><span class="math display">\[
\begin{align}
    Q_s &amp;= \frac{8}{3}\gamma^4\big(\frac{m^2-1}{m^2+2}\big)\big[1+\frac{6}{5}\big(\frac{m^2-1}{m^2+2}\big)\gamma^2 + \cdots \big]\\
    \gamma &amp;= \frac{r}{\lambda_m}, \\
    m &amp;= \frac{n}{n_m},
\end{align}
\tag{10.22}\]</span></span></p>
<p>where <span class="math inline">\(m\)</span> is the the relative refractive index between the particle and the medium surrounding the particle, and <span class="math inline">\(\gamma\)</span> is the ratio between the particle radius <span class="math inline">\(r\)</span> and the incident light wavelength in the surrounding medium <span class="math inline">\(\lambda_m\)</span>. The notion of surrounding media might come across as a little surprising: doesn’t the material consist merely of its particles? Hardly. For instance, in paints, pigments are surrounded by binders (e.g., linseed oil in oil paints, egg yolk in tempera paints, and beeswax in encaustic paints) and usually some amount of water (except oil paints). When paint dries, some water might be evaporated, leaving pockets of air, which also contributes to the surrounding media.</p>
<p>We can draw a few general conclusions from the model.</p>
<section id="small-particle-rayleigh-scattering" class="level4">
<h4 class="anchored" data-anchor-id="small-particle-rayleigh-scattering">Small-Particle (Rayleigh) Scattering</h4>
<p>For small particles where <span class="math inline">\(\gamma \ll 1\)</span> (generally when the radius is ten times smaller than the wavelength of the incident light), only the first term in <a href="#eq-mie_1" class="quarto-xref">Equation&nbsp;<span>10.22</span></a>’s bracket matters, so the scattering efficiency is inversely proportional to <span class="math inline">\(\lambda_m^{-4}\)</span>. The inverse proportionality to <span class="math inline">\(\lambda_m^{-4}\)</span> <em>largely</em> (but apparently not entirely) explains why the sky is blue and why the sun is red <span class="citation" data-cites="bohren2006fundamentals">(<a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">Bohren and Clothiaux 2006</a>, Chpt. 8.1)</span>. Why? First, recognize that individual molecules, such as air molecules, are usually sub-nm in size, so they scatter in this small-particle regime. Short wavelength lights from the sun are scattered by the atmospheric molecules more toward the sky and eventually enter your eyes, so if you look at the sky (against the sun) it would appear blue; when you look at the sun directly, the photons entering your eyes are mostly those unscattered ones that transmit directly through the atmosphere, and they are mostly longer-wavelength photons.</p>
<p>By then water molecules are also similarly small, so why would water look so different from the air? It is because water molecules are very densely packed, so their scatterings are coherent. In fact, the end result of such coherent scatterings by a collection of water molecules is that water appears specular.</p>
<p>The photopigments in a photoreceptor are very small in size compared to the wavelengths of visible light (each rhodopsin has a cross-section area of about <span class="citation" data-cites="milo2015cell">(<a href="references.html#ref-milo2015cell" role="doc-biblioref">Milo and Phillips 2015, p. 144</a>)</span>), so they almost do not scatter lights at all, only absorption. That is why we could use microspectrophotometry (MSP) to measure a photoreceptor’s (transverse) absorption rate (<a href="hvs-receptor.html#sec-chpt-hvs-receptor-absorb-msp" class="quarto-xref"><span>Section 3.2.1</span></a>): MSP measures the amount of light transmitted through a photoreceptor, and if there is little scattering, then all the photons that are not measured must be absorbed by the photoreceptor.</p>
<p>Scattering in the small-particle regime is also called <strong>Rayleigh scattering</strong>, which, again, is <em>not</em> somehow a fundamentally different scattering process, and the Rayleigh scattering theory<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> is nothing more than a special case of the Mie scattering theory <span class="citation" data-cites="sharma2003color bohren2006fundamentals">(<a href="references.html#ref-sharma2003color" role="doc-biblioref">Sharma 2003</a>, Chpt. 3.5.1; <a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">Bohren and Clothiaux 2006</a>. Chpt. 3.2)</span>.</p>
<p>The phase function in the Rayleigh regime is proportional to <span class="math inline">\(1+\cos^2\theta\)</span>, so the backward and forward scatterings are roughly equally probable. Taking the phase function into account, the scattering efficiency (in the form defined in <a href="#eq-sca_eff_phase" class="quarto-xref">Equation&nbsp;<span>10.20</span></a>) in Rayleigh scattering is proportional to:</p>
<p><span class="math display">\[
\begin{align}
    Q_s \propto (\frac{r}{\lambda_m})^4 \frac{m^2-1}{m^2+2} (1 + \cos^2\theta).
\end{align}
\]</span></p>
</section>
<section id="impact-of-particle-size" class="level4">
<h4 class="anchored" data-anchor-id="impact-of-particle-size">Impact of Particle Size</h4>
<p>When the particle size increases, the scattering efficiency increases, initially very quickly, but eventually saturates. In fact, the Mie theory predicts that when the particle size is much larger than the wavelength (e.g., more than 100 times larger), the scattering efficiency approaches a constant 2 regardless of <span class="math inline">\(m\)</span> and <span class="math inline">\(\lambda_m\)</span> <span class="citation" data-cites="johnsen2012optics">(<a href="references.html#ref-johnsen2012optics" role="doc-biblioref">Johnsen 2012, fig. 5.4</a>)</span>. This is evident in <a href="#fig-scattering_efficiency_m" class="quarto-xref">Figure&nbsp;<span>10.7</span></a>, which shows the scattering efficiency of a kind of particle as a function of particle radius (<span class="math inline">\(x\)</span>-axis) under different <span class="math inline">\(m\)</span> (different curves); the incident light wavelength is 500 nm.</p>
<div id="fig-scattering_efficiency_m" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scattering_efficiency_m-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/scattering_efficiency_m.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scattering_efficiency_m-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.7: Scattering efficiency as a function of particle radius under different relative refractive index <span class="math inline">\(m\)</span>; the incident light wavelength is 500~nm. From <span class="citation" data-cites="johnsen2012optics">Johnsen (<a href="references.html#ref-johnsen2012optics" role="doc-biblioref">2012, fig. 5.4</a>)</span>.
</figcaption>
</figure>
</div>
<p>The particle size also affects the phase function. As we have discussed above, small particles in the Rayleigh regime tend to scatter photons equally in the forward and backward directions, while large particles primarily scatter photons in the forward directions. The last two graphs in <a href="#fig-phase_function" class="quarto-xref">Figure&nbsp;<span>10.5</span></a> show the phase functions predicted by the Mie scattering theory under different particle sizes (both are larger than that in the Rayleigh regime). The forward fraction increases as the particle size increases.</p>
<p>Consider the scenario in <a href="#fig-photon_particle_interactions" class="quarto-xref">Figure&nbsp;<span>10.1</span></a>, where Material<sub>1</sub> sits on top of Material<sub>2</sub>, and our goal is to hide Material 2 so that the color of Material 1 is dependent only on the illumination (not the property of Material 2). There is an interesting trade-off between scattering efficiency and scattering direction here. If we want Material 1 to hide Material 2, we want the particles in Material 1 to scatter a lot of light (high scattering efficiency) backwards. If the scattering efficiency is low (so photons march on and are hindered only by absorption) or the scattering is heavy in the forward directions, photons penetrate through Material 1 and reach Material 2, which would then contribute to the overall color.</p>
<p>Now, to scatter a lot of light, we need the particles to be large, but then the scattering will be mostly in the forward directions. So there exists a sweet spot of the particle size that provides the highest “hiding power” for a material per unit volume. If we work out the math, we will see that the sweet spot falls roughly in the visible wavelength range. That is why most paint pigments have a diameter between 100 nm and <span class="citation" data-cites="paintpigmentsize">(<a href="references.html#ref-paintpigmentsize" role="doc-biblioref">Bruce MacEvoy 2015</a>)</span>. Of course, no matter how poor the hiding power is for a particular paint, if you apply enough of it, it will eventually hide whatever is behind it. Dye pigments are rather small in size (nm range), so they scatter few photons and that is why dye solutions look relatively transparent.</p>
</section>
<section id="impact-of-refractive-index" class="level4">
<h4 class="anchored" data-anchor-id="impact-of-refractive-index">Impact of Refractive Index</h4>
<p><a href="#fig-scattering_efficiency_m" class="quarto-xref">Figure&nbsp;<span>10.7</span></a> also shows the impact of the relative refractive index <span class="math inline">\(m\)</span> (between the particle and the surrounding media) on scattering efficiency. Generally, the scattering efficiency increases with <span class="math inline">\(m\)</span> at all particle sizes until when the particles are so large that the scattering efficiency becomes a constant. This is supported by <a href="#eq-mie_1" class="quarto-xref">Equation&nbsp;<span>10.22</span></a>, too (<span class="math inline">\(\frac{m^2-1}{m^2+2}\)</span> monotonically increases and has a limit of 1).</p>
<p>For large particles, while <span class="math inline">\(m\)</span> does not affect the scattering efficiency, it influences the scattering directions. When <span class="math inline">\(m\)</span> is small, the scattering tends to be more forward, whereas when <span class="math inline">\(m\)</span> is large, the scattering tends to be toward large angles (i.e., more photons will be back-scattered). This is why wet objects look darker (recall the unpleasant experience of accidentally spilling water on your pants). In dry paints, the medium surrounding the textile particles is air, and in wet paints it is water. <span class="math inline">\(m\)</span> becomes smaller when the material is wet (i.e., the relative refractive-index difference becomes smaller between the textile particles and water), so most of the scattering will be forward, increasing the traversal length of photons and essentially giving photons more opportunities to be absorbed.</p>
</section>
<section id="aspherical-particles" class="level4">
<h4 class="anchored" data-anchor-id="aspherical-particles">Aspherical Particles</h4>
<p>What if the particle is not spherical? The Mie theory does not apply. Analytical or even numerical solutions to the Maxwell’s equations would be difficult, so perhaps a better approach is just to parameterize a model and fit it with the experimental data.</p>
<p>One popular one-parameter parameterization of the phase function is the <strong>Henyey–Greenstein</strong> phase function <span class="citation" data-cites="pharr2018physically bohren2006fundamentals">(<a href="references.html#ref-pharr2018physically" role="doc-biblioref">Pharr, Jakob, and Humphreys 2018</a>, Chpt. 11.3.1; <a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">Bohren and Clothiaux 2006</a>, Chpt. 6.3.2)</span>, which takes the form:</p>
<p><span class="math display">\[
\begin{align}
    p(\theta) = \frac{1}{4\pi} \frac{1-g^2}{(1+g^2-2g\cos\theta)^{3/2}},
\end{align}
\]</span></p>
<p>where <span class="math inline">\(g\)</span> is the free parameter and is usually called the <strong>asymmetry parameter</strong>.</p>
<p>We hasten to emphasize that the Henyey–Greenstein function has absolutely zero physical meaning; it is designed for fitting experimental phase function data, so in the modern deep learning era, you might as well try a deep neural network. The second graph in <a href="#fig-phase_function" class="quarto-xref">Figure&nbsp;<span>10.5</span></a> shows one instantiation of the Henyey–Greenstein function.</p>
</section>
</section>
</section>
<section id="sec-chpt-mat-vs-rte" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte"><span class="header-section-number">10.4</span> Radiative Transfer Equation and Volume Rendering</h2>
<p>So far we have assumed that a ray can only be attenuated, which can happen only when the illumination is collimated and we assume single scattering. Under this assumption, <a href="#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>10.14</span></a> allows us to calculate any radiance in the medium (by weakening the initial radiance). General media are much more complicated: illumination can be from anywhere, and multiple scattering must be accounted for. As a result, external photons can be scattered into a ray of interest, as we have intuitively discussed in <a href="#sec-chpt-mat-vs-sca-intuition" class="quarto-xref"><span>Section 10.3.1</span></a>.</p>
<p>In the realm of geometric optics and radiometry, the general way to model lights going through a material/medium amounts to solving the so-called <strong>Radiative Transfer Equation</strong> (RTE), whose modern version was established by <span class="citation" data-cites="chandrasekhar1960radiative">Chandrasekhar (<a href="references.html#ref-chandrasekhar1960radiative" role="doc-biblioref">1960</a>)</span><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, and <span class="citation" data-cites="kajiya1984ray">Kajiya and Von Herzen (<a href="references.html#ref-kajiya1984ray" role="doc-biblioref">1984</a>)</span> was the first to introduce it to computer graphics. The RTE provides a mathematical way to express an arbitrary radiance in a medium.</p>
<section id="sec-chpt-mat-vs-rte-rte" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-rte"><span class="header-section-number">10.4.1</span> Radiative Transfer Equation</h3>
<p>The basic idea is to set up a differential equation to describe the (rate) of the radiance <em>change</em>. Given an incident radiance <span class="math inline">\(L(p, \os)\)</span>, we are interested in <span class="math inline">\(L(p+\D s \os, \os)\)</span>, the radiance after the ray has gone a small distance <span class="math inline">\(\D s\)</span>. The radiance can be:</p>
<ul>
<li>attenuated by the medium because of absorption;</li>
<li>attenuated by the medium because photons are scattered out into other directions; this is called <strong>out-scattering</strong> in graphics;</li>
<li>augmented by photons that are scattered into the ray direction from all other directions — because of multiple scattering<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>; this is called <em>in-scattering</em> in graphics;</li>
<li>augmented because particles can emit photons.</li>
</ul>
<p>The attenuation (reduction) of the radiance over <span class="math inline">\(\D s\)</span> is:</p>
<p><span id="eq-radiance_sub"><span class="math display">\[
\begin{align}
    -L(p, \os) \sigma_t(p, \os) \D s.
\end{align}
\tag{10.23}\]</span></span></p>
<p>The radiance augmentation due to in-scattering is given by:</p>
<p><span id="eq-radiance_add_insca"><span class="math display">\[
\begin{align}
    \int^{\Omega = 4\pi} f_p(p, \os, \oi) \sigma_s(p, \os) \D s L(\oi) \doi = \sigma_s(p, \os) \D s \int^{\Omega = 4\pi} L(p, \oi) f_p(p, \os, \oi) \doi.
\end{align}
\tag{10.24}\]</span></span></p>
<!-- %\fixme{different oi will have different optical length, but that can be folded into sigma. the fact that we are integrating over 4pi means we should absolutely consider photons that hit all six faces of the cube. also recall that we considering single scattering, so a scattered photon will not go through other scatterings in that volume/entire medium.} -->
<p>The way to interpret <a href="#eq-radiance_add" class="quarto-xref">Equation&nbsp;<span>10.27</span></a> is the following. <span class="math inline">\(L(p, \oi)\)</span> is the incident radiance from a direction <span class="math inline">\(\oi\)</span>, <span class="math inline">\(L(p, \oi) \doi\)</span> is the irradiance received from <span class="math inline">\(\doi\)</span>, of which <span class="math inline">\(\sigma_s(p, \oi)\D s L(p, \os) \doi\)</span> is the irradiance scattered in all directions after traveling a distance <span class="math inline">\(\D s\)</span>. That portion of the scattered irradiance is multiplied by <span class="math inline">\(f_p(\os, \oi)\)</span> to give us the radiance toward <span class="math inline">\(\os\)</span> (see <a href="#eq-phase_func_def2" class="quarto-xref">Equation&nbsp;<span>10.19</span></a>). We then integrate over the entire sphere, accounting for the fact that lights can come from anywhere over the space, to obtain the total augmented radiance toward <span class="math inline">\(\os\)</span>.</p>
<p>If we consider emission, the total radiance augmentation is:</p>
<p><span id="eq-radiance_add_total"><span class="math display">\[
\begin{align}
    \sigma_a(p, \os) \D s L_e(p, \os) + \sigma_s(p, \os) \D s \int^{\Omega = 4\pi} L(p, \oi) f_p(p, \os, \oi) \doi,
\end{align}
\tag{10.25}\]</span></span></p>
<p>where <span class="math inline">\(L_e(p, \os)\)</span> is the emitted radiance at <span class="math inline">\(p\)</span> toward <span class="math inline">\(\os\)</span>, so the first term represents the total emission over <span class="math inline">\(\D s\)</span>. If we let:</p>
<p><span id="eq-source_term_em"><span class="math display">\[
\begin{align}
    L_s(p, \os) = \sigma_a(p, \os) L_e(p, \os) + \sigma_s(p, \os) \int^{\Omega = 4\pi} L(p, \oi) f_p(p, \os, \oi) \doi,
\end{align}
\tag{10.26}\]</span></span></p>
<p>the total augmentation can be simplified to:</p>
<p><span id="eq-radiance_add"><span class="math display">\[
\begin{align}
    L_s(p, \os) \D s,
\end{align}
\tag{10.27}\]</span></span></p>
<p>where the <span class="math inline">\(L_s\)</span> term is sometimes called the <strong>source term</strong> or <strong>source function</strong> in computer graphics, because it is the source of power at <span class="math inline">\(p\)</span>.</p>
<p>Combining <a href="#eq-radiance_sub" class="quarto-xref">Equation&nbsp;<span>10.23</span></a> and <a href="#eq-radiance_add" class="quarto-xref">Equation&nbsp;<span>10.27</span></a>, the net radiance change is:</p>
<p><span id="eq-rte_1"><span class="math display">\[
\begin{align}
    \D L(p, \os) &amp;= L(p + \D s \os, \os) - L(p, \os) \\
    &amp;= -L(p, \os) \sigma_t(p, \os) \D s + L_s(p, \os) \D s.
\end{align}
\tag{10.28}\]</span></span></p>
<p>As <span class="math inline">\(\D s\)</span> approaches 0, we get (assuming <span class="math inline">\(\os\)</span> is a unit vector as in <a href="#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>10.13</span></a> and <a href="#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>10.14</span></a>):</p>
<p><span id="eq-rte_2"><span class="math display">\[
\begin{align}
    \os \cdot \nabla_p L(p, \os) &amp;= \frac{\d L(p, \os)}{\d s} = \lim_{\D s \rightarrow 0} \frac{L(p + \D s \os, \os) - L(p, \os)}{\D s} \nonumber \\
    &amp;= -\sigma_t(p, \os) L(p, \os) + L_s(p, \os),
\end{align}
\tag{10.29}\]</span></span></p>
<p>where <span class="math inline">\(\nabla_p\)</span> denotes the gradient of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(p\)</span>, and <span class="math inline">\(\os \cdot \nabla_p\)</span> denotes the directional derivative, which is used because technically <span class="math inline">\(p\)</span> and <span class="math inline">\(\os\)</span> are both defined in a three-dimensional space, so what we are really calculating is the rate of radiance change at <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span>.</p>
<p><a href="#eq-rte_2" class="quarto-xref">Equation&nbsp;<span>10.29</span></a> is the RTE, which is an integro-differential equation, because it is a differential equation with an integral embedded. The RTE has an intuitive interpretation: if we think of radiance as the power of a ray, as a ray propagates, its power is attenuated by the medium but also augmented by “stray photons” from other rays. The latter is given by <span class="math inline">\(L_s(p, \os)\)</span>, which can be thought of as the augmentation of the radiance per unit length.</p>
<p>The RTE describes the rate of change of an arbitrary radiance <span class="math inline">\(L(p, \os)\)</span>. But our ultimate goal is to calculate the radiance itself? Generally the RTE has no analytical solution. There are two strategies to solve it. First, we can derive analytical solutions under certain certain assumptions and simplifications.</p>
<ul>
<li><p>For instance, the integral in <a href="#eq-rte_2" class="quarto-xref">Equation&nbsp;<span>10.29</span></a> can be approximated by a summation along <span class="math inline">\(N\)</span> directions; then we can turn <a href="#eq-rte_2" class="quarto-xref">Equation&nbsp;<span>10.29</span></a> into a system of <span class="math inline">\(N\)</span> differential equations to be solved. This is sometimes called the <strong>N-flux theory</strong>. We will omit a formal treatment but refer you to <span class="citation" data-cites="bohren2006fundamentals">Bohren and Clothiaux (<a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">2006</a>, Chpt. 6.1)</span>, <span class="citation" data-cites="volz2001industrial">Volz and Simon (<a href="references.html#ref-volz2001industrial" role="doc-biblioref">2001</a>, Chpt. 3.1.2)</span>, and <span class="citation" data-cites="klein2010industrial">Klein (<a href="references.html#ref-klein2010industrial" role="doc-biblioref">2010</a>, Chpt. 5.5)</span> for details. You might have heard of the famous Kubelka-Munk model <span class="citation" data-cites="kubelka1931beitrag kubelka1931article kubelka1948new">(<a href="references.html#ref-kubelka1931beitrag" role="doc-biblioref">Kubelka and Munk 1931b</a>, <a href="references.html#ref-kubelka1931article" role="doc-biblioref">1931a</a>; <a href="references.html#ref-kubelka1948new" role="doc-biblioref">Kubelka 1948</a>)</span> widely used in modeling the color of pigment mixture; it is essentially a special case of the N-flux theory where <span class="math inline">\(N=2\)</span>, which we will discuss in <a href="#sec-chpt-mat-vs-km" class="quarto-xref"><span>Section 10.5</span></a>.</p></li>
<li><p>Another assumption people make is to assume that volume scattering is isotropic and can be approximated as a <em>diffusion</em> process. This is called the <strong>diffusion approximation</strong> <span class="citation" data-cites="ishimaru1977theory ishimaru1978wave">(<a href="references.html#ref-ishimaru1977theory" role="doc-biblioref">Ishimaru 1977</a>; <a href="references.html#ref-ishimaru1978wave" role="doc-biblioref">Ishimaru et al. 1978</a>)</span>, which is widely used in both scientific modeling <span class="citation" data-cites="farrell1992diffusion eason1978theory schweiger1995finite boas2001imaging">(<a href="references.html#ref-farrell1992diffusion" role="doc-biblioref">Farrell, Patterson, and Wilson 1992</a>; <a href="references.html#ref-eason1978theory" role="doc-biblioref">Eason et al. 1978</a>; <a href="references.html#ref-schweiger1995finite" role="doc-biblioref">Schweiger et al. 1995</a>; <a href="references.html#ref-boas2001imaging" role="doc-biblioref">Boas et al. 2001</a>)</span> and in rendering <span class="citation" data-cites="stam1995multiple wann2001practical dong2013material">(<a href="references.html#ref-stam1995multiple" role="doc-biblioref">Stam 1995</a>, Chpt. 7; <a href="references.html#ref-wann2001practical" role="doc-biblioref">Jensen et al. 2001</a>; <a href="references.html#ref-dong2013material" role="doc-biblioref">Dong et al. 2013</a>)</span>; see <span class="citation" data-cites="bohren2006fundamentals">Bohren and Clothiaux (<a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">2006</a>, Chpt. 6.2)</span> for a theoretical treatment.</p></li>
</ul>
<p>The second approach deserves its own section.</p>
</section>
<section id="sec-chpt-mat-vs-rte-vre" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vre"><span class="header-section-number">10.4.2</span> Volume Rendering Equation</h3>
<p>The second approach, which is particularly popular in computer graphics, is to first turn the RTE into a purely integral equation and then <em>numerically</em> (rather than analytically) estimate the integral using Monte Carlo integration, very similar to how the rendering equation is dealt with for surface scattering (<a href="rendering-surface.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 9.3</span></a>).</p>
<div id="fig-vre" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vre-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/vre.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vre-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.8: (a): Illustration of the continuous VRE (<a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>10.30</span></a>). (b): Illustration of a discrete VRE (<a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>10.31</span></a>), where the integral in the continuous VRE is replaced by a summation between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> at an interval of <span class="math inline">\(\D s\)</span>; <span class="math inline">\(t_i\)</span> is the total transmittance between <span class="math inline">\(p_i\)</span> and <span class="math inline">\(p_{i+1}\)</span>; <span class="math inline">\(L_i\)</span> is a shorthand for <span class="math inline">\(L_s(p_i, \os)\)</span>, the source term of at <span class="math inline">\(p_i\)</span> toward <span class="math inline">\(\os\)</span>.
</figcaption>
</figure>
</div>
<p>The way to think of this is that in order to calculate any given radiance <span class="math inline">\(L(p, \os)\)</span>, we need to integrate all the changes along the direction <span class="math inline">\(\os\)</span> up until <span class="math inline">\(p\)</span>. Where do we start the integration? We can start anywhere. <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>10.8</span></a> (a) visualizes the integration process. Let’s say we want to start from a point <span class="math inline">\(p_0\)</span>, whose initial radiance toward <span class="math inline">\(\os\)</span> is <span class="math inline">\(L_0(p_0, \os)\)</span>. Let <span class="math inline">\(p = p_0 + s\os\)</span>, where <span class="math inline">\(\os\)</span> is a unit vector and <span class="math inline">\(s\)</span> is the distance between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>. An arbitrary point <span class="math inline">\(p'\)</span> between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> would then be <span class="math inline">\(p' = p_0 + s' \os\)</span><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
<p>Now we need to integrate from <span class="math inline">\(p_0\)</span> to <span class="math inline">\(p\)</span> by running <span class="math inline">\(s'\)</span> from 0 to <span class="math inline">\(s\)</span>. Observe that the RTE is a form of a <em>non-homogeneous</em> linear differential equation, whose solution is firmly established in calculus. Without going through the derivations, its solution is:</p>
<p><span id="eq-vre"><span class="math display">\[
\begin{align}
    L(p, \os) = T(p_0 \rightarrow p)L_0(p_0, \os) + \int_{0}^{s} T(p' \rightarrow p) L_s(p', \os)\d s',
\end{align}
\tag{10.30}\]</span></span></p>
<p>where <span class="math inline">\(T(p_0 \rightarrow p)\)</span> is the transmittance between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span>, and <span class="math inline">\(T(p' \rightarrow p)\)</span> is the transmittance between <span class="math inline">\(p'\)</span> and <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span>. Recall the definition of transmittance in <a href="#eq-transmittance" class="quarto-xref">Equation&nbsp;<span>10.15</span></a>: it is the remaining fraction of the radiance after attenuation by the medium after traveling the distance between two points. In our case here:</p>
<p><span class="math display">\[
\begin{align}
    T(p' \rightarrow p) = \frac{L(p+s\os, \os)}{L(p+s'\os, \os)} = e^{-\int_{s'}^s \sigma_t(p+t\omega, \omega) \d t}, \\
    T(p_0 \rightarrow p) = \frac{L(p+s\os, \os)}{L(p, \os)} = e^{-\int_{0}^s \sigma_t(p+t\omega, \omega) \d t},
\end{align}
\]</span></p>
<p>The integral equation <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>10.30</span></a> in the graphics literature is called the <strong>volume rendering equation</strong> (VRE) or the <strong>volumetric light transport equation</strong> — the counterpart of the surface LTE (<a href="rendering-surface.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 9.3</span></a>). Looking at the visualization in <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>10.8</span></a> (a), the VRE has an intuitive interpretation: the radiance at <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span> is the the contribution of <span class="math inline">\(p_0\)</span> plus and contribution of every single point between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>.</p>
<ul>
<li>The contribution of <span class="math inline">\(p_0\)</span> is given by its initial radiance <span class="math inline">\(L_0\)</span> weakened by the transmittance between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>;</li>
<li>Why would a point <span class="math inline">\(p'\)</span> between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> make any contribution? It is because of the source term (<a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>10.26</span></a>): <span class="math inline">\(p'\)</span> might emit lights, and some of the in-scattered photons at <span class="math inline">\(p'\)</span> will be scattered toward <span class="math inline">\(\os\)</span>. The contribution of <span class="math inline">\(p'\)</span> is thus given by the source term <span class="math inline">\(L_s\)</span> weakened by the transmittance between <span class="math inline">\(p'\)</span> and <span class="math inline">\(p\)</span>.</li>
</ul>
<p>The form of the VRE might appear to suggest that it is enough to accumulate along only the <em>direct</em> path between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>, which is surprising given that there are infinitely many scattering paths between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> (due to multiple scattering). For instance, it appears that we consider only the outgoing radiance toward <span class="math inline">\(\os\)</span> from <span class="math inline">\(p_0\)</span>, but <span class="math inline">\(p_0\)</span> might have outgoing radiances over other directions, which might eventually contribute to <span class="math inline">\(L(p, \os)\)</span> through multiple scattering. Are we ignoring them?</p>
<p>The answer is that the VRE <em>implicitly</em> accounts for all the potential paths between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> because of the <span class="math inline">\(L_s\)</span> term, which expands to . That is, every time we accumulate the contribution of a point between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>, we have to consider the in-scattering from all the directions at that point. Another way to interpret this is to observe that the radiance term <span class="math inline">\(L\)</span> appears on both sides of the equation. Therefore, the VRE must be solved recursively by evaluating it everywhere in space.</p>
<p>Does this remind you of the rendering equation (<a href="rendering-surface.html#eq-re" class="quarto-xref">Equation&nbsp;<span>9.18</span></a>)? Indeed, the VRE can be thought of as the volumetric counterpart of the rendering equation. Similarly, we can use Monte Carlo integration to estimate it, just like how the rendering equation is dealt with — with an extra complication: the VRE has two integrals: the outer integral runs from <span class="math inline">\(p_0\)</span> to <span class="math inline">\(p\)</span> and, for any intermediate point <span class="math inline">\(p'\)</span>, there is an inner integral that runs from <span class="math inline">\(p'\)</span> to <span class="math inline">\(p\)</span> to evaluate the transmittance <span class="math inline">\(T(p' \rightarrow p)\)</span>. Therefore, we have to sample both integrands.</p>
<p>Similar to the situation of the rendering equation, sampling recursively would exponentially increase the number of rays to be tracked. Put it another way, since there are infinitely many paths from which a ray gains its energy due to multiple scattering, we have to integrate infinitely many paths. Again, a common solution is path tracing, for which <span class="citation" data-cites="pharr2023physically">Pharr, Jakob, and Humphreys (<a href="references.html#ref-pharr2023physically" role="doc-biblioref">2023</a>, Chpt. 14)</span> is a great reference.</p>
<p>A simplification that is commonly used is to assume that there is only single scattering directly from the light source. In this way, the <span class="math inline">\(L_s\)</span> term does not have to integrate infinitely many incident rays over the sphere but only a fixed amount of rays emitted from the light source <em>non-recursively</em>. This strategy is sometimes called <strong>local illumination</strong> in volume rendering, as opposed to <strong>global illumination</strong>, where one needs to consider all the possible paths of light transport. The distinction is similar to that in modeling surface scattering (<a href="rendering-surface.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 9.3</span></a>).</p>
</section>
<section id="sec-chpt-mat-vs-rte-vis" class="level3" data-number="10.4.3">
<h3 data-number="10.4.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vis"><span class="header-section-number">10.4.3</span> Discrete VRE and Scientific Volume Visualization</h3>
<p>Sometimes the VRE takes the following discrete form:</p>
<p><span id="eq-vre_1a"><span class="math display">\[
\begin{align}
    L = \sum_{i=0}^{N-1}\big(L_i\D s\prod_{j=i+1}^{N-1}t_j\big).
\end{align}
\tag{10.31}\]</span></span></p>
<p><a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>10.31</span></a> is the discrete version of <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>10.30</span></a>: the former turns the two integrals in the latter (both the outer integral and the inner one carried by <span class="math inline">\(T(\cdot)\)</span>) to discrete summations using the Riemann sum over <span class="math inline">\(N\)</span> discrete points along the ray between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> at an interval of <span class="math inline">\(\D s = \frac{s}{N}\)</span>.</p>
<p>The notations are slightly different; <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>10.8</span></a> (b) visualizes how this discrete VRE is expressed with the new notations.</p>
<ul>
<li><span class="math inline">\(L\)</span> is <span class="math inline">\(L(p, \os)\)</span>, the quantity to be calculated;</li>
<li><span class="math inline">\(L_i\)</span> is a shorthand for <span class="math inline">\(L_s(p_i, \os)\)</span>, i.e., the source term (<a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>10.26</span></a>) for the <span class="math inline">\(i^{th}\)</span> point between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> toward <span class="math inline">\(\os\)</span>; by definition, <span class="math inline">\(p_0\)</span> is the <span class="math inline">\(0^{th}\)</span> point (so <span class="math inline">\(L_0\)</span> is the initial radiance <span class="math inline">\(L_0(p_0, \os)\)</span> in <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>10.30</span></a>) and <span class="math inline">\(p\)</span> is the <span class="math inline">\(N^{th}\)</span> point;</li>
<li><span class="math inline">\(t_i\)</span> (or more explicitly <span class="math inline">\(t(p_{i} \rightarrow p_{i+1})\)</span>) represents the total transmittance between the <span class="math inline">\(i^{th}\)</span> and the <span class="math inline">\((i+1)^{th}\)</span> point and is given by <span class="math inline">\(e^{-\sigma_t(p_i, \os) \D s}\)</span> (notice the integral in continuous transmittance <a href="#eq-transmittance" class="quarto-xref">Equation&nbsp;<span>10.15</span></a> is gone, because we assume the transmittance between two adjacent points is a constant in the Reimann sum);</li>
<li><span class="math inline">\(\alpha_i\)</span> is the <strong>opacity</strong> between the <span class="math inline">\(i^{th}\)</span> and the <span class="math inline">\((i+1)^{th}\)</span> point, which is defined as the residual of the transmittance between the two points: <span class="math inline">\(1-t_i\)</span>.</li>
</ul>
<p>See <span class="citation" data-cites="max1995optical">Max (<a href="references.html#ref-max1995optical" role="doc-biblioref">1995</a>, Sect. 4)</span> or <span class="citation" data-cites="kaufman2003volume">Kaufman and Mueller (<a href="references.html#ref-kaufman2003volume" role="doc-biblioref">2003</a>, Sect. 6.1)</span> for a relatively straightforward derivation of <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>10.31</span></a>, but hopefully this form of the VRE is equally intuitive to interpret from <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>10.8</span></a> (b). It is nothing more than accumulating the contribution of each point along the ray, but now we also need to accumulate the attenuation along the way just because of how opacity is defined by convention (per step), hence the product of a sequence of the opacity residuals.</p>
<p>We can also re-express <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>10.31</span></a> using opacity rather than transmittance: <span id="eq-vre_1b"><span class="math display">\[
\begin{align}
    L &amp;= \sum_{i=0}^{N-1}\big(L_i\D s\prod_{j=i+1}^{N-1}(1-\alpha_j)\big) \\
    &amp;= L_{N-1} \D s + L_{N-2} \D s(1-\alpha_{N-1}) + L_{N-3} \D s(1-\alpha_{N-1})(1-\alpha_{N-2}) +~\cdots~  \\
    &amp;~~~+ L_1\D s\prod_{j=2}^{N-1}(1-\alpha_j)+ L_0\D s\prod_{j=1}^{N-1}(1-\alpha_j).
\end{align}
\tag{10.32}\]</span></span></p>
<p>The discrete VRE is usually used in the scientific visualization literature, where people are interested in visualizing data obtained from, e.g., computer tomography (CT) scans or magnetic resonance imaging (MRI). There, it is the relative color that people usually care about, not the physical quantity such as the radiance, so people sometimes lump <span class="math inline">\(L_i\D s\)</span> together as <span class="math inline">\(C_i\)</span> and call it the “color” of the <span class="math inline">\(i^{th}\)</span> point. The VRE is then written as:</p>
<p><span id="eq-vre_2"><span class="math display">\[
\begin{align}
    C = \sum_{i=0}^{N-1}\big(C_i\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\end{align}
\tag{10.33}\]</span></span></p>
<p>The <span class="math inline">\(C\)</span> terms are defined in a three-dimensional RGB space, and <a href="#eq-vre_2" class="quarto-xref">Equation&nbsp;<span>10.33</span></a> is evaluated for the three channels separately, similar to how <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>10.31</span></a> and <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>10.30</span></a> are meant to be evaluated for each wavelength independently. Since color is a linear projection from the spectral radiance, the so-calculated <span class="math inline">\(C\)</span> (all three channels) is indeed proportional to the true color, although in visualization one usually does not care about the true colors anyway (see <a href="#sec-chpt-mat-vs-rte-vis-vis" class="quarto-xref"><span>Section 10.4.3.3</span></a>).</p>
<p><a href="#eq-vre_2" class="quarto-xref">Equation&nbsp;<span>10.33</span></a> is also called the <em>back-to-front</em> compositing formula in volume rendering, since it starts from <span class="math inline">\(p_0\)</span>, the farthest point on the ray to <span class="math inline">\(p\)</span>. We can easily turn the order around to start from <span class="math inline">\(p\)</span> and end at <span class="math inline">\(p_0\)</span> in a <em>front-to-back</em> fashion (<span class="math inline">\(C_{N-1}\)</span> now corresponds to <span class="math inline">\(p_0\)</span>):</p>
<p><span id="eq-vre2_front"><span class="math display">\[
\begin{align}
    C = \sum_{i=0}^{N-1}\big(C_i\prod_{j=0}^{i-1}t_j\big).
\end{align}
\tag{10.34}\]</span></span></p>
<p>While theoretically equivalent, the latter is better in practice because it allows us to opportunistically terminate the integration early when, for instance, the accumulated opacity is high enough (transmittance is low enough), at which point integrating further makes little numerical contribution to the result.</p>
<section id="another-discrete-form-of-vre" class="level4">
<h4 class="anchored" data-anchor-id="another-discrete-form-of-vre">Another Discrete Form of VRE</h4>
<p>A perhaps more common way to express the discrete VRE is to approximate the transmittance <span class="math inline">\(t\)</span> using the first two terms of its Taylor series expansion and further assume that the medium has a low albedo, i.e., <span class="math inline">\(\sigma_t \approx \sigma_a\)</span> and <span class="math inline">\(\sigma_s \approx 0\)</span> (that is, the medium emits and absorbs <em>only</em>); we have:</p>
<p><span class="math display">\[
\begin{align}
    &amp; 1 - \alpha_i = t_i = t(p_{i} \rightarrow p_{i+1}) = e^{-\sigma_t(p_i, \os) \D s} = 1 - \sigma_t(p_i, \os) \D s + \frac{(\sigma_t(p_i, \os) \D s)^2}{2} - \cdots \\
    \approx &amp; 1 - \sigma_t(p_i, \os) \D s \\
    \approx &amp; 1 - \sigma_a(p_i, \os) \D s.
\end{align}
\]</span></p>
<p>Therefore:</p>
<p><span id="eq-vre_alpha_approx"><span class="math display">\[
\begin{align}
\alpha_i \approx \sigma_a(p_i, \os) \D s.
\end{align}
\tag{10.35}\]</span></span></p>
<p>Now, observe that the <span class="math inline">\(L_i\)</span> term in <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>10.31</span></a> is the source term in <a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>10.26</span></a>, which under the low albedo assumption has only the emission term, so:</p>
<p><span id="eq-vre_3b"><span class="math display">\[
\begin{align}
\label{eq:vre_3}
    L &amp;= \sum_{i=0}^{N-1}\big(L_i\D s\prod_{j=i+1}^{N-1}(1-\alpha_j)\big) \\
    &amp;=  \sum_{i=0}^{N-1}\big(\sigma_a(p_i, \os) L_e(p_i, \os)\D s\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\end{align}
\tag{10.36}\]</span></span></p>
<p>Now plug in <a href="#eq-vre_alpha_approx" class="quarto-xref">Equation&nbsp;<span>10.35</span></a>, we have:</p>
<p><span id="eq-vre_3c"><span class="math display">\[
\begin{align}
    L =  \sum_{i=0}^{N-1}\big(L_e(p_i, \os)\alpha_i\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\end{align}
\tag{10.37}\]</span></span></p>
<p>If we let <span class="math inline">\(C_i = L_e(p_i, \os)\)</span>, the discrete VRE is then expressed as <span class="citation" data-cites="levoy1988display">(<a href="references.html#ref-levoy1988display" role="doc-biblioref">Levoy 1988</a>)</span>:</p>
<p><span id="eq-vre_4"><span class="math display">\[
\begin{align}
    C = \sum_{i=0}^{N-1}\big(C_i\alpha_i\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\end{align}
\tag{10.38}\]</span></span></p>
<p>This can be interpreted as a form of <strong>alpha blending</strong> <span class="citation" data-cites="smith1995alpha">(<a href="references.html#ref-smith1995alpha" role="doc-biblioref">Smith 1995</a>)</span>, a typical trick in graphics to render transparent materials. It makes sense for our discrete VRE to reduce to alpha blending: our derivation assumes that the volume does not scatter lights, so translucent materials become transparent.</p>
<p>Again, <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>10.38</span></a> is the back-to-front equation, and the front-to-back counterpart looks like:</p>
<p><span id="eq-vre4_front"><span class="math display">\[
\begin{align}
    C = \sum_{i=0}^{N-1}\big(C_i\alpha_i\prod_{j=0}^{i-1}t_j\big).
\end{align}
\tag{10.39}\]</span></span></p>
<p>If you compare the two discrete forms in <a href="#eq-vre_2" class="quarto-xref">Equation&nbsp;<span>10.33</span></a> and <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>10.38</span></a>, it would appear that the two are not mutually consistent! Of course we know why: 1) <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>10.38</span></a> applies two further approximations (low albedo and Taylor series expansion) <em>and</em> 2) the two <span class="math inline">\(C\)</span> terms in the two equations refer to different physical quantities (compare <a href="#eq-vre_1b" class="quarto-xref">Equation&nbsp;<span>10.32</span></a> with <a href="#eq-vre_3c" class="quarto-xref">Equation&nbsp;<span>10.37</span></a>).</p>
</section>
<section id="sec-chpt-mat-vs-rte-vis-compare" class="level4">
<h4 class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vis-compare">The Second Form is More Flexible</h4>
<p>What is the benefit of this new discrete form, comparing <a href="#eq-vre2_front" class="quarto-xref">Equation&nbsp;<span>10.34</span></a> and <a href="#eq-vre4_front" class="quarto-xref">Equation&nbsp;<span>10.39</span></a>? Both equations can be interpreted as a form of weighted sum, where <span class="math inline">\(C_i\)</span> is weighted by a weight <span class="math inline">\(w_i\)</span>, which is <span class="math inline">\(\prod_{j=0}^{i-1}t_j\)</span> in the first case and <span class="math inline">\(\alpha_i\prod_{j=0}^{i-1}t_j\)</span> in the second case. The most obvious difference is that the weights in the first case are correlated but less so in the second case. The weights are strictly decreasing as <span class="math inline">\(i\)</span> increases in the first case, since <span class="math inline">\(t_i &lt; 1\)</span>.</p>
<p>In the second case, the weights are technically independent. One way to understand this is to observe, in the second case, that <span class="math inline">\(w_0 = \alpha_0\)</span> and <span class="math inline">\(w_{i+1} = w_i \frac{\alpha_{i+1}(1-\alpha_i)}{\alpha_i}\)</span>, so there is generally a unique assignment of the <span class="math inline">\(\alpha\)</span> values for a given weight combination. This “flexibility” will come in handy when we can manually assign (<a href="#sec-chpt-mat-vs-rte-vis-vis" class="quarto-xref"><span>Section 10.4.3.3</span></a>) or learn the weights (<a href="#sec-chpt-mat-vs-rte-nr" class="quarto-xref"><span>Section 10.4.4</span></a>). Note, however, that if we impose the constraint that <span class="math inline">\(\alpha\in[0, 1]\)</span>, we are effectively constraining the weights too.</p>
</section>
<section id="sec-chpt-mat-vs-rte-vis-vis" class="level4">
<h4 class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vis-vis">Visualization is Not (Necessarily) Physically-Based Rendering!</h4>
<p>These discrete VRE forms might give you the false impression that we have avoided the need to integrate infinitely many paths, because, computationally, the evaluation of the VRE comes down to a <em>single-path</em> summation along the ray trajectory. Not really. Calculating the <span class="math inline">\(C_i\)</span> terms in the new formulations still requires recursion if the results are meant to be physically accurate. Of course we can sidestep this by, e.g., applying the local-illumination approximation, as mentioned before, to avoid recursion.</p>
<p>Scientific visualization offers another opportunity: we can simply <em>assign</em> values to the <span class="math inline">\(C\)</span>s and even the <span class="math inline">\(\alpha\)</span>s without regard to physics. The goal of visualization is to discover/highlight interesting objects and structures while de-emphasizing things that are irrelevant. So the actual colors are not as important, which gives us great latitude to determine VRE parameters.</p>
<div id="fig-render_vs_vis" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-render_vs_vis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/render_vs_vis_new.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-render_vs_vis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.9: Comparing volume rendering for visualization and rendering. (a): two examples of scientific visualization (of CT data) using volume rendering; from <span class="citation" data-cites="ctscan">Sjschen (<a href="references.html#ref-ctscan" role="doc-biblioref">2025</a>)</span> and <span class="citation" data-cites="ctscanmouse">MathiasRav (<a href="references.html#ref-ctscanmouse" role="doc-biblioref">2009</a>)</span>. (b): photorealistic volume rendering (a scene from Disney’s Moana, 2016); from <span class="citation" data-cites="eelt_rendering">Gnash (<a href="references.html#ref-eelt_rendering" role="doc-biblioref">2017</a>)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-render_vs_vis" class="quarto-xref">Figure&nbsp;<span>10.9</span></a> compares volume-rendered images for scientific visualization (a) and for photorealistic rendering (b). In the case of visualization, the data were from CT scans. In both scans, the outer surface is not transparent but is rendered so just because we are interested in seeing the inner structures that are otherwise occluded. The user makes an executive call to assign a very low transparency to the bones in the knee model 0 but a very high transparency value to the skin and other tissues: this is not physically accurate but a good choice for this particular visualization. Photorealistic rendering, in contrast, has to be physically based and does not usually have this flexibility. See figures in <span class="citation" data-cites="wrenninge2011production">Wrenninge and Bin Zafar (<a href="references.html#ref-wrenninge2011production" role="doc-biblioref">2011</a>)</span> and <span class="citation" data-cites="fong2017production">Fong et al. (<a href="references.html#ref-fong2017production" role="doc-biblioref">2017</a>)</span> for more examples.</p>
<p>There is volume rendering software that would allow the users to make such an assignment depending on what the user wants to highlight and visualize. With certain constraints and heuristics, one can also procedurally assign the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(C\)</span> values from the raw measurement data, usually a density field (see below) acquired from whatever measurement device is used (e.g., CT scanners or MRI machines), using what is called the <em>transfer functions</em> in the literature<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. Making an assignment usually is tied to a <em>classification</em> problem: voxels/points of different classes should have different assignments.</p>
</section>
<section id="density-fields" class="level4">
<h4 class="anchored" data-anchor-id="density-fields">Density Fields</h4>
<p>Physically speaking, the medium in RTE/VRE is parameterized by its absorption and scattering coefficients, which are a product of cross section and concentration, which is sometimes also called the density. In physically-based volume rendering, this is indeed how the density is used from the very beginning <span class="citation" data-cites="kajiya1984ray blinn1982light">(<a href="references.html#ref-kajiya1984ray" role="doc-biblioref">Kajiya and Von Herzen 1984</a>; <a href="references.html#ref-blinn1982light" role="doc-biblioref">Blinn 1982</a>)</span>.</p>
<p>In visualization where being physically accurate or photorealistic is unimportant, the notion of an attenuation coefficient loses its physical meaning; it is just a number that controls how the brightness of a point weakens. People simply call the attenuation coefficient the density <span class="citation" data-cites="kaufman2003volume">(<a href="references.html#ref-kaufman2003volume" role="doc-biblioref">Kaufman and Mueller 2003</a>)</span>, presumably because, intuitively, if the particle density is high the color should be dimmer. If you want to be pedantic, you might say that the attenuation coefficient depends not only on the density/concentration but also on the cross section (<a href="#eq-abs_2" class="quarto-xref">Equation&nbsp;<span>10.2</span></a>), so how can we do that? Remember in visualization one gets to make an executive call and <em>assign</em> the density value (and thus control <span class="math inline">\(\alpha\)</span>), so it does not really matter if the value itself means the physical quantity of density/concentration. This is apparent in early work that uses volume rendering for scientific visualization <span class="citation" data-cites="sabella1988rendering williams1992volume">(<a href="references.html#ref-sabella1988rendering" role="doc-biblioref">Sabella 1988</a>; <a href="references.html#ref-williams1992volume" role="doc-biblioref">Williams and Max 1992</a>)</span>, where attenuation coefficients are nowhere to be found.</p>
<p>For this reason, the raw volume data obtained from raw measurement device for scientific (medical) visualization are most often called the density field, even though what is being measured is almost certainly not the density field but a field of optical properties that are related to, but certainly do not equate, density. For instance, the raw data you get from a CT scanner is actually a grid of attenuation coefficients <span class="citation" data-cites="bharath2009introductory">(<a href="references.html#ref-bharath2009introductory" role="doc-biblioref">Bharath 2009</a>, Chpt. 3)</span>.</p>
</section>
</section>
<section id="sec-chpt-mat-vs-rte-nr" class="level3" data-number="10.4.4">
<h3 data-number="10.4.4" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-nr"><span class="header-section-number">10.4.4</span> Discrete VRE in (Neural) Radiance-Field Rendering</h3>
<p>There is another field where the discrete VRE (especially our second form <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>10.38</span></a>) is becoming incredibly popular: (neural) radiance-field rendering. The two most representative examples are NeRF <span class="citation" data-cites="mildenhall2021nerf">(<a href="references.html#ref-mildenhall2021nerf" role="doc-biblioref">Mildenhall et al. 2021</a>)</span> and 3D Gaussian Splatting (3DGS) <span class="citation" data-cites="kerbl20233d">(<a href="references.html#ref-kerbl20233d" role="doc-biblioref">Kerbl et al. 2023</a>)</span>. They are fundamentally image-based rendering or light-field rendering (<a href="rendering-basics.html#sec-chpt-mat-basics-radiometry-lf" class="quarto-xref"><span>Section 8.6</span></a>), where they sample the light field of the scene by taking a set of images at different camera poses and learn to reconstruct the underlying light field, from which they can then re-sample a new camera pose and, thus, render the corresponding image as if it was taken at that new camera pose. This is re-branded in the modern era as “novel view synthesis”.</p>
<p>We will assume that you have read the two papers above so that we can focus on interpreting these radiance-field methods within the fundamental framework of physically-based rendering. Such a re-interpretation would allow us to better understand where these methods come from, how they have introduced new tweaks to physically-based rendering, and what their limitations might be.</p>
<p>The first thing to notice is that NeRF and 3DGS, being essentially a sampling and reconstruction method, use the discrete form of the VRE (mostly <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>10.38</span></a>) as the reconstruction function. This means they assume that the radiance is calculated by a single-path summation along the ray trajectory without the need for path tracing and solving the actual RTE/VRE. The reason they can reduce infinite paths to a single-path evaluation is very similar to that in scientific visualization, except now instead of assigning the “color” values <span class="math inline">\(C\)</span> and opacity values <span class="math inline">\(\alpha\)</span> (or equivalently the density field as discussed above), they train a neural network to directly learn these values.</p>
<section id="sec-chpt-mat-vs-rte-nr-why" class="level4">
<h4 class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-nr-why">VRE for Surface Rendering?</h4>
<p>It is interesting to observe that both NeRF and 3DGS (and the vast majority of their later developments) use the discrete VRE form in <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>10.38</span></a> as their forward model and can evidently do a very good job at rendering opaque surfaces. Is this surprising? Isn’t <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>10.38</span></a> designed to render transparent materials/volumes (alpha blending)?</p>
<p>For opaque surfaces, the “ground truth” is the surface rendering equation (<a href="rendering-surface.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 9.3</span></a>), which can be seen as a form of weighted sum, where the BRDF <span class="math inline">\(f_r(p, \os, \oi)\)</span> weighs the incident light irradiance <span class="math inline">\(L(p, \oi) \cos\theta_i \text{d}\oi\)</span>. In theory, the weights are independent of each other: the value of <span class="math inline">\(f_r(p, \os, \oi)\)</span> at different <span class="math inline">\(\oi\)</span> can technically be completely uncorrelated. But in reality they are most likely somewhat correlated for real materials: the appearance of a material does not change dramatically when the incident light direction changes slightly. For volumes/translucent materials, the “ground truth” is the VRE, which you could also say is a weighted sum, although the weights are constrained if the <span class="math inline">\(\alpha\)</span> values are constrained (e.g., between 0 and 1), which is the case in NeRF and 3DGS training (<a href="#sec-chpt-mat-vs-rte-vis-compare" class="quarto-xref"><span>Section 10.4.3.2</span></a>).</p>
<p>So effectively, when rendering opaque surfaces, we are using a form of (theoretically) constrained weighted sum to approximate another (practically) constrained weighted sum, and we hope that we can learn the approximation from a large amount of offline samples. The learned parameters (color and opacity of each point) should not be interpreted literally in the physical sense. One advantage of this parameterization is that it <em>could</em> be used to render volumes or translucent materials if needed, where the ground truth <em>is</em> the VRE, in which case the learned parameters might be more amenable to physical interpretations.</p>
</section>
<section id="volume-graphics-vs.-point-based-graphics" class="level4">
<h4 class="anchored" data-anchor-id="volume-graphics-vs.-point-based-graphics">Volume Graphics vs.&nbsp;Point-Based Graphics</h4>
<p>Related to volume graphics, there is also a subtly different branch of graphics called <strong>point-based graphics</strong> (PBG) <span class="citation" data-cites="levoy1985use gross2011point">(<a href="references.html#ref-levoy1985use" role="doc-biblioref">Levoy and Whitted 1985</a>; <a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011</a>)</span>. The boundary is somewhat blurred, but given the way the two terms are usually used, we can observe a few similarities and distinctions. Both volume graphics and PBG use discrete points as the rendering primitives (as opposed to continuous surfaces such as a mesh), although the input points in volume graphics are usually placed on uniform grids <span class="citation" data-cites="engel2004real">(<a href="references.html#ref-engel2004real" role="doc-biblioref">Engel et al. 2006</a>, Chpt. 1.5.2)</span> whereas points in PBG can be spatially arbitrary.</p>
<p>Traditionally, PBG is almost exclusively used for photorealistic rendering of surfaces. In fact, the points used in PBG are usually acquired as samples on continuous surfaces <span class="citation" data-cites="gross2011point">(<a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011</a>, Chpt. 3)</span>. PBG usually uses object-order rendering through splatting, although ray casting is used too, but RTE/VRE is not involved in the rendering process <span class="citation" data-cites="gross2011point">(<a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011</a>, Chpt. 6)</span>.</p>
<p>In contrast, the use of volume graphics is much broader. Volume rendering can be used for photorealistic rendering of participating media and translucent surfaces (by solving the RTE/VRE), or it can be used for non-photorealistic data visualization (by evaluating the single-path, discrete VRE), at which point whether the object to be rendered is called a participating medium, a translucent surface, or anything else is irrelevant, because visualization does not care much about being physically accurate.</p>
<p>3DGS is a somewhat interesting case. It is largely a form of PBG because the rendering primitives are unaligned surface samples, and its splatting technique (which we will discuss shortly) resembles that developed in the PBG literature <span class="citation" data-cites="gross2011point">(<a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011</a>, Chpt. 6.1)</span>. However, 3DGS does use the discrete VRE as the forward model. Again, as discussed just above, VRE is just a way for 3DGS to parameterize its forward mode, so the comparison with traditional volume graphics and PBG should not be taken literally.</p>
</section>
<section id="sec-chpt-mat-vs-rte-nr-splatting" class="level4">
<h4 class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-nr-splatting">Splatting is Signal Filtering</h4>
<p>Splatting, initially proposed by <span class="citation" data-cites="westover1990footprint">Westover (<a href="references.html#ref-westover1990footprint" role="doc-biblioref">1990</a>)</span> for visualizing volume data, is a common rendering technique used in PBG and 3DGS-family models. We discuss what splatting is, why it works, and how it is used in NeRF and 3DGS. We start by asking: how can we render continuous surfaces from discrete points? If we directly project the points to the sensor plane, we obviously will get holes, as shown in <a href="#fig-splatting" class="quarto-xref">Figure&nbsp;<span>10.10</span></a> (a). This is, of course, not an issue if the rendering primitives are meshes (or procedurally-generated surfaces).</p>
<div id="fig-splatting" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-splatting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/splatting_new.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-splatting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.10: (a): directly projecting discrete points to the image plane would create holes in the rendered image. (b): in splatting, each point is associated with a splat or a footprint function, which can distribute the color of the point to a spatial region on the image plane. (c): splatting essentially allows signal interpolation, which amounts to first reconstructing the underlying signal from the samples (with potential anti-aliasing filtering) followed by re-sampling at new, desired positions.
</figcaption>
</figure>
</div>
<p>The key is to realize that “meshless” does not mean surfaceless: the fact that we do not have a mesh as the rendering primitives does not mean the surface does not exist. Recall that the points used by PBG are actually samples on the surface. To render an image pixel is essentially to estimate the color of a surface point that projects to the pixel (ignoring supersampling for now). From a signal processing perspective, this is a classic problem of signal filtering: reconstruction and resampling.</p>
<p>That is, ideally what we need to do is to reconstruct the underlying signal, i.e., the color distribution of the continuous surface<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> (combined with an anti-aliasing pre-filter<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>) and then resample the reconstructed/filtered signal at positions corresponding to pixels in an image. This is shown in <a href="#fig-splatting" class="quarto-xref">Figure&nbsp;<span>10.10</span></a> (c). %This amounts to applying a single composite filter <span class="math inline">\(F\)</span> at new sampling positions, and The name of the game is to design proper filters. The issue of signal sampling, reconstruction, and resampling is absolutely fundamental to all forms of photorealistic rendering and not limited to PBG; <span class="citation" data-cites="pharr2023physically">Pharr, Jakob, and Humphreys (<a href="references.html#ref-pharr2023physically" role="doc-biblioref">2023</a>, Chpt. 8)</span> and <span class="citation" data-cites="glassner1995principles">Glassner (<a href="references.html#ref-glassner1995principles" role="doc-biblioref">1995</a>, Unit II)</span> are great references.</p>
<p>Another way to think of this is that the color of a surface point is very likely related to its nearby points that have been sampled as part of the rendering input, so one straightforward thing to do is to interpolate from those samples to calculate colors of new surface points. Signal interpolation is essentially signal filtering/convolution.</p>
<p>There is one catch. In classic signal sampling theories (think of the Nyquist-Shannon sampling theorem), samples are uniformly taken and, as a result, we can use a single reconstruction filter. But in PBG the surface samples are non-uniformly taken, so a single reconstruction filter would not work. Instead, we need a different filter for each point. The filter in the PBG parlance is called a <em>splat</em>, or a <em>footprint function</em>; it is associated with each point (surface sample) and essentially distributes the point color to a local region, enabling signal interpolation. This is shown in <a href="#fig-splatting" class="quarto-xref">Figure&nbsp;<span>10.10</span></a> (b). The exact forms of the footprint functions would determine the exact forms of the signal filters. Gaussian filters are particularly common, and Gaussian splatting is a splatting method that uses Gaussian filters <span class="citation" data-cites="greene1986creating heckbert1989fundamentals zwicker2001surface">(<a href="references.html#ref-greene1986creating" role="doc-biblioref">Greene and Heckbert 1986</a>; <a href="references.html#ref-heckbert1989fundamentals" role="doc-biblioref">Heckbert 1989</a>; <a href="references.html#ref-zwicker2001surface" role="doc-biblioref">Zwicker et al. 2001b</a>)</span>.</p>
<p>From a 3D modeling perspective, instead of having a continuous mesh, the scene is now represented by a set of discrete points, each of which is represented by a 2D Gaussian distribution, which is called a surface element or a surfel <span class="citation" data-cites="pfister2000surfels">(<a href="references.html#ref-pfister2000surfels" role="doc-biblioref">Pfister et al. 2000</a>)</span>. Each surfel is then projected to the screen space to generate a splat as the corresponding reconstruction kernel of that surface point; the reconstruction kernel, after projection, is another Gaussian filter (which can be cascaded with an anti-aliasing pre-filter). The color of each screen space point is then calculated by summing over all the splats (each of which is, of course, scaled by the color of the sample), essentially taking a weighted sum of the colors of the neighboring surface samples (see <span class="citation" data-cites="zwicker2001surface">Zwicker et al. (<a href="references.html#ref-zwicker2001surface" role="doc-biblioref">2001b, fig. 3</a>)</span> for a visualization) or, in signal processing parlance, resampling the reconstructed signal with the reconstruction kernels.</p>
<p>This rendering process is traditionally called surface splatting <span class="citation" data-cites="zwicker2001surface">(<a href="references.html#ref-zwicker2001surface" role="doc-biblioref">Zwicker et al. 2001b</a>)</span>. <span class="citation" data-cites="yifan2019differentiable">Yifan et al. (<a href="references.html#ref-yifan2019differentiable" role="doc-biblioref">2019</a>)</span> is an early attempt to learn the surfels through a differential surface splatting process. Surface splatting is a reasonable rendering model in PBG: the “ground truth” in rendering surfaces is the rendering equation, which can also be interpreted as a weighted sum.</p>
<p>One can also apply the same splatting idea to volume rendering. In this case, each point in the scene is represented by a 3D Gaussian distribution, which is projected to a 2D splat in the screen space. The color of a pixel is then calculated through, critically, alpha blending the corresponding splats, not weighted sum. This is called volume splatting <span class="citation" data-cites="zwicker2001ewa">(<a href="references.html#ref-zwicker2001ewa" role="doc-biblioref">Zwicker et al. 2001a</a>)</span>. 3DGS can be seen as a differential variant of traditional volume splatting, even though it is also very effective in rendering opaque surfaces (and we have discussed the reason on <a href="#sec-chpt-mat-vs-rte-nr-why" class="quarto-xref"><span>Section 10.4.4.1</span></a>).</p>
</section>
</section>
<section id="sec-chpt-mat-vs-sca-bssrdf" class="level3" data-number="10.4.5">
<h3 data-number="10.4.5" class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-bssrdf"><span class="header-section-number">10.4.5</span> Integrating Surface Scattering with Volume Scattering</h3>
<p>The rendering equation governs the surface scattering or light transport in space, and the RTE/VRE governs the volume/subsurface scattering or light transport in a medium. Both processes can be involved in a real-life scene. For instance, the appearance of a translucent material like a paint or a wax is a combination of both forms of scattering/light transport (<a href="#fig-photon_particle_interactions" class="quarto-xref">Figure&nbsp;<span>10.1</span></a>). Another example would be rendering smoke against a wall.</p>
<!-- %https://pbr-book.org/4ed/Light_Transport_II_Volume_Rendering/Volume_Scattering_Integrators -->
<p>Conceptually nothing new needs to be introduced to deal with the two forms of light transport together. Say we have an opaque surface (a wall) located with a volume (smoke) in the scene. If we want to calculate the radiance of a ray leaving a point on the wall, we would evaluate the rendering equation there, and for each incident ray, we might have to evaluate the VRE since that ray might come from the volume. In practice it amounts to extending the path tracing algorithm to account for the fact that a path might go through a volume and bounce off between surface points. See <span class="citation" data-cites="pharr2023physically">Pharr, Jakob, and Humphreys (<a href="references.html#ref-pharr2023physically" role="doc-biblioref">2023</a>, Chpt. 14.2)</span> and <span class="citation" data-cites="fong2017production">Fong et al. (<a href="references.html#ref-fong2017production" role="doc-biblioref">2017</a>, Sect. 3)</span> for detailed discussions.</p>
<p>Another approach, which is perhaps more common when dealing with translucent materials (whose appearance, of course, depends on both the surface and subsurface scattering), is through a phenomenological model based on the notion of Bidirectional Scattering Surface Reflectance Distribution Function (<strong>BSSRDF</strong>) <span class="citation" data-cites="nicodemus1977geometrical">(<a href="references.html#ref-nicodemus1977geometrical" role="doc-biblioref">Nicodemus et al. 1977</a>)</span>. The BSSRDF is parameterized as <span class="math inline">\(f_s(p_s, \os, p_i, \oi)\)</span>, describing the infinitesimal outgoing radiance at <span class="math inline">\(p_s\)</span> toward <span class="math inline">\(\os\)</span> given the infinitesimal power incident on <span class="math inline">\(p_i\)</span> from the direction <span class="math inline">\(\oi\)</span>:</p>
<p><span id="eq-bssrdf"><span class="math display">\[
\begin{align}
    f_s(p_s, \os, p_i, \oi) = \frac{\text{d}L(p_s, \os)}{\text{d}\Phi(p_i, \oi)}.
\end{align}
\tag{10.40}\]</span></span></p>
<p>BSSRDF can be seen as an extension of BRDF in that it considers the possibility that the radiance of a ray leaving <span class="math inline">\(p_s\)</span> could be influenced by a ray incident on another point <span class="math inline">\(p_i\)</span> due to SSS/volume scattering. Given the BSSRDF, the rendering equation can be generalized to:</p>
<p><span id="eq-re_sss"><span class="math display">\[
\begin{align}
    L(p_o, \os) = \int^A\int^{\Omega=2\pi} f_s(p_s, \os, p_i, \oi) L(p_i, \oi) \cos\theta_i \doi \d A,
\end{align}
\tag{10.41}\]</span></span></p>
<p>where <span class="math inline">\(L(p_o, \os)\)</span> is the outgoing radiance at <span class="math inline">\(p_o\)</span> toward <span class="math inline">\(\os\)</span>, <span class="math inline">\(L(p_i, \oi)\)</span> is the incident radiance at <span class="math inline">\(p_i\)</span> from <span class="math inline">\(\oi\)</span>, <span class="math inline">\(A\)</span> in the outer integral is the surface area that is under illumination, and <span class="math inline">\(\Omega=2\pi\)</span> means that each surface point receives illumination from the entire hemisphere.</p>
<p>We can again use path tracing and Monte Carlo integration to evaluate <a href="#eq-re_sss" class="quarto-xref">Equation&nbsp;<span>10.41</span></a> if we know the BSSRDF, which can, again, either be analytically derived given certain constraints and assumptions or measured <span class="citation" data-cites="frisvad2020survey">(<a href="references.html#ref-frisvad2020survey" role="doc-biblioref">Frisvad et al. 2020</a>)</span>. To analytically derive it, one has to consider the fact that the transfer of energy from an incident ray to an outgoing ray is the consequence of a cascade of three factors: two surface scattering (refraction) factors, one entering the material surface <span class="math inline">\(p_i\)</span> from <span class="math inline">\(\oi\)</span> and the other leaving the material surface at <span class="math inline">\(p_i\)</span> toward <span class="math inline">\(p_o\)</span>, and a volume scattering factor that accounts for the subsurface scattering between the incident ray at <span class="math inline">\(p_i\)</span> and the exiting ray at <span class="math inline">\(p_o\)</span> <span class="citation" data-cites="pharr2018physically">(<a href="references.html#ref-pharr2018physically" role="doc-biblioref">Pharr, Jakob, and Humphreys 2018</a>, Chpt. 11.4)</span>. If all three factors have an analytical form, the final BSSRDF has an analytical form too. This is the approach that, for instance, <span class="citation" data-cites="wann2001practical">Jensen et al. (<a href="references.html#ref-wann2001practical" role="doc-biblioref">2001</a>)</span> takes.</p>
</section>
</section>
<section id="sec-chpt-mat-vs-km" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="sec-chpt-mat-vs-km"><span class="header-section-number">10.5</span> The Kubelka–Munk Model</h2>
<p>As discussed in <a href="#sec-chpt-mat-vs-rte-rte" class="quarto-xref"><span>Section 10.4.1</span></a>, the general RTE is difficult to solve, and there are two general strategies. <a href="#sec-chpt-mat-vs-rte-rte" class="quarto-xref"><span>Section 10.4.1</span></a> discusses one strategy that numerically approximates the solution using Monte Carlo methods. Another common strategy is to make some simplified assumptions and/or apply additional constraints, which would allow us to derive analytical solutions. This section discusses perhaps the most aggressive form of simplification that, nevertheless, is very widely used, especially in the printing, painting, and dye industry (and to some extent in graphics).</p>
<p>Kubelka and Munk, two Czechoslovakian chemists, built a phenomenological model that estimates the spectral reflectance/transmittance of a material <span class="citation" data-cites="kubelka1931beitrag kubelka1931article kubelka1948new">(<a href="references.html#ref-kubelka1931beitrag" role="doc-biblioref">Kubelka and Munk 1931b</a>, <a href="references.html#ref-kubelka1931article" role="doc-biblioref">1931a</a>; <a href="references.html#ref-kubelka1948new" role="doc-biblioref">Kubelka 1948</a>)</span>. Their model cares only about the hemispherical-hemispherical reflectance (<a href="rendering-surface.html#sec-chpt-mat-ss-reflectance" class="quarto-xref"><span>Section 9.2</span></a>), i.e., the ratio of total flux scattered upward to the hemisphere to the total toward flux incident from the hemisphere. The K-M model also considers that the material under modeling is in immediate contact with a <em>Lambertian</em> substrate that reflects light uniformly over all directions. This is a common scenario in scenarios such as paints on a canvas, dyes on textiles, printer inks on paper, coatings on films, etc.</p>
<!-- %\fixme{diffuse assumption is technically wrong; use Fig. 2.5 in Bohren and the light absorption into a tube.} -->
<p>We will go through an excruciatingly long derivation, but the intuitions behind the derivation are exactly the same as that of the RTE, because the K-M model is a simplification of the RTE. The derivation allows us to make clear what simplifications we have made and, thus, when the model is and is not applicable.</p>
<section id="sec-chpt-mat-vs-km-derivation" class="level3" data-number="10.5.1">
<h3 data-number="10.5.1" class="anchored" data-anchor-id="sec-chpt-mat-vs-km-derivation"><span class="header-section-number">10.5.1</span> Deriving the Model</h3>
<p><a href="#fig-km_model" class="quarto-xref">Figure&nbsp;<span>10.11</span></a> illustrates the setup that we will use to derive the model. The first important assumption that the K-M model makes is that the every point on the material surface receives exactly the same irradiance and that the material itself is homogeneous, consisting of particles that are statistically randomly distributed and oriented. As a result, there is no difference between different positions at the same depth anywhere inside the material. Of course the radiation fields at different depths are different; at the very least, the deeper you go, the fewer photons there are due to absorption. Another way to think of this is that we are intentionally limiting our consideration to only a small area where there is no spatial difference at the same depth, so we can analyze information only at different depths rather than different positions at the same depth.</p>
<div id="fig-km_model" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-km_model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/km_model.svg" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-km_model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.11: The setup of deriving the K-M model. We focus on the change of downward irradiance (<span class="math inline">\(E_{\downarrow}\)</span>) and upward irradiance (<span class="math inline">\(E_{\uparrow}\)</span>) as they travel a thin layer <span class="math inline">\(\D x\)</span>. We make the assumption that the material is an isotropic medium and is homogeneous spatially.
</figcaption>
</figure>
</div>
<p>We focus on a very thin layer <span class="math inline">\(\D x\)</span>; since there are no differences between horizontal positions, we can arbitrarily pick a point at depth <span class="math inline">\(0 \leq x \leq X\)</span> for analysis, where <span class="math inline">\(X\)</span> is the total depth (the material surface has <span class="math inline">\(x=0\)</span> and the material bottom has <span class="math inline">\(x=X\)</span>). The point at <span class="math inline">\(x\)</span> receives photons from all directions. Let’s say all the downward photons (going to the lower hemisphere) have a total irradiance of <span class="math inline">\(E_{\downarrow}(x)\)</span> and all the upward photons (going to the upper hemisphere) have a total irradiance of <span class="math inline">\(E_{\uparrow}(x)\)</span>. The (hemispherical-hemispherical) reflectance at <span class="math inline">\(x\)</span> is then the ratio of the two:</p>
<p><span class="math display">\[
\begin{align}
    R(x) = \frac{E_{\uparrow}(x)}{E_{\downarrow}(x)},
\end{align}
\]</span></p>
<p>and the reflectance at the material surface (which is what the K-M model is interested in calculating) is <span class="math inline">\(R(0)\)</span>.</p>
<p>How do we express <span class="math inline">\(E_{\downarrow}(x)\)</span>? As usual, we set a differential equation to describe the change of <span class="math inline">\(E_{\downarrow}(x)\)</span>. Consider the following conservation of energy when <span class="math inline">\(E_{\downarrow}(x)\)</span> goes through the thin layer <span class="math inline">\(\D x\)</span>:</p>
<p><span id="eq-km_raw"><span class="math display">\[
\begin{align}
    E_{\downarrow}(x + \D x) - E_{\downarrow}(x) = &amp; - \int^{S^2_+}\sigma_a(x, \omega) \D x L(x, \omega) \do \label{eq:km_down_1} \\
    &amp; - \int^{S^2_+}\int^{S^2_+}\sigma_s(x, \omega) f_p(x, \omega', \omega) \D x L(x, \omega) \do' \do \label{eq:km_down_2} \\
    &amp; + \int^{S^2_-}\int^{S^2_-}\sigma_s(x + \D x, \omega) f_p(x + \D x, \omega', \omega) \D x L(x + \D x, \omega) \do' \do,  \label{eq:km_down_3}
\end{align}
\tag{10.42}\]</span></span></p>
<p>where <span class="math inline">\(S^2_+\)</span> and <span class="math inline">\(S^2_-\)</span> represent the upper and lower hemispheres, respectively; <span class="math inline">\(L(x, \omega)\)</span> is the radiance coming from direction <span class="math inline">\(\omega\)</span> incident on a point of depth <span class="math inline">\(x\)</span>, <span class="math inline">\(f_p(x, \omega', \omega)\)</span> is the phase function between the incident direction <span class="math inline">\(\omega\)</span> and outgoing direction <span class="math inline">\(\omega'\)</span>, and <span class="math inline">\(\sigma_s(x, \omega)\)</span> is the scattering coefficient at <span class="math inline">\(x\)</span> for an incident direction <span class="math inline">\(\omega\)</span> (<a href="#sec-chpt-mat-vs-sca-single" class="quarto-xref"><span>Section 10.3.2</span></a>).</p>
<p>The interpretation of this equation is exactly the same as that of the RTE. The equation essentially says that the downward irradiance after traveling <span class="math inline">\(\D x\)</span> is (omitting emission):</p>
<ul>
<li>reduced by absorption (the first negative term in <a href="#eq-km_raw" class="quarto-xref">Equation&nbsp;<span>10.42</span></a>), which is the absorption component in the RTE;</li>
<li>reduced by upward scattering (the second negative term in <a href="#eq-km_raw" class="quarto-xref">Equation&nbsp;<span>10.42</span></a>), which is the out-scattering component in the RTE;</li>
<li>increased by the downward-scattering of upward irradiance reaching the bottom of the thin layer (the positive term in <a href="#eq-km_raw" class="quarto-xref">Equation&nbsp;<span>10.42</span></a>), which is the in-scattering component in RTE.</li>
</ul>
<p>Now let’s take a closer look at the absorption term in <a href="#eq-km_raw" class="quarto-xref">Equation&nbsp;<span>10.42</span></a> and re-write it:</p>
<p><span id="eq-km_s_2"><span class="math display">\[
\begin{align}
    \int^{S^2_+}\sigma_a(x, \omega) \D x L(x, \omega) \do = \sigma_a(x, \bar{\omega}) \D x \int^{S^2_+} L(x, \omega) \do.
\end{align}
\tag{10.43}\]</span></span></p>
<p><a href="#eq-km_s_2" class="quarto-xref">Equation&nbsp;<span>10.43</span></a> is derived based on the <strong>mean-value theorem</strong><a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> in integral calculus, which says that there exists <em>some</em> value of <span class="math inline">\(\bar{\omega}\in S^2_+\)</span> that would allow us to take the <span class="math inline">\(\sigma_a\)</span> term out of the integral. Once we do that, the integral on the right-hand side of <a href="#eq-km_s_2" class="quarto-xref">Equation&nbsp;<span>10.43</span></a> is simply the total downward irradiance, which we denote <span class="math inline">\(E_{\downarrow}(x)\)</span>.</p>
<p>If we further assume that the material absorption is isotropic, then <span class="math inline">\(\sigma_a(x, \bar{\omega})\)</span> is independent of <span class="math inline">\(\bar{\omega}\)</span> and is simply a function of <span class="math inline">\(x\)</span>, so we write it as <span class="math inline">\(K_{\downarrow}(x)\)</span>, which allows us to re-write <a href="#eq-km_s_2" class="quarto-xref">Equation&nbsp;<span>10.43</span></a> as:</p>
<p><span id="eq-km_s_3"><span class="math display">\[
\begin{align}
    \int^{S^2_+}\sigma_a(x, \omega) \D x L(x, \omega) \do = K_{\downarrow}(x) \D x E_{\downarrow}(x).
\end{align}
\tag{10.44}\]</span></span></p>
<p><span class="math inline">\(K_{\downarrow}(x)\)</span> is a phenomenological coefficient, but it is related to the fundamental absorption coefficient <span class="math inline">\(\sigma_a\)</span> and, thus, carries physical meanings. This is clear from <a href="#eq-km_s_4" class="quarto-xref">Equation&nbsp;<span>10.45</span></a>:</p>
<p><span id="eq-km_s_4"><span class="math display">\[
\begin{align}
    K_{\downarrow}(x) = \frac{\int^{S^2_+}\sigma_a(x, \omega) L(x, \omega) \do}{\D x E_{\downarrow}(x)}.
\end{align}
\tag{10.45}\]</span></span></p>
<p><span class="math inline">\(K_{\downarrow}(x)\)</span>, by definition, represents the fraction of downward irradiance that is absorbed per unit length. Therefore, <span class="math inline">\(K_{\downarrow}(x)\)</span> can be intuitively interpreted as the effective <em>downward absorption coefficient</em> at depth <span class="math inline">\(x\)</span>. Note that while the mean-value theorem tells us that <em>some</em> <span class="math inline">\(\bar{\omega}\in S^2_+\)</span> exists, it does not tell us what its values is. In reality, <span class="math inline">\(K_{\downarrow}(x)\)</span> will very much depend on <span class="math inline">\(L(x, \omega)\)</span>.</p>
<p>Similarly, we can rewrite the upward scattering term in <a href="#eq-km_raw" class="quarto-xref">Equation&nbsp;<span>10.42</span></a> by first rearranging the terms:</p>
<p><span id="eq-km_ku_1b"><span class="math display">\[
\begin{align}
    &amp;\int^{S^2_+}\int^{S^2_+}\sigma_s(x, \omega) f_p(x, \omega', \omega) \D x L(x, \omega) \do' \do \\
    = &amp;\int^{S^2_+}\Big(\int^{S^2_+}\sigma_s(x, \omega) f_p(x, \omega', \omega) \do'\Big) \D x L(x, \omega) \do.
\end{align}
\tag{10.46}\]</span></span></p>
<p>We then invoke the mean-value theorem again, which says that there exists <span class="math inline">\(\bar{\omega}\in S^2_+\)</span> that allows us to write the upward scattering term as:</p>
<p><span id="eq-km_ku_2"><span class="math display">\[
\begin{align}
    (\int^{S^2_+}\sigma_s(x, \bar{\omega}) f_p(x, \omega', \bar{\omega}) \do' \D x) \int^{S^2_+}L(x, \omega) \do.
\end{align}
\tag{10.47}\]</span></span></p>
<p>We use <span class="math inline">\(S_{\downarrow\uparrow}(x)\)</span> to denote the first integral in <a href="#eq-km_ku_2" class="quarto-xref">Equation&nbsp;<span>10.47</span></a>: <span class="math inline">\(S_{\downarrow\uparrow}(x) = \int^{S^2_+}\sigma_s(x, \bar{\omega}) f_p(x, \omega', \bar{\omega}) \do'\)</span>, which means the upward scattering term can be simplied to:</p>
<p><span id="eq-km_ku_3"><span class="math display">\[
\begin{align}
    S_{\downarrow\uparrow}(x) \D x E_{\downarrow}(x).
\end{align}
\tag{10.48}\]</span></span></p>
<p>Combining <a href="#eq-km_ku_1b" class="quarto-xref">Equation&nbsp;<span>10.46</span></a> and <a href="#eq-km_ku_3" class="quarto-xref">Equation&nbsp;<span>10.48</span></a>, we get: <span id="eq-km_ku_4"><span class="math display">\[
\begin{align}
    S_{\downarrow\uparrow}(x) = &amp; \frac{\int^{S^2_+}\int^{S^2_+}\sigma_s(x, \omega) f_p(x, \omega', \omega) L(x, \omega) \do' \do}{\D x E_{\downarrow}(x)}.
\end{align}
\tag{10.49}\]</span></span></p>
<p><span class="math inline">\(S_{\downarrow\uparrow}(x)\)</span> is again a phenomenological coefficient that is related to the fundamental scattering coefficient. Its physical interpretation is clear from <a href="#eq-km_ku_4" class="quarto-xref">Equation&nbsp;<span>10.49</span></a>: it is the fraction of the downward irradiance that is scattered upward per unit length. We can think of it as the effective “upward scattering coefficient of the downward irradiance”.</p>
<p>Finally, we can do the same thing to the downward scattering term in <a href="#eq-km_raw" class="quarto-xref">Equation&nbsp;<span>10.42</span></a>:</p>
<p><span id="eq-km_kd_1"><span class="math display">\[
\begin{align}
    \int^{S^2_-}\int^{S^2_-}\sigma_s(x + \D x, \omega) f_p(x + \D x, \omega', \omega) \D x L(x + \D x, \omega) \do' \do
\end{align}
\tag{10.50}\]</span></span></p>
<p>by first invoking the mean-value theorem and re-express it as:</p>
<p><span id="eq-km_kd_2"><span class="math display">\[
\begin{align}
    (\int^{S^2_-}\sigma_s(x + \D x, \hat{\omega}) f_p(x + \D x, \omega', \hat{\omega}) \do' \D x) \int^{S^2_-}L(x + \D x, \omega) \do.
\end{align}
\tag{10.51}\]</span></span></p>
<p>We use <span class="math inline">\(S_{\uparrow\downarrow}(x)\)</span> to denote the first integral in <a href="#eq-km_kd_2" class="quarto-xref">Equation&nbsp;<span>10.51</span></a>. The second integral in <a href="#eq-km_kd_2" class="quarto-xref">Equation&nbsp;<span>10.51</span></a> is essentially the total upward irradiance at the depth <span class="math inline">\(x+\D x\)</span>, which we denote <span class="math inline">\(E_{\uparrow}(x + \D x)\)</span>. Therefore, the downward scattering term becomes:</p>
<p><span id="eq-km_kd_3"><span class="math display">\[
\begin{align}
    S_{\uparrow\downarrow}(x + \D x) \D x E_{\uparrow}(x + \D x).
\end{align}
\tag{10.52}\]</span></span></p>
<p>Combining <a href="#eq-km_kd_1" class="quarto-xref">Equation&nbsp;<span>10.50</span></a> and <a href="#eq-km_kd_3" class="quarto-xref">Equation&nbsp;<span>10.52</span></a>, we have:</p>
<p><span id="eq-km_kd_5"><span class="math display">\[
\begin{align}
    S_{\uparrow\downarrow}(x + \D x) = &amp; \frac{\int^{S^2_-}\int^{S^2_-}\sigma_s(x + \D x, \omega) f_p(x + \D x, \omega', \omega) \D x L(x + \D x, \omega) \do' \do}{\D x E_{\uparrow}(x + \D x)},\\
    S_{\uparrow\downarrow}(x) = &amp; \frac{\int^{S^2_-}\int^{S^2_-}\sigma_s(x, \omega) f_p(x, \omega', \omega) \D x L(x, \omega) \do' \do}{\D x E_{\uparrow}(x)}.
\end{align}
\tag{10.53}\]</span></span></p>
<p>Now plug <a href="#eq-km_s_3" class="quarto-xref">Equation&nbsp;<span>10.44</span></a>, <a href="#eq-km_ku_3" class="quarto-xref">Equation&nbsp;<span>10.48</span></a>, and <a href="#eq-km_kd_3" class="quarto-xref">Equation&nbsp;<span>10.52</span></a> back into <a href="#eq-km_raw" class="quarto-xref">Equation&nbsp;<span>10.42</span></a>, we get:</p>
<p><span class="math display">\[
\begin{align}
    E_{\downarrow}(x + \D x) = E_{\downarrow}(x) - K_{\downarrow}(x) \D x E_{\downarrow}(x) - S_{\downarrow\uparrow}(x) \D x E_{\downarrow}(x) + S_{\uparrow\downarrow}(x + \D x) \D x E_{\uparrow}(x + \D x).
\end{align}
\]</span></p>
<p>Rewrite it and take the limit as <span class="math inline">\(\D x \rightarrow 0\)</span>:</p>
<p><span id="eq-km_down"><span class="math display">\[
\begin{align}
    \frac{E_{\downarrow}(x + \D x) - E_{\downarrow}(x)}{\D x} &amp;= - K_{\downarrow}(x) E_{\downarrow}(x) - S_{\downarrow\uparrow}(x) E_{\downarrow}(x) + S_{\uparrow\downarrow}(x + \D x) E_{\uparrow}(x + \D x),\\
    \frac{\d E_{\downarrow}(x)}{\d x} &amp;= - K_{\downarrow}(x) E_{\downarrow}(x) - S_{\downarrow\uparrow}(x) E_{\downarrow}(x) + S_{\uparrow\downarrow}(x) E_{\uparrow}(x).
\end{align}
\tag{10.54}\]</span></span></p>
<p>Similarly we can express the rate of change of the upward irradiance <span class="math inline">\(E_{\uparrow}(x)\)</span> based on the same energy conservation constraint:</p>
<p><span id="eq-km_up"><span class="math display">\[
\begin{align}
    \frac{\d E_{\uparrow}(x)}{\d x} &amp;= K_{\uparrow}(x) E_{\uparrow}(x) + S_{\uparrow\downarrow}(x) E_{\uparrow}(x) - S_{\downarrow\uparrow}(x) E_{\downarrow}(x),
\end{align}
\tag{10.55}\]</span></span></p>
<p>where the three terms on the right-hand side, again, represent the absorption, out-scattering, and in-scattering in the original RTE.</p>
<p>Now a few more assumptions. If we assume that the material absorption is isotropic (the total absorption per unit length is invariant to incident light direction over the entire sphere), we have <span class="math inline">\(K_{\uparrow}(x) = K_{\downarrow}(x)\)</span> because:</p>
<p><span id="eq-km_abs_approx"><span class="math display">\[
\begin{align}
    K_{\uparrow}(x) = \sigma_a(x, \hat{\omega}) = \sigma_a(x, \bar{\omega}) = K_{\downarrow}(x),
\end{align}
\tag{10.56}\]</span></span></p>
<p>for some <span class="math inline">\(\hat{\omega} \in S^2_-\)</span> and <span class="math inline">\(\bar{\omega} \in S^2_+\)</span>.</p>
<p>If we further assume that 1) the material is an isotropic scattering medium, then <span class="math inline">\(\sigma_s(x, \omega)\)</span> is invariant to <span class="math inline">\(\omega\)</span> (the total amount of scattering per unit length does not change with the incident light direction over the entire sphere), and 2) the particles are also isotropic scatters (which theoretically do not exist), then <span class="math inline">\(f_p(x, \omega', \omega)\)</span> is a constant (<span class="math inline">\(\frac{1}{4\pi}\)</span>). Therefore, <span class="math inline">\(S_{\uparrow\downarrow}(x) = S_{\downarrow\uparrow}(x)\)</span>, because:</p>
<p><span id="eq-km_sca_approx"><span class="math display">\[
\begin{align}
    S_{\uparrow\downarrow}(x) &amp;= \int^{S^2_-}\sigma_s(x, \hat{\omega}) f_p(x, \omega', \hat{\omega}) \do' \\
    &amp;= \sigma_s(x, \hat{\omega}) \int^{S^2_-}f_p(x, \omega', \hat{\omega}) \do' = \sigma_s(x, \hat{\omega})/2 \\
    &amp;= \sigma_s(x, \bar{\omega}) \int^{S^2_-}f_p(x, \omega', \bar{\omega}) \do' = \sigma_s(x, \bar{\omega})/2 \\
    &amp;= S_{\downarrow\uparrow}(x),
\end{align}
\tag{10.57}\]</span></span></p>
<p>for some <span class="math inline">\(\hat{\omega} \in S^2_-\)</span> and <span class="math inline">\(\bar{\omega} \in S^2_+\)</span>.</p>
<p>A few notes on the assumptions here:</p>
<ul>
<li>The assumption of isotropic scatters is important; assuming only an isotropic medium is not enough. This is because the integrals in integrate only the upper (or lower) hemisphere rather than the entire sphere, so if the phase function itself is not a constant, the integral result will still depend on <span class="math inline">\(\bar{\omega}\)</span> or <span class="math inline">\(\hat{\omega}\)</span>. See the distinction between an isotropic medium and an isotropic scatter on <a href="#sec-chpt-mat-vs-sca-single-pf-iso" class="quarto-xref"><span>Section 10.3.3.2</span></a>.</li>
<li>Alternatively, if the particles are not isotropic scatters, <span class="math inline">\(S_{\uparrow\downarrow}(x) = S_{\downarrow\uparrow}(x)\)</span> can still hold if we assume that the upward and downward irradiance are both diffuse, i.e., the radiance <span class="math inline">\(L(x, \omega)\)</span> is invariant to <span class="math inline">\(\omega\)</span>. The isotropic medium assumption still needs to hold. This can be proven by going back to the respective definitions of <span class="math inline">\(S_{\uparrow\downarrow}(x)\)</span> and <span class="math inline">\(S_{\downarrow\uparrow}(x)\)</span> in <a href="#eq-km_ku_4" class="quarto-xref">Equation&nbsp;<span>10.49</span></a> and <a href="#eq-km_kd_5" class="quarto-xref">Equation&nbsp;<span>10.53</span></a><a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>. Interestingly, if the particles are isotropic scatters, the outgoing irradiance will necessarily be diffuse.</li>
<li>Yet another way for <span class="math inline">\(S_{\uparrow\downarrow}(x) = S_{\downarrow\uparrow}(x)\)</span> to hold is if we are considering a very idealized scenario where photons travel and are scattered only upward or downward <span class="citation" data-cites="bohren2006fundamentals">(<a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">Bohren and Clothiaux 2006</a>, Chpt. 5.2)</span>. If the medium is also isotropic (but does not have to consist of isotropic scatters), the fraction of the upward irradiance turned downward would be the same as the fraction of the downward irradiance turned upward, so <span class="math inline">\(S_{\uparrow\downarrow}(x) = S_{\downarrow\uparrow}(x)\)</span>.</li>
</ul>
<p>Finally, given the assumption that the material is spatially homogeneous, both <span class="math inline">\(\sigma_a\)</span>, <span class="math inline">\(\sigma_s\)</span>, and <span class="math inline">\(f_p\)</span> are all independent of <span class="math inline">\(x\)</span>. Therefore, we can denote <span class="math inline">\(K = K_{\uparrow}(x) = K_{\downarrow}(x)\)</span> and <span class="math inline">\(S = S_{\uparrow\downarrow}(x) = S_{\downarrow\uparrow}(x)\)</span>. <span class="math inline">\(K\)</span> and <span class="math inline">\(S\)</span> are simply called the absorption and scattering coefficients, respectively, of the medium, but we now should know that they are of the phenomenological nature and, with all the simplifications above, are derived from the fundamental optical absorption/scattering properties of the medium (see <a href="#eq-km_abs_approx" class="quarto-xref">Equation&nbsp;<span>10.56</span></a> and <a href="#eq-km_sca_approx" class="quarto-xref">Equation&nbsp;<span>10.57</span></a>).</p>
<p>Now we combine <a href="#eq-km_down" class="quarto-xref">Equation&nbsp;<span>10.54</span></a> and <a href="#eq-km_up" class="quarto-xref">Equation&nbsp;<span>10.55</span></a> and get to the famous pair of differential equations underlying the K-M model:</p>
<p><span id="eq-km_diff"><span class="math display">\[
\begin{align}
    \frac{\d E_{\downarrow}(x)}{\d x} &amp;= - (K +S)E_{\downarrow}(x) + S E_{\uparrow}(x), \\
    \frac{\d E_{\uparrow}(x)}{\d x} &amp;= (K + S)E_{\uparrow}(x) - S E_{\downarrow}(x).
\end{align}
\tag{10.58}\]</span></span></p>
</section>
<section id="sec-chpt-mat-vs-km-model" class="level3" data-number="10.5.2">
<h3 data-number="10.5.2" class="anchored" data-anchor-id="sec-chpt-mat-vs-km-model"><span class="header-section-number">10.5.2</span> The Model and Its Interpretation</h3>
<p><a href="#eq-km_diff" class="quarto-xref">Equation&nbsp;<span>10.58</span></a> gives us a pair of linear differential equations. What we are interested in solving for is <span class="math inline">\(R(0) = \frac{E_{\uparrow}(0)}{E_{\downarrow}(0)}\)</span>. The boundary condition is that <span class="math inline">\(R(X) = R_g\)</span>, which is the (assumed-to-be) known reflectance of the substrate. Solving the differential equations gives us:</p>
<p><span id="eq-km"><span class="math display">\[
\begin{align}
    &amp; R(0) = \frac{E_{\uparrow}(0)}{E_{\downarrow}(0)} = \frac{1-R_g[a-b\coth(bSX)]}{a-R_g+b\coth(bSX)},\\
    &amp; T(X) = \frac{E_{\downarrow}(X)}{E_{\downarrow}(0)} = \frac{b}{a\sinh(bSX)+b\cosh(bSX)},\\
    &amp; a = \frac{K+S}{S},\\
    &amp; b = \sqrt{a^2-1},
\end{align}
\tag{10.59}\]</span></span></p>
<p>where <span class="math inline">\(R(0)\)</span> is the hemispherical-hemispherical reflectance at the material surface and <span class="math inline">\(T(X)\)</span> is the hemispherical-hemispherical transmittance at the bottom of the material<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>; <span class="math inline">\(\coth(\cdot)\)</span> is the hyperbolic cotangent function, <span class="math inline">\(\sinh(\cdot)\)</span> is the hyperbolic sine function, and <span class="math inline">\(\cosh(\cdot)\)</span> is the hyperbolic cosine function. Note that we omit <span class="math inline">\(\lambda\)</span> for simplicity but keep in mind that <span class="math inline">\(R(0), T(X), S, K, R_g, a, b\)</span> are all spectral quantities.</p>
<p><a href="#eq-km" class="quarto-xref">Equation&nbsp;<span>10.59</span></a> is the famous K-M model. Consider the case where the material is purely absorptive and scatters little (e.g., dyes on textiles or fabrics), so <span class="math inline">\(S\)</span> is close to 0 and the reflectance is simplified to:</p>
<p><span id="eq-kmabs"><span class="math display">\[
\begin{align}
    R(0) = R_g e^{-2KX} = e^{-KX} R_g e^{-KX}.
\end{align}
\tag{10.60}\]</span></span></p>
<p>We can understand <span class="math inline">\(R_X\)</span> by decomposing it into the product of three terms, each representing a step in the overall, observed reflection. First, photons go through the material from the top down, being absorbed as they go. The percentage of photons that are still left (i.e., unabsorbed) just before they hit the substrate is <span class="math inline">\(e^{-KX}\)</span>, which is consistent with the Beer-Lambert law. Second, the substrate reflects <span class="math inline">\(R_g\)</span> amount of light back toward the material. Finally, as the photons make their way back to the surface, they go through another round of absorption governed by the same Beer-Lambert law (<a href="#sec-chpt-mat-vs-abs-simple" class="quarto-xref"><span>Section 10.2.1</span></a>).</p>
<p>Now consider the case where there is no substrate or when the substrate is a perfect black substrate; in both cases <span class="math inline">\(R_g = 0\)</span>. Reflectance is now:</p>
<p><span id="eq-black"><span class="math display">\[
\begin{align}
    R_{black} = \frac{1}{a+b\coth(bSX)}.
\end{align}
\tag{10.61}\]</span></span></p>
<p>Finally, consider the case where the material is so thick that no photon reaches the substrate. In this case, the reflectance is not affected by the substrate and can be simplified to (by letting <span class="math inline">\(X\)</span> approach infinity):</p>
<p><span id="eq-hide"><span class="math display">\[
\begin{align}
    \lim_{X \rightarrow \infty} = R_{\infty} = \frac{1}{a+b} = 1 + \frac{K}{S} - \sqrt{\Big(\frac{K}{S}\Big)^2 + 2 \frac{K}{S}}.
\end{align}
\tag{10.62}\]</span></span></p>
<p>In the painting industry, we say the paint’s “hiding is complete” when the substrate does not influence the material color. We can quantify the “hiding power” of a paint by <span class="math inline">\(H = \frac{R_{white}}{R_{black}}\)</span>, i.e., the ratio of reflectance between when the substrate is black (absorbs everything) and white (reflects everything back). If the hiding is complete, <span class="math inline">\(H\)</span> would be 1.</p>
<p>You might be wondering how we know <span class="math inline">\(K\)</span> and <span class="math inline">\(S\)</span> of a material — we measure them. For instance, observe <a href="#eq-black" class="quarto-xref">Equation&nbsp;<span>10.61</span></a> and <a href="#eq-hide" class="quarto-xref">Equation&nbsp;<span>10.62</span></a>; we can measure the reflectance <span class="math inline">\(R_{black}\)</span> when the substrate is nearly black and the reflectance <span class="math inline">\(R_{\infty}\)</span> when the hiding is near complete. We can then solve the system of equations to estimate <span class="math inline">\(K\)</span> and <span class="math inline">\(S\)</span>.</p>
<p>You can see that we are not actually taking a very thin layer of particles, illuminating it, and then measuring how much of the light is scattered vs.&nbsp;absorbed. Instead, we estimate <span class="math inline">\(K\)</span> and <span class="math inline">\(S\)</span> macroscopically. We have in mind a model (a set of equations or functions, if you will) that is parameterized by unknown variables. We then probe the model by giving it different inputs and measuring the outputs. From the input-output pairs, we can then estimate the unknown parameters. This is why a model so defined and derived is called a phenomenological model and the parameters (e.g., the <span class="math inline">\(K\)</span> and <span class="math inline">\(S\)</span> coefficients) are called the phenomenological parameters — because all we do is to observe the phenomena.</p>
</section>
<section id="sec-chpt-mat-vs-km-mix" class="level3" data-number="10.5.3">
<h3 data-number="10.5.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-km-mix"><span class="header-section-number">10.5.3</span> K-M Model for Mixture of Materials</h3>
<p>The basic K-M model can be extended to account for materials that consist of a mixture of materials, each with different absorption/scattering behaviors. This is done by first expressing the overall absorption and scattering coefficients of the mixture and then plugging them into the K-M model.</p>
<p>Specifically, if we are mixing <span class="math inline">\(N\)</span> materials, each with a phenomenological absorption and scattering coefficient <span class="math inline">\(K_i\)</span> and <span class="math inline">\(S_i\)</span>, the overall absorption and scattering coefficient of the material is:</p>
<p><span id="eq-ks_mix"><span class="math display">\[
\begin{align}
    K &amp;= \sum_{i=1}^N \eta_i K_i, \label{eq:ks_mix_k} \\
    S &amp;= \sum_{i=1}^N \eta_i S_i, \label{eq:ks_mix_s}
\end{align}
\tag{10.63}\]</span></span></p>
<p>where <span class="math inline">\(\eta_i\)</span> is the <em>volume concentration</em> of the <span class="math inline">\(i^{th}\)</span> material in the overall material mixture and is defined as:</p>
<p><span class="math display">\[
\begin{align}
    \eta_i = \frac{V_i}{\sum_{j=1}^N V_j},
\end{align}
\]</span></p>
<p>where <span class="math inline">\(V_j\)</span> is the volume of the <span class="math inline">\(j^{th}\)</span> material. Once we have the <span class="math inline">\(K\)</span> and <span class="math inline">\(S\)</span> coefficients, we simply invoke <a href="#eq-km" class="quarto-xref">Equation&nbsp;<span>10.59</span></a> to calculate the reflectance/transmittance of the material mixture.</p>
<p>Why would it make sense to calculate the overall <span class="math inline">\(K\)</span> and <span class="math inline">\(S\)</span> using the volume-weighting method in <a href="#eq-ks_mix" class="quarto-xref">Equation&nbsp;<span>10.63</span></a>? Let’s derive it using absorption as an example. The overall absorption coefficient <span class="math inline">\(K\)</span> of the material mixture is also the optical absorption coefficient <span class="math inline">\(\sigma_a\)</span> of the mixture (given the set of assumptions we have made so far; see <a href="#eq-km_abs_approx" class="quarto-xref">Equation&nbsp;<span>10.56</span></a>), which is given by <a href="#eq-absorbances_add" class="quarto-xref">Equation&nbsp;<span>10.11</span></a> as:</p>
<p><span class="math display">\[
\begin{align}
    K = \sigma_a = \sum_i^N c^i\epsilon^i,
\end{align}
\]</span></p>
<p>where <span class="math inline">\(c^i\)</span> and <span class="math inline">\(\epsilon^i\)</span> are the number concentration and the absorption cross section of the <span class="math inline">\(i^{th}\)</span> material in the material mixture. Specifically, <span class="math inline">\(c^i\)</span> is defined as:</p>
<p><span id="eq-num_conc"><span class="math display">\[
\begin{align}
    c^i = \frac{n_i}{\sum_{j=1}^N V_j} = \frac{V_i}{\sum_{j=1}^N V_j} \frac{n_i}{V_i},
\end{align}
\tag{10.64}\]</span></span></p>
<p>where <span class="math inline">\(n_i\)</span> is the number of particles of the <span class="math inline">\(i^{th}\)</span> material in the mixture. We assume that when we mix <span class="math inline">\(N\)</span> materials, their volumes add. That is, the volume of the mixture is the sum of that of the individual materials. This is in general true if different materials do not chemically react and if materials do not dissolve into each other. Therefore:</p>
<p><span id="eq-k_mix_2"><span class="math display">\[
\begin{align}
    K = \sum_i^N c^i\epsilon^i \label{eq:k_mix_1} = \sum_i^N \frac{V_i}{\sum_{j=1}^N V_j} \frac{n_i}{V_i} \epsilon^i = \sum_i^N \eta_i \frac{n_i}{V_i} \epsilon^i.
\end{align}
\tag{10.65}\]</span></span></p>
<p>We then, again, use the fact (<a href="#eq-km_abs_approx" class="quarto-xref">Equation&nbsp;<span>10.56</span></a>) that the phenomenological absorption coefficient of the <span class="math inline">\(i^{th}\)</span> material <span class="math inline">\(K_i\)</span> is the same as its optical absorption coefficient <span class="math inline">\(\sigma_{a, i} = c_i \epsilon_i\)</span>, where:</p>
<ul>
<li><span class="math inline">\(c_i = \frac{n_i}{V_i}\)</span> is the number concentration of the <span class="math inline">\(i^{th}\)</span> material <em>on its own</em> (note the subtle difference of <span class="math inline">\(c_i\)</span> here and <span class="math inline">\(c^i\)</span> in <a href="#eq-num_conc" class="quarto-xref">Equation&nbsp;<span>10.64</span></a>, which is the number concentration of the <span class="math inline">\(i^{th}\)</span> material in a mixture), and</li>
<li><span class="math inline">\(\epsilon_i\)</span> is just <span class="math inline">\(\epsilon^i\)</span>: they both refer to absorption cross section of the <span class="math inline">\(i^{th}\)</span> material, which does not change whether the material is in a mixture or not.</li>
</ul>
<p>Therefore: <span id="eq-k_mix_3"><span class="math display">\[
\begin{align}
    K = \sum_i^N \eta_i c_i \epsilon_i = \sum_i^N \eta_i K_i,
\end{align}
\tag{10.66}\]</span></span></p>
<p>which is exactly <a href="#eq-ks_mix" class="quarto-xref">Equation&nbsp;<span>10.63</span></a>.</p>
</section>
<section id="sec-chpt-mat-vs-km-nflux" class="level3" data-number="10.5.4">
<h3 data-number="10.5.4" class="anchored" data-anchor-id="sec-chpt-mat-vs-km-nflux"><span class="header-section-number">10.5.4</span> N-Stream Model</h3>
<p>The basic K-M model is called the two-stream or two-flux model, because it considers only the total upward irradiance and total downward irradiance. We basically have divided all the directions possible in the space into only two solid angles, the upper hemisphere and the lower hemisphere. What if we want to know the irradiance at a finer granularity (i.e., over a smaller solid angle)? We divide all the directions into more solid angles and analyze the irradiance change in them using a similar method.</p>
<p>For instance, if we now consider irradiance in four directions: <span class="math inline">\(E_{\nwarrow}(x)\)</span>, <span class="math inline">\(E_{\nearrow}(x)\)</span>, <span class="math inline">\(E_{\searrow}(x)\)</span>, and <span class="math inline">\(E_{\swarrow}(x)\)</span>, we can write the change of the irradiance in <span class="math inline">\(E_{\searrow}(x)\)</span> as:</p>
<p><span id="eq-n_stream_se"><span class="math display">\[
\begin{align}
    \frac{\d E_{\searrow}(x)}{\d x} = &amp; - K_{\searrow}(x) E_{\searrow}(x) \nonumber \\
    &amp; + S_{\nwarrow\searrow}(x) E_{\nwarrow}(x) + S_{\nearrow\searrow}(x) E_{\nearrow}(x) + S_{\swarrow\searrow}(x) E_{\swarrow}(x) \nonumber \\
    &amp; - S_{\searrow\nwarrow}(x) E_{\searrow}(x) - S_{\searrow\nearrow}(x) E_{\searrow}(x) - S_{\searrow\swarrow}(x) E_{\searrow}(x),
\end{align}
\tag{10.67}\]</span></span></p>
<p>where <span class="math inline">\(S_{\nwarrow\searrow}\)</span> is the scattering coefficient of from the northwest irradiance to the southeast direction, and so on. We can express the changes of the other three directions similarly. In general, if we divide the space into <span class="math inline">\(N\)</span> “channels”, each representing a set of directions (a finite solid angle), we can extend the two-flux model to a “N-flux” model.</p>
<div id="fig-n_flux" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-n_flux-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/n_flux.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-n_flux-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.12: The setup for the N-flux model. All the possible directions (consider all the arrows that can possibly go out from the origin) are divided into “channels” or “streams”, each of which represents a finite solid angle within which an irradiance travels. The N-flux model models the changes of each of these irradiances. Adapted from <span class="citation" data-cites="li2003ink">Li (<a href="references.html#ref-li2003ink" role="doc-biblioref">2003, fig. 4.1</a>)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-n_flux" class="quarto-xref">Figure&nbsp;<span>10.12</span></a> shows the setup for deriving the N-flux model, where all the possible directions (consider all the arrows that can possibly go out from the origin) are divided into “channels” or “streams”, each of which represents a finite solid angle within which an irradiance travels. The figure visualizes eight such channels. The change of each channel is modeled by taking away from each channel photons that are absorbed and scattered to all other channels and by adding photons scattered into the channel from all other channels. In the end, we get <span class="math inline">\(N\)</span> linear differential equations. <a href="#eq-n_stream_se" class="quarto-xref">Equation&nbsp;<span>10.67</span></a> is one such equation when <span class="math inline">\(N=4\)</span>. The channels are usually rotationally symmetric about the <span class="math inline">\(z\)</span>-axis, assuming that the material is rotationally symmetric about the <span class="math inline">\(z\)</span>-axis.</p>
<p>Comparing against the RTE in <a href="#eq-rte_2" class="quarto-xref">Equation&nbsp;<span>10.29</span></a>, which has an integral term <span class="math inline">\(L_s\)</span> given in <a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>10.26</span></a>. What the N-flux model does is to essentially approximate that integral with a finite sum. In general, the larger the <span class="math inline">\(N\)</span> the better the approximation but also the more computationally intensive to solve. We will omit a formal treatment but refer you to <span class="citation" data-cites="bohren2006fundamentals">Bohren and Clothiaux (<a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">2006</a>, Chpt. 6.1)</span>, <span class="citation" data-cites="volz2001industrial">Volz and Simon (<a href="references.html#ref-volz2001industrial" role="doc-biblioref">2001</a>, Chpt. 3.1.2)</span>, and <span class="citation" data-cites="klein2010industrial">Klein (<a href="references.html#ref-klein2010industrial" role="doc-biblioref">2010</a>, Chpt. 5.5)</span> for details.</p>
</section>
<section id="sec-chpt-mat-vs-km-cor" class="level3" data-number="10.5.5">
<h3 data-number="10.5.5" class="anchored" data-anchor-id="sec-chpt-mat-vs-km-cor"><span class="header-section-number">10.5.5</span> Correction for Surface Reflection</h3>
<p>One thing that is ignored in the K-M model is the surface reflection/refraction yet. Part of the photons will be reflected away at the air/material interface before they enter the material. Similarly, when we consider the transmittance, we have ignored the reflection/refraction at the other side of the material. So the reflectance and transmittance calculated by the K-M model are defined at the point when the photons are just about to leave the material.</p>
<p>To account for the surface phenomena, we can apply what is called the Saunderson correction, derived by <span class="citation" data-cites="saunderson1942calculation">Saunderson (<a href="references.html#ref-saunderson1942calculation" role="doc-biblioref">1942</a>)</span>. See <span class="citation" data-cites="sharma2003color">Sharma (<a href="references.html#ref-sharma2003color" role="doc-biblioref">2003</a>, Chpt. 3.6.3)</span> for a derivation, but briefly, if the illumination is diffuse, the corrected surface reflectance is:</p>
<p><span class="math display">\[
\begin{align}
    R = r_s + \frac{(1-r_s)(1-r_i)~R(0)}{1-r_i~R(0)},
\end{align}
\]</span></p>
<p>where <span class="math inline">\(R(0)\)</span> is the reflectance given by the K-M model, <span class="math inline">\(r_s\)</span> is the fraction of incident irradiance scattered by the air-material surface, and <span class="math inline">\(r_i\)</span> is the fraction of the internal irradiance approaching the air-material interface that is scattered back by the interface. Assuming a smooth surface, both <span class="math inline">\(r_s\)</span> and <span class="math inline">\(r_i\)</span> can be calculated by the Fresnel equations given the refractive index of the material (<a href="rendering-surface.html#sec-chpt-mat-ss-mat" class="quarto-xref"><span>Section 9.4</span></a>).</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bharath2009introductory" class="csl-entry" role="listitem">
Bharath, Anil. 2009. <em>Introductory Medical Imaging</em>. Morgan &amp; Claypool.
</div>
<div id="ref-blinn1982light" class="csl-entry" role="listitem">
Blinn, James F. 1982. <span>“Light Reflection Functions for Simulation of Clouds and Dusty Surfaces.”</span> <em>Acm SIGGRAPH Computer Graphics</em> 16 (3): 21–29.
</div>
<div id="ref-boas2001imaging" class="csl-entry" role="listitem">
Boas, David A, Dana H Brooks, Eric L Miller, Charles A DiMarzio, Misha Kilmer, Richard J Gaudette, and Quan Zhang. 2001. <span>“Imaging the Body with Diffuse Optical Tomography.”</span> <em>IEEE Signal Processing Magazine</em> 18 (6): 57–75.
</div>
<div id="ref-bohren2006fundamentals" class="csl-entry" role="listitem">
Bohren, Craig F, and Eugene E Clothiaux. 2006. <em>Fundamentals of Atmospheric Radiation: An Introduction with 400 Problems</em>. John Wiley &amp; Sons.
</div>
<div id="ref-bowmaker1980visual" class="csl-entry" role="listitem">
Bowmaker, James K, and HJk Dartnall. 1980. <span>“Visual Pigments of Rods and Cones in a Human Retina.”</span> <em>The Journal of Physiology</em> 298 (1): 501–11.
</div>
<div id="ref-paintpigmentsize" class="csl-entry" role="listitem">
Bruce MacEvoy. 2015. <span>“<span class="nocase">The material attributes of paints</span>.”</span> <a href="https://www.handprint.com/HP/WCL/pigmt3.html#particlesize" class="uri">https://www.handprint.com/HP/WCL/pigmt3.html#particlesize</a>.
</div>
<div id="ref-chandrasekhar1960radiative" class="csl-entry" role="listitem">
Chandrasekhar, Subrahmanyan. 1960. <em>Radiative Transfer</em>. Courier Corporation.
</div>
<div id="ref-dong2013material" class="csl-entry" role="listitem">
Dong, Yue, Stephen Lin, Baining Guo, et al. 2013. <em>Material Appearance Modeling: A Data-Coherent Approach</em>. Springer.
</div>
<div id="ref-eason1978theory" class="csl-entry" role="listitem">
Eason, G, AR Veitch, RM Nisbet, and FW Turnbull. 1978. <span>“The Theory of the Back-Scattering of Light by Blood.”</span> <em>Journal of Physics D: Applied Physics</em> 11 (10): 1463.
</div>
<div id="ref-engel2004real" class="csl-entry" role="listitem">
Engel, Klaus, Markus Hadwiger, Joe M Kniss, Christof Rezk-Salama, and Daniel Weiskopf. 2006. <em>Real-Time Volume Graphics</em>. A K Peters, Ltd.
</div>
<div id="ref-farrell1992diffusion" class="csl-entry" role="listitem">
Farrell, Thomas J, Michael S Patterson, and Brian Wilson. 1992. <span>“A Diffusion Theory Model of Spatially Resolved, Steady-State Diffuse Reflectance for the Noninvasive Determination of Tissue Optical Properties in Vivo.”</span> <em>Medical Physics</em> 19 (4): 879–88.
</div>
<div id="ref-fong2017production" class="csl-entry" role="listitem">
Fong, Julian, Magnus Wrenninge, Christopher Kulla, and Ralf Habel. 2017. <span>“Production Volume Rendering: Siggraph 2017 Course.”</span> In <em>ACM SIGGRAPH 2017 Courses</em>, 1–97.
</div>
<div id="ref-frisvad2020survey" class="csl-entry" role="listitem">
Frisvad, Jeppe Revall, Soeren A Jensen, Jonas Skovlund Madsen, António Correia, Li Yang, Søren Kimmer Schou Gregersen, Youri Meuret, and P-E Hansen. 2020. <span>“Survey of Models for Acquiring the Optical Properties of Translucent Materials.”</span> In <em>Computer Graphics Forum</em>, 39:729–55. 2. Wiley Online Library.
</div>
<div id="ref-glassner1995principles" class="csl-entry" role="listitem">
Glassner, Andrew S. 1995. <em>Principles of Digital Image Synthesis</em>. Elsevier.
</div>
<div id="ref-eelt_rendering" class="csl-entry" role="listitem">
Gnash. 2017. <span>“<span class="nocase">Rendering of the Extremely Large Telescope from 2009; CC BY-SA 4.0 license</span>.”</span> <a href="https://commons.wikimedia.org/wiki/File:Latest_Rendering_of_the_E-ELT.jpg" class="uri">https://commons.wikimedia.org/wiki/File:Latest_Rendering_of_the_E-ELT.jpg</a>.
</div>
<div id="ref-greene1986creating" class="csl-entry" role="listitem">
Greene, Ned, and Paul S Heckbert. 1986. <span>“Creating Raster Omnimax Images from Multiple Perspective Views Using the Elliptical Weighted Average Filter.”</span> <em>IEEE Computer Graphics and Applications</em> 6 (6): 21–27.
</div>
<div id="ref-gross2011point" class="csl-entry" role="listitem">
Gross, Markus, and Hanspeter Pfister. 2011. <em>Point-Based Graphics</em>. Elsevier.
</div>
<div id="ref-heckbert1989fundamentals" class="csl-entry" role="listitem">
Heckbert, Paul S. 1989. <span>“Fundamentals of Texture Mapping and Image Warping. Master’s Thesis.”</span> <em>University of California, Berkeley</em>.
</div>
<div id="ref-ishimaru1977theory" class="csl-entry" role="listitem">
Ishimaru, Akira. 1977. <span>“Theory and Application of Wave Propagation and Scattering in Random Media.”</span> <em>Proceedings of the IEEE</em> 65 (7): 1030–61.
</div>
<div id="ref-ishimaru1978wave" class="csl-entry" role="listitem">
Ishimaru, Akira et al. 1978. <em>Wave Propagation and Scattering in Random Media</em>. Vol. 2. Academic press New York.
</div>
<div id="ref-wann2001practical" class="csl-entry" role="listitem">
Jensen, Henrik Wann, Stephen R Marschner, Marc Levoy, and Pat Hanrahan. 2001. <span>“A Practical Model for Subsurface Light Transport.”</span> <em>ACM SIGGRAPH Computer Graphics</em>, 511–18.
</div>
<div id="ref-johnsen2012optics" class="csl-entry" role="listitem">
Johnsen, Sönke. 2012. <em>The Optics of Life: A Biologist’s Guide to Light in Nature</em>. Princeton University Press.
</div>
<div id="ref-kajiya1984ray" class="csl-entry" role="listitem">
Kajiya, James T, and Brian P Von Herzen. 1984. <span>“Ray Tracing Volume Densities.”</span> <em>ACM SIGGRAPH Computer Graphics</em> 18 (3): 165–74.
</div>
<div id="ref-kaufman2003volume" class="csl-entry" role="listitem">
Kaufman, Arie, and Klaus Mueller. 2003. <span>“Volume Visualization and Volume Graphics.”</span> <em>Technical Report; Stony Brook University</em>.
</div>
<div id="ref-kerbl20233d" class="csl-entry" role="listitem">
Kerbl, Bernhard, Georgios Kopanas, Thomas Leimkühler, and George Drettakis. 2023. <span>“3d Gaussian Splatting for Real-Time Radiance Field Rendering.”</span> <em>ACM Trans. Graph.</em> 42 (4): 139–31.
</div>
<div id="ref-klein2010industrial" class="csl-entry" role="listitem">
Klein, GA. 2010. <span>“Industrial Color Physics.”</span> Springer Science+ Business Media.
</div>
<div id="ref-kubelka1948new" class="csl-entry" role="listitem">
Kubelka, Paul. 1948. <span>“New Contributions to the Optics of Intensely Light-Scattering Materials. Part i.”</span> <em>Josa</em> 38 (5): 448–57.
</div>
<div id="ref-kubelka1931article" class="csl-entry" role="listitem">
Kubelka, Paul, and Franz Munk. 1931a. <span>“An Article on Optics of Paint Layers (Translated by Stephen h. Westin).”</span> <em>Z. Tech. Phys</em> 12 (593-601): 259–74.
</div>
<div id="ref-kubelka1931beitrag" class="csl-entry" role="listitem">
———. 1931b. <span>“Ein Beitrag Zur Optik Der Farbanstriche.”</span> <em>Z. Tech. Phys</em> 12:593–601.
</div>
<div id="ref-levoy1988display" class="csl-entry" role="listitem">
Levoy, Marc. 1988. <span>“Display of Surfaces from Volume Data.”</span> <em>IEEE Computer Graphics and Applications</em> 8 (3): 29–37.
</div>
<div id="ref-levoy1985use" class="csl-entry" role="listitem">
Levoy, Marc, and Turner Whitted. 1985. <span>“The Use of Points as a Display Primitive.”</span> <em>Technical Report; University of North Carolina at Chapel Hill</em>.
</div>
<div id="ref-li2003ink" class="csl-entry" role="listitem">
Li, Yang. 2003. <span>“Ink-Paper Interaction-a Study in Ink-Jet Color Reproduction.”</span> <em>Institute of Technology-Link<span>ö</span>pings University. Norrk<span>ö</span>ping, Sweden: UniTryck</em>.
</div>
<div id="ref-ctscanmouse" class="csl-entry" role="listitem">
MathiasRav. 2009. <span>“<span class="nocase">Volume rendering of a mouse skull (CT) using shear warp algorithm; CC BY-SA 3.0 license</span>.”</span> <a href="https://en.wikipedia.org/wiki/File:VolRenderShearWarp.gif" class="uri">https://en.wikipedia.org/wiki/File:VolRenderShearWarp.gif</a>.
</div>
<div id="ref-max1995optical" class="csl-entry" role="listitem">
Max, Nelson. 1995. <span>“Optical Models for Direct Volume Rendering.”</span> <em>IEEE Transactions on Visualization and Computer Graphics</em> 1 (2): 99–108.
</div>
<div id="ref-mayerhofer2020bouguer" class="csl-entry" role="listitem">
Mayerhöfer, Thomas G, Susanne Pahlow, and Jürgen Popp. 2020. <span>“The Bouguer-Beer-Lambert Law: Shining Light on the Obscure.”</span> <em>ChemPhysChem</em> 21 (18): 2029–46.
</div>
<div id="ref-melbourne2004radio" class="csl-entry" role="listitem">
Melbourne, William G. 2004. <em>Radio Occultations Using Earth Satellites: A Wave Theory Treatment</em>. 1st ed. John Wiley &amp; Sons.
</div>
<div id="ref-mildenhall2021nerf" class="csl-entry" role="listitem">
Mildenhall, Ben, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. 2021. <span>“Nerf: Representing Scenes as Neural Radiance Fields for View Synthesis.”</span> <em>Communications of the ACM</em> 65 (1): 99–106.
</div>
<div id="ref-milo2015cell" class="csl-entry" role="listitem">
Milo, Ron, and Rob Phillips. 2015. <em>Cell Biology by the Numbers</em>. Garland Science.
</div>
<div id="ref-nicodemus1977geometrical" class="csl-entry" role="listitem">
Nicodemus, FE, JC Richmond, JJ Hsia, IW Ginsberg, and T Limperis. 1977. <em>Geometrical Considerations and Nomenclature for Reflectance</em>. Vol. 160. US Department of Commerce, National Bureau of Standards Washington, DC, USA.
</div>
<div id="ref-novak2018monte" class="csl-entry" role="listitem">
Novák, Jan, Iliyan Georgiev, Johannes Hanika, Jaroslav Křivánek, and Wojciech Jarosz. 2018. <span>“<span>Monte</span> <span>Carlo</span> Methods for Physically Based Volume Rendering.”</span> In <em>ACM SIGGRAPH 2018 Courses</em>.
</div>
<div id="ref-pfister2000surfels" class="csl-entry" role="listitem">
Pfister, Hanspeter, Matthias Zwicker, Jeroen Van Baar, and Markus Gross. 2000. <span>“Surfels: Surface Elements as Rendering Primitives.”</span> In <em>Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques</em>, 335–42.
</div>
<div id="ref-pharr2018physically" class="csl-entry" role="listitem">
Pharr, Matt, Wenzel Jakob, and Greg Humphreys. 2018. <em>Physically Based Rendering: From Theory to Implementation</em>. 3rd ed. MIT Press.
</div>
<div id="ref-pharr2023physically" class="csl-entry" role="listitem">
———. 2023. <em>Physically Based Rendering: From Theory to Implementation</em>. 4th ed. MIT Press.
</div>
<div id="ref-sabella1988rendering" class="csl-entry" role="listitem">
Sabella, Paolo. 1988. <span>“A Rendering Algorithm for Visualizing 3D Scalar Fields.”</span> <em>ACM SIGGRAPH Computer Graphics</em> 22 (4): 51–58.
</div>
<div id="ref-saunderson1942calculation" class="csl-entry" role="listitem">
Saunderson, JL. 1942. <span>“Calculation of the Color of Pigmented Plastics.”</span> <em>JOSA</em> 32 (12): 727–36.
</div>
<div id="ref-schweiger1995finite" class="csl-entry" role="listitem">
Schweiger, Martin, SR Arridge, M Hiraoka, and DT Delpy. 1995. <span>“The Finite Element Method for the Propagation of Light in Scattering Media: Boundary and Source Conditions.”</span> <em>Medical Physics</em> 22 (11): 1779–92.
</div>
<div id="ref-sharma2003color" class="csl-entry" role="listitem">
Sharma, Gaurav. 2003. <span>“Color Fundamentals for Digital Imaging.”</span> In <em>Digital Color Imaging Handbook</em>, edited by Gaurav Sharma, 14–127. CRC Press.
</div>
<div id="ref-ctscan" class="csl-entry" role="listitem">
Sjschen. 2025. <span>“<span class="nocase">Volume rendered CT scan of a forearm with different color schemes for muscle, fat, bone, and blood; released into the public domain by the copyright holder</span>.”</span> <a href="https://commons.wikimedia.org/wiki/File:CTWristImage.png" class="uri">https://commons.wikimedia.org/wiki/File:CTWristImage.png</a>.
</div>
<div id="ref-smith1995alpha" class="csl-entry" role="listitem">
Smith, Alvy Ray. 1995. <span>“Alpha and the History of Digital Compositing.”</span> Citeseer.
</div>
<div id="ref-stam1995multiple" class="csl-entry" role="listitem">
Stam, Jos. 1995. <span>“Multiple Scattering as a Diffusion Process.”</span> In <em>Rendering Techniques’ 95: Proceedings of the Eurographics Workshop in Dublin, Ireland, June 12–14, 1995 6</em>, 41–50. Springer.
</div>
<div id="ref-volz2001industrial" class="csl-entry" role="listitem">
Volz, Hans G, and Frederick T Simon. 2001. <em>Industrial Color Testing</em>. Vol. 2. Wiley-VCH New York.
</div>
<div id="ref-westover1990footprint" class="csl-entry" role="listitem">
Westover, Lee. 1990. <span>“Footprint Evaluation for Volume Rendering.”</span> In <em>Proceedings of the 17th Annual Conference on Computer Graphics and Interactive Techniques</em>, 367–76.
</div>
<div id="ref-williams1992volume" class="csl-entry" role="listitem">
Williams, Peter L, and Nelson Max. 1992. <span>“A Volume Density Optical Model.”</span> In <em>Proceedings of the 1992 Workshop on Volume Visualization</em>, 61–68.
</div>
<div id="ref-wrenninge2011production" class="csl-entry" role="listitem">
Wrenninge, Magnus, and Nafees Bin Zafar. 2011. <span>“Production Volume Rendering: Siggraph 2011 Course.”</span> In <em>ACM SIGGRAPH 2011 Courses</em>, 1–71.
</div>
<div id="ref-yifan2019differentiable" class="csl-entry" role="listitem">
Yifan, Wang, Felice Serena, Shihao Wu, Cengiz Öztireli, and Olga Sorkine-Hornung. 2019. <span>“Differentiable Surface Splatting for Point-Based Geometry Processing.”</span> <em>ACM Transactions On Graphics (TOG)</em> 38 (6): 1–14.
</div>
<div id="ref-zwicker2001ewa" class="csl-entry" role="listitem">
Zwicker, Matthias, Hanspeter Pfister, Jeroen Van Baar, and Markus Gross. 2001a. <span>“EWA Volume Splatting.”</span> In <em>Proceedings Visualization, 2001. VIS’01.</em>, 29–538. IEEE.
</div>
<div id="ref-zwicker2001surface" class="csl-entry" role="listitem">
———. 2001b. <span>“Surface Splatting.”</span> In <em>Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques</em>, 371–78.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>“Isotropic” is a very overloaded term; it just means some physical property is invariant when measured from different directions. So depending on what physical property you care about, “isotropic” can mean different things. The property we care about here is a volume’s ability to absorb photons, which is different from our earlier use of isotropy, which is concerned with the ability of a surface to scatter photons.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Technically photons from other objects can enter our eye through a single-scattering event; see the discussion at the end.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>A direction <span class="math inline">\(\os\)</span> has a solid angle of 0, so its associated irradiance is technically 0, too. What <span class="math inline">\(f_p(\os, \oi)L(\oi)\doi\)</span> represents is the irradiance per solid angle.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>or when the medium consists of randomly distributed and oriented spherically asymmetric particles, in which case the medium is <em>statistically</em> spherically symmetric.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>In theory, it is certainly possible to have a medium whose total scattering coefficient/efficiency varies with the incident direction but not the angular distribution/probability of the scattered photons.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>The modern form of the solution is summarized, not invented, by Gustav Mie but the solution had been developed by many predecessors such as Ludvig Lorenz.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>worked out by Lord Rayleigh, who won the Nobel Prize in Physics in 1904<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Subrahmanyan Chandrasekhar won the Nobel Prize in physics in 1983 (not for the RTE).<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Technically, even single scattering can lead to augmentation if there is illumination coming from anywhere outside the ray direction.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>There are two alternative parameterizations, both of which are common in graphics literature. The first <span class="citation" data-cites="pharr2023physically">(<a href="references.html#ref-pharr2023physically" role="doc-biblioref">Pharr, Jakob, and Humphreys 2023</a>)</span> is to express <span class="math inline">\(p_0 = p + s\os\)</span> (<span class="math inline">\(s\)</span> being positive), but then the initial radiance would have to be expressed as <span class="math inline">\(L(p_0, -\os)\)</span>, since <span class="math inline">\(\os\)</span> now points from <span class="math inline">\(p\)</span> to <span class="math inline">\(p_0\)</span>. The other is to express <span class="math inline">\(p_0 = p - s\os\)</span> (<span class="math inline">\(s\)</span> again being positive) <span class="citation" data-cites="fong2017production">(<a href="references.html#ref-fong2017production" role="doc-biblioref">Fong et al. 2017</a>)</span>; this avoids the need to switch directions but uses a negative sign. It is a matter of taste which one to use, but be alert to the different conventions.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Some (color) transfer functions could have physical underpinnings, such as applying a single-scattering shading algorithms (i.e., local illumination); see, e.g., <span class="citation" data-cites="levoy1988display">Levoy (<a href="references.html#ref-levoy1988display" role="doc-biblioref">1988</a>, Sect. 3)</span> or <span class="citation" data-cites="max1995optical">Max (<a href="references.html#ref-max1995optical" role="doc-biblioref">1995</a>, Sect. 5)</span>, but the goal there is not to precisely model physics but for better, subjective visualization.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>assuming a diffuse surface so we care to reconstruct the color of each point, not the radiance of each ray.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>The compound filter combining reconstruction and anti-aliasing filters is sometimes also called a resampling filter, because the compound filter is used during resampling to calculate the new sample values.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>which says that there exists <span class="math inline">\(c\in [a, b]\)</span> such that <span class="math inline">\(\int_a^b f(x)g(x)\d x = f(c)\int_a^b g(x)\d x\)</span>, if <span class="math inline">\(g(x)\)</span> is integrable and does not change its sign in <span class="math inline">\([a, b]\)</span>.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>If <span class="math inline">\(L(x, \omega)\)</span> is invariant to <span class="math inline">\(\omega\)</span> and <span class="math inline">\(f_p(x, \omega', \hat{\omega})\)</span>, under the isotropic medium assumption, is reduced to <span class="math inline">\(f_p(x, \theta)\)</span>, where <span class="math inline">\(\theta\)</span> is the angle subtended by <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega'\)</span>, both <span class="math inline">\(S_{\uparrow\downarrow}(x)\)</span> and <span class="math inline">\(S_{\downarrow\uparrow}(x)\)</span> are essentially calculating <span class="math inline">\(\int^{\pi}\int^{\pi}c~\d \theta\d \theta'\)</span>.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>You can see that <span class="math inline">\(T(X)\)</span> does not involve <span class="math inline">\(R_g\)</span>: when we calculate the transmittance of the material, we assume that there is no substrate.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./rendering-surface.html" class="pagination-link" aria-label="Surface Scattering">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Surface Scattering</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./imaging.html" class="pagination-link" aria-label="Imaging">
        <span class="nav-page-text">Imaging</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>